{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_tokens = {'additional_special_tokens': ['[entity1]', '[entity2]', '[learn1]', '[learn2]', '[learn3]', '[learn4]', '[learn5]', '[learn6]']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "\n",
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 124439808 || all params: 124439808 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_added_toks = tokenizer.add_special_tokens(additional_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50267, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DocRED/GPT_w_ner[]/gpt2_tokenizer/tokenizer_config.json',\n",
       " 'DocRED/GPT_w_ner[]/gpt2_tokenizer/special_tokens_map.json',\n",
       " 'DocRED/GPT_w_ner[]/gpt2_tokenizer/vocab.json',\n",
       " 'DocRED/GPT_w_ner[]/gpt2_tokenizer/merges.txt',\n",
       " 'DocRED/GPT_w_ner[]/gpt2_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the tokenizer\n",
    "\n",
    "tokenizer.save_pretrained('DocRED/GPT_w_ner[]/gpt2_tokenizer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file from DocRED/data/test.json and DocRED/data/rel_info.json\n",
    "\n",
    "import json\n",
    "\n",
    "with open('DocRED/data/train_annotated.json') as f:\n",
    "    train_set = json.load(f)\n",
    "\n",
    "\n",
    "with open('DocRED/data/rel_info.json') as f:\n",
    "    rel_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = {\n",
    "    'id': [],\n",
    "    'text': [],\n",
    "    'head': [],\n",
    "    'tail': [],\n",
    "    'head_first': [],\n",
    "    'relation': [],\n",
    "    'head_start_pos' : [],\n",
    "    'tail_start_pos' : []\n",
    "}\n",
    "\n",
    "for i in range(len(train_set)):\n",
    "    sents = \"\"\n",
    "    for sent in train_set[i]['sents']:\n",
    "        # flatten the sent list\n",
    "        a = \" \".join(sent)\n",
    "        sents += a.lower() + \" \"\n",
    "    # relation_dict['text'].append(sents)\n",
    "\n",
    "    for relation_pair in train_set[i]['labels']:\n",
    "        relation_dict['id'].append(i)\n",
    "        relation_dict['text'].append(sents)\n",
    "        head = []\n",
    "        head_ = []\n",
    "        head_start_pos = []\n",
    "        head.append([[item['name'].lower()] for item in train_set[i]['vertexSet'][relation_pair['h']]])\n",
    "        for j, item in enumerate(head[0]):\n",
    "            if item not in head_:\n",
    "                head_.append(item)\n",
    "                head_start_pos.append(train_set[i]['vertexSet'][relation_pair['h']][j]['pos'][0])\n",
    "\n",
    "        relation_dict['head'].append(head_)\n",
    "        relation_dict['head_start_pos'].append(head_start_pos)\n",
    "\n",
    "        tail = []\n",
    "        tail_ = []\n",
    "        tail_start_pos = []\n",
    "        tail.append([[item['name'].lower()] for item in train_set[i]['vertexSet'][relation_pair['t']]])\n",
    "        for j, item in enumerate(tail[0]):\n",
    "            if item not in tail_:\n",
    "                tail_.append(item)\n",
    "                tail_start_pos.append(train_set[i]['vertexSet'][relation_pair['t']][j]['pos'][0])\n",
    "        relation_dict['tail'].append(tail_)\n",
    "        relation_dict['tail_start_pos'].append(tail_start_pos)\n",
    "\n",
    "        \n",
    "        if train_set[i]['vertexSet'][relation_pair['h']][0]['pos'][0] < train_set[i]['vertexSet'][relation_pair['t']][0]['pos'][0]:\n",
    "            relation_dict['head_first'].append(1)\n",
    "        else:\n",
    "            relation_dict['head_first'].append(0)\n",
    "        \n",
    "        relation_dict['relation'].append(relation_pair['r'])\n",
    "    # break\n",
    "\n",
    "\n",
    "# save the relation_dict to a json file\n",
    "\n",
    "with open('DocRED/data/DocRED_baseline_metadata/relation_dict.json', 'w') as f:\n",
    "    json.dump(relation_dict, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "if ner:\n",
    "    with open('DocRED/data/DocRED_baseline_metadata/relation_dict.json') as f:\n",
    "        relation_dict = json.load(f)\n",
    "\n",
    "    dataset = Dataset.from_dict(\n",
    "        {\n",
    "            'text': relation_dict['text'],\n",
    "            'head': relation_dict['head'],\n",
    "            'tail': relation_dict['tail'],\n",
    "            'head_first': relation_dict['head_first'],\n",
    "            'relation': relation_dict['relation']\n",
    "        }\n",
    "    )\n",
    "\n",
    "else:\n",
    "    with open('DocRED/data/DocRED_baseline_metadata/relation_dict_ner.json') as f:\n",
    "        relation_dict = json.load(f)\n",
    "\n",
    "    dataset = Dataset.from_dict(\n",
    "        {\n",
    "            'text': relation_dict['text'],\n",
    "            'pair': relation_dict['pair'],\n",
    "            'relation': relation_dict['relation']\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'head', 'tail', 'head_first', 'relation'],\n",
       "    num_rows: 38180\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pro_processing_ner(example, tokenizer, padding=True):\n",
    "    texts = example['text']\n",
    "\n",
    "    # special_tokens = [50259, 50260, 50261, 50262, 50263, 50264]\n",
    "\n",
    "    output_texts = []\n",
    "\n",
    "    text_ids = tokenizer(texts, add_special_tokens=False)['input_ids']\n",
    "\n",
    "    for i in range(len(example['head'])):\n",
    "        head = \"\"\n",
    "        for item in example['head'][i]:\n",
    "            head += item[0] + \" ; \"\n",
    "        head = head[:-2]\n",
    "        head += \". \"\n",
    "\n",
    "        tail = \"\"\n",
    "        for item in example['tail'][i]:\n",
    "            tail += item[0] + \" ; \"\n",
    "        tail = tail[:-2]\n",
    "        tail += \". \"\n",
    "        \n",
    "        if example['head_first'][i] == 1:\n",
    "            output_line = \" [entity1] : \" + head + \"[entity2] : \" + tail + \"[learn1] [learn2] [learn3] [learn4] [learn5] [learn6] \"\n",
    "            output_line = output_line + f\"the relation between source [entity1] and target [entity2] is {rel_info[example['relation'][i]]} . \" + tokenizer.eos_token\n",
    "\n",
    "        else:\n",
    "            output_line = \" [entity1] : \" + tail + \"[entity2] : \" + head + \"[learn1] [learn2] [learn3] [learn4] [learn5] [learn6] \"\n",
    "            output_line = output_line + f\"the relation between source [entity2] and target [entity1] is {rel_info[example['relation'][i]]} . \" + tokenizer.eos_token\n",
    "        \n",
    "        output_texts.append(output_line)\n",
    "\n",
    "\n",
    "    output_ids = tokenizer(output_texts, add_special_tokens=False)['input_ids']\n",
    "\n",
    "    # input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    count = 0\n",
    "    for i, ids in enumerate(output_ids):\n",
    "        if len(text_ids[i]) + len(ids) > 1024:\n",
    "            text_ids[i] = text_ids[:1024 - len(ids)]\n",
    "            count += 1\n",
    "        text_ids[i] = text_ids[i] + output_ids[i]\n",
    "        assert len(text_ids[i]) <= 1024\n",
    "        attention_mask.append([1] * len(text_ids[i]) + [0] * (1024 - len(text_ids[i])))\n",
    "    if count != 0:\n",
    "        print(f\"truncated {count} examples\")\n",
    "\n",
    "    if padding:\n",
    "        for i, ids in enumerate(output_ids):\n",
    "            output_ids[i] = ids + [tokenizer.pad_token_id] * (1024 - len(ids))\n",
    "            text_ids[i] = text_ids[i] + [tokenizer.pad_token_id] * (1024 - len(text_ids[i]))\n",
    "\n",
    "    return {\n",
    "        'input_ids': text_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbf9994d1e247c2996e442fc630198f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(lambda example: pro_processing_ner(example, tokenizer), batched=True, remove_columns=['text', 'head', 'tail', 'head_first', 'relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab0d8b60e2e439694e9add2d53f0ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/38180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save the datasets type tokenized_dataset\n",
    "\n",
    "tokenized_dataset.save_to_disk('DocRED/data/DocRED_baseline_metadata/tokenized_dataset_w_ner_[]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenized_dataset\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n",
    "tokenized_dataset = load_from_disk('DocRED/data/DocRED_baseline_metadata/tokenized_dataset_w_ner_[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"zest airways, inc. operated as airasia zest ( formerly asian spirit and zest air ), was a low - cost airline based at the ninoy aquino international airport in pasay city, metro manila in the philippines. it operated scheduled domestic and international tourist services, mainly feeder services linking manila and cebu with 24 domestic destinations in support of the trunk route operations of other airlines. in 2013, the airline became an affiliate of philippines airasia operating their brand separately. its main base was ninoy aquino international airport, manila. the airline was founded as asian spirit, the first airline in the philippines to be run as a cooperative. on august 16, 2013, the civil aviation authority of the philippines ( caap ), the regulating body of the government of the republic of the philippines for civil aviation, suspended zest air flights until further notice because of safety issues. less than a year after airasia and zest air's strategic alliance, the airline has been rebranded as airasia zest. the airline was merged into airasia philippines in january 2016.  [entity1] : zest airways, inc. ; asian spirit and zest air ; airasia zest. [entity2] : pasay city. [learn1] [learn2] [learn3] [learn4] [learn5] [learn6] the relation between source [entity1] and target [entity2] is headquarters location. <|endoftext|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|> <|pad|>\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset[0]['input_ids'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m309439737\u001b[0m (\u001b[33mtian1995\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tian/Projects/BioRED/wandb/run-20230709_222050-7ao24mdl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tian1995/GPT2-normal/runs/7ao24mdl' target=\"_blank\">GPT2-DocRED-w-ner-[]-5epochs</a></strong> to <a href='https://wandb.ai/tian1995/GPT2-normal' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tian1995/GPT2-normal' target=\"_blank\">https://wandb.ai/tian1995/GPT2-normal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tian1995/GPT2-normal/runs/7ao24mdl' target=\"_blank\">https://wandb.ai/tian1995/GPT2-normal/runs/7ao24mdl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/tian1995/GPT2-normal/runs/7ao24mdl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8ad2742da0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"GPT2-normal\",\n",
    "    # notes=\"PubmedBERT-FT-NER_w_NERin_10epochs\",\n",
    "    name=\"GPT2-DocRED-w-ner-[]-5epochs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model, \n",
    "    train_dataset=tokenized_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1, \n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=1000, \n",
    "        num_train_epochs=5,\n",
    "        learning_rate=2e-4, \n",
    "        # fp16=True,\n",
    "        logging_steps=100, \n",
    "        report_to=\"wandb\",\n",
    "        save_strategy=\"epoch\",\n",
    "        output_dir='DocRED/GPT_w_ner[]'\n",
    "    ),\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d47e7c0bd241f79913b917ee49e57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 31.3334, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
      "{'loss': 4.2714, 'learning_rate': 4e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5394, 'learning_rate': 6e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3138, 'learning_rate': 8e-05, 'epoch': 0.01}\n",
      "{'loss': 3.2583, 'learning_rate': 0.0001, 'epoch': 0.01}\n",
      "{'loss': 3.1792, 'learning_rate': 0.00012, 'epoch': 0.02}\n",
      "{'loss': 3.1823, 'learning_rate': 0.00014, 'epoch': 0.02}\n",
      "{'loss': 3.1748, 'learning_rate': 0.00016, 'epoch': 0.02}\n",
      "{'loss': 3.1869, 'learning_rate': 0.00018, 'epoch': 0.02}\n",
      "{'loss': 3.1112, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
      "{'loss': 3.1083, 'learning_rate': 0.0001998946814112691, 'epoch': 0.03}\n",
      "{'loss': 3.0954, 'learning_rate': 0.0001997893628225382, 'epoch': 0.03}\n",
      "{'loss': 3.0576, 'learning_rate': 0.00019968404423380726, 'epoch': 0.03}\n",
      "{'loss': 2.9796, 'learning_rate': 0.00019957872564507637, 'epoch': 0.04}\n",
      "{'loss': 2.9982, 'learning_rate': 0.00019947340705634545, 'epoch': 0.04}\n",
      "{'loss': 3.0452, 'learning_rate': 0.00019936808846761453, 'epoch': 0.04}\n",
      "{'loss': 2.9426, 'learning_rate': 0.00019926276987888364, 'epoch': 0.04}\n",
      "{'loss': 2.9404, 'learning_rate': 0.00019915745129015273, 'epoch': 0.05}\n",
      "{'loss': 2.8744, 'learning_rate': 0.0001990521327014218, 'epoch': 0.05}\n",
      "{'loss': 2.7302, 'learning_rate': 0.0001989468141126909, 'epoch': 0.05}\n",
      "{'loss': 2.8062, 'learning_rate': 0.00019884149552395997, 'epoch': 0.06}\n",
      "{'loss': 2.7527, 'learning_rate': 0.00019873617693522908, 'epoch': 0.06}\n",
      "{'loss': 2.7649, 'learning_rate': 0.00019863085834649817, 'epoch': 0.06}\n",
      "{'loss': 2.7603, 'learning_rate': 0.00019852553975776728, 'epoch': 0.06}\n",
      "{'loss': 2.6685, 'learning_rate': 0.00019842022116903633, 'epoch': 0.07}\n",
      "{'loss': 2.7269, 'learning_rate': 0.00019831490258030542, 'epoch': 0.07}\n",
      "{'loss': 2.7318, 'learning_rate': 0.00019820958399157453, 'epoch': 0.07}\n",
      "{'loss': 2.6038, 'learning_rate': 0.0001981042654028436, 'epoch': 0.07}\n",
      "{'loss': 2.4921, 'learning_rate': 0.00019799894681411272, 'epoch': 0.08}\n",
      "{'loss': 2.7343, 'learning_rate': 0.0001978936282253818, 'epoch': 0.08}\n",
      "{'loss': 2.6299, 'learning_rate': 0.00019778830963665086, 'epoch': 0.08}\n",
      "{'loss': 2.4902, 'learning_rate': 0.00019768299104791997, 'epoch': 0.08}\n",
      "{'loss': 2.6657, 'learning_rate': 0.00019757767245918905, 'epoch': 0.09}\n",
      "{'loss': 2.6225, 'learning_rate': 0.00019747235387045816, 'epoch': 0.09}\n",
      "{'loss': 2.4771, 'learning_rate': 0.00019736703528172724, 'epoch': 0.09}\n",
      "{'loss': 2.5315, 'learning_rate': 0.00019726171669299633, 'epoch': 0.09}\n",
      "{'loss': 2.4107, 'learning_rate': 0.0001971563981042654, 'epoch': 0.1}\n",
      "{'loss': 2.5906, 'learning_rate': 0.0001970510795155345, 'epoch': 0.1}\n",
      "{'loss': 2.4018, 'learning_rate': 0.0001969457609268036, 'epoch': 0.1}\n",
      "{'loss': 2.4473, 'learning_rate': 0.00019684044233807268, 'epoch': 0.1}\n",
      "{'loss': 2.5375, 'learning_rate': 0.00019673512374934177, 'epoch': 0.11}\n",
      "{'loss': 2.4477, 'learning_rate': 0.00019662980516061085, 'epoch': 0.11}\n",
      "{'loss': 2.3969, 'learning_rate': 0.00019652448657187993, 'epoch': 0.11}\n",
      "{'loss': 2.4894, 'learning_rate': 0.00019641916798314904, 'epoch': 0.12}\n",
      "{'loss': 2.2545, 'learning_rate': 0.00019631384939441813, 'epoch': 0.12}\n",
      "{'loss': 2.3081, 'learning_rate': 0.0001962085308056872, 'epoch': 0.12}\n",
      "{'loss': 2.3475, 'learning_rate': 0.00019610321221695632, 'epoch': 0.12}\n",
      "{'loss': 2.3501, 'learning_rate': 0.00019599789362822537, 'epoch': 0.13}\n",
      "{'loss': 2.4139, 'learning_rate': 0.00019589257503949448, 'epoch': 0.13}\n",
      "{'loss': 2.3458, 'learning_rate': 0.00019578725645076357, 'epoch': 0.13}\n",
      "{'loss': 2.3006, 'learning_rate': 0.00019568193786203265, 'epoch': 0.13}\n",
      "{'loss': 2.2876, 'learning_rate': 0.00019557661927330176, 'epoch': 0.14}\n",
      "{'loss': 2.3101, 'learning_rate': 0.00019547130068457084, 'epoch': 0.14}\n",
      "{'loss': 2.3285, 'learning_rate': 0.00019536598209583992, 'epoch': 0.14}\n",
      "{'loss': 2.2714, 'learning_rate': 0.000195260663507109, 'epoch': 0.14}\n",
      "{'loss': 2.1504, 'learning_rate': 0.0001951553449183781, 'epoch': 0.15}\n",
      "{'loss': 2.2002, 'learning_rate': 0.0001950500263296472, 'epoch': 0.15}\n",
      "{'loss': 2.0947, 'learning_rate': 0.00019494470774091628, 'epoch': 0.15}\n",
      "{'loss': 2.086, 'learning_rate': 0.0001948393891521854, 'epoch': 0.15}\n",
      "{'loss': 2.156, 'learning_rate': 0.00019473407056345445, 'epoch': 0.16}\n",
      "{'loss': 2.2104, 'learning_rate': 0.00019462875197472353, 'epoch': 0.16}\n",
      "{'loss': 2.0139, 'learning_rate': 0.00019452343338599264, 'epoch': 0.16}\n",
      "{'loss': 2.2189, 'learning_rate': 0.00019441811479726172, 'epoch': 0.17}\n",
      "{'loss': 2.227, 'learning_rate': 0.00019431279620853083, 'epoch': 0.17}\n",
      "{'loss': 2.1136, 'learning_rate': 0.0001942074776197999, 'epoch': 0.17}\n",
      "{'loss': 2.0119, 'learning_rate': 0.00019410215903106897, 'epoch': 0.17}\n",
      "{'loss': 2.1381, 'learning_rate': 0.00019399684044233808, 'epoch': 0.18}\n",
      "{'loss': 2.0665, 'learning_rate': 0.00019389152185360717, 'epoch': 0.18}\n",
      "{'loss': 2.0177, 'learning_rate': 0.00019378620326487628, 'epoch': 0.18}\n",
      "{'loss': 2.1113, 'learning_rate': 0.00019368088467614536, 'epoch': 0.18}\n",
      "{'loss': 2.0685, 'learning_rate': 0.00019357556608741444, 'epoch': 0.19}\n",
      "{'loss': 2.0225, 'learning_rate': 0.00019347024749868352, 'epoch': 0.19}\n",
      "{'loss': 1.9398, 'learning_rate': 0.0001933649289099526, 'epoch': 0.19}\n",
      "{'loss': 1.9354, 'learning_rate': 0.00019325961032122172, 'epoch': 0.19}\n",
      "{'loss': 1.9025, 'learning_rate': 0.0001931542917324908, 'epoch': 0.2}\n",
      "{'loss': 1.809, 'learning_rate': 0.00019304897314375988, 'epoch': 0.2}\n",
      "{'loss': 1.8731, 'learning_rate': 0.00019294365455502897, 'epoch': 0.2}\n",
      "{'loss': 1.9234, 'learning_rate': 0.00019283833596629805, 'epoch': 0.2}\n",
      "{'loss': 1.938, 'learning_rate': 0.00019273301737756716, 'epoch': 0.21}\n",
      "{'loss': 1.9755, 'learning_rate': 0.00019262769878883624, 'epoch': 0.21}\n",
      "{'loss': 2.0275, 'learning_rate': 0.00019252238020010532, 'epoch': 0.21}\n",
      "{'loss': 1.8585, 'learning_rate': 0.00019241706161137443, 'epoch': 0.21}\n",
      "{'loss': 1.7389, 'learning_rate': 0.0001923117430226435, 'epoch': 0.22}\n",
      "{'loss': 1.8362, 'learning_rate': 0.0001922064244339126, 'epoch': 0.22}\n",
      "{'loss': 1.9141, 'learning_rate': 0.00019210110584518168, 'epoch': 0.22}\n",
      "{'loss': 1.8767, 'learning_rate': 0.00019199578725645076, 'epoch': 0.23}\n",
      "{'loss': 1.8774, 'learning_rate': 0.00019189046866771987, 'epoch': 0.23}\n",
      "{'loss': 1.8086, 'learning_rate': 0.00019178515007898893, 'epoch': 0.23}\n",
      "{'loss': 1.6758, 'learning_rate': 0.00019167983149025804, 'epoch': 0.23}\n",
      "{'loss': 1.6252, 'learning_rate': 0.00019157451290152712, 'epoch': 0.24}\n",
      "{'loss': 1.6436, 'learning_rate': 0.0001914691943127962, 'epoch': 0.24}\n",
      "{'loss': 1.843, 'learning_rate': 0.00019136387572406532, 'epoch': 0.24}\n",
      "{'loss': 1.7074, 'learning_rate': 0.0001912585571353344, 'epoch': 0.24}\n",
      "{'loss': 1.74, 'learning_rate': 0.00019115323854660348, 'epoch': 0.25}\n",
      "{'loss': 1.7914, 'learning_rate': 0.00019104791995787256, 'epoch': 0.25}\n",
      "{'loss': 1.6206, 'learning_rate': 0.00019094260136914165, 'epoch': 0.25}\n",
      "{'loss': 1.7442, 'learning_rate': 0.00019083728278041076, 'epoch': 0.25}\n",
      "{'loss': 1.6865, 'learning_rate': 0.00019073196419167984, 'epoch': 0.26}\n",
      "{'loss': 1.4943, 'learning_rate': 0.00019062664560294895, 'epoch': 0.26}\n",
      "{'loss': 1.6654, 'learning_rate': 0.000190521327014218, 'epoch': 0.26}\n",
      "{'loss': 1.8709, 'learning_rate': 0.00019041600842548712, 'epoch': 0.26}\n",
      "{'loss': 1.4633, 'learning_rate': 0.0001903106898367562, 'epoch': 0.27}\n",
      "{'loss': 1.6603, 'learning_rate': 0.00019020537124802528, 'epoch': 0.27}\n",
      "{'loss': 1.5909, 'learning_rate': 0.0001901000526592944, 'epoch': 0.27}\n",
      "{'loss': 1.6286, 'learning_rate': 0.00018999473407056347, 'epoch': 0.28}\n",
      "{'loss': 1.3723, 'learning_rate': 0.00018988941548183256, 'epoch': 0.28}\n",
      "{'loss': 1.5346, 'learning_rate': 0.00018978409689310164, 'epoch': 0.28}\n",
      "{'loss': 1.6544, 'learning_rate': 0.00018967877830437072, 'epoch': 0.28}\n",
      "{'loss': 1.4379, 'learning_rate': 0.00018957345971563983, 'epoch': 0.29}\n",
      "{'loss': 1.4377, 'learning_rate': 0.00018946814112690892, 'epoch': 0.29}\n",
      "{'loss': 1.5793, 'learning_rate': 0.000189362822538178, 'epoch': 0.29}\n",
      "{'loss': 1.5562, 'learning_rate': 0.00018925750394944708, 'epoch': 0.29}\n",
      "{'loss': 1.5667, 'learning_rate': 0.00018915218536071616, 'epoch': 0.3}\n",
      "{'loss': 1.5642, 'learning_rate': 0.00018904686677198527, 'epoch': 0.3}\n",
      "{'loss': 1.6667, 'learning_rate': 0.00018894154818325436, 'epoch': 0.3}\n",
      "{'loss': 1.5321, 'learning_rate': 0.00018883622959452344, 'epoch': 0.3}\n",
      "{'loss': 1.4148, 'learning_rate': 0.00018873091100579252, 'epoch': 0.31}\n",
      "{'loss': 1.5084, 'learning_rate': 0.0001886255924170616, 'epoch': 0.31}\n",
      "{'loss': 1.3633, 'learning_rate': 0.00018852027382833071, 'epoch': 0.31}\n",
      "{'loss': 1.638, 'learning_rate': 0.0001884149552395998, 'epoch': 0.31}\n",
      "{'loss': 1.2875, 'learning_rate': 0.00018830963665086888, 'epoch': 0.32}\n",
      "{'loss': 1.458, 'learning_rate': 0.000188204318062138, 'epoch': 0.32}\n",
      "{'loss': 1.3555, 'learning_rate': 0.00018809899947340705, 'epoch': 0.32}\n",
      "{'loss': 1.3728, 'learning_rate': 0.00018799368088467616, 'epoch': 0.32}\n",
      "{'loss': 1.3125, 'learning_rate': 0.00018788836229594524, 'epoch': 0.33}\n",
      "{'loss': 1.3971, 'learning_rate': 0.00018778304370721432, 'epoch': 0.33}\n",
      "{'loss': 1.4418, 'learning_rate': 0.00018767772511848343, 'epoch': 0.33}\n",
      "{'loss': 1.3319, 'learning_rate': 0.00018757240652975251, 'epoch': 0.34}\n",
      "{'loss': 1.4148, 'learning_rate': 0.0001874670879410216, 'epoch': 0.34}\n",
      "{'loss': 1.6041, 'learning_rate': 0.00018736176935229068, 'epoch': 0.34}\n",
      "{'loss': 1.4891, 'learning_rate': 0.00018725645076355976, 'epoch': 0.34}\n",
      "{'loss': 1.5322, 'learning_rate': 0.00018715113217482887, 'epoch': 0.35}\n",
      "{'loss': 1.3699, 'learning_rate': 0.00018704581358609796, 'epoch': 0.35}\n",
      "{'loss': 1.3053, 'learning_rate': 0.00018694049499736707, 'epoch': 0.35}\n",
      "{'loss': 1.3912, 'learning_rate': 0.00018683517640863612, 'epoch': 0.35}\n",
      "{'loss': 1.4047, 'learning_rate': 0.00018672985781990523, 'epoch': 0.36}\n",
      "{'loss': 1.2424, 'learning_rate': 0.00018662453923117431, 'epoch': 0.36}\n",
      "{'loss': 1.446, 'learning_rate': 0.0001865192206424434, 'epoch': 0.36}\n",
      "{'loss': 1.2809, 'learning_rate': 0.0001864139020537125, 'epoch': 0.36}\n",
      "{'loss': 1.2055, 'learning_rate': 0.00018630858346498156, 'epoch': 0.37}\n",
      "{'loss': 1.3922, 'learning_rate': 0.00018620326487625067, 'epoch': 0.37}\n",
      "{'loss': 1.4937, 'learning_rate': 0.00018609794628751976, 'epoch': 0.37}\n",
      "{'loss': 1.3018, 'learning_rate': 0.00018599262769878884, 'epoch': 0.37}\n",
      "{'loss': 1.1855, 'learning_rate': 0.00018588730911005795, 'epoch': 0.38}\n",
      "{'loss': 1.1487, 'learning_rate': 0.00018578199052132703, 'epoch': 0.38}\n",
      "{'loss': 1.4253, 'learning_rate': 0.00018567667193259611, 'epoch': 0.38}\n",
      "{'loss': 1.1792, 'learning_rate': 0.0001855713533438652, 'epoch': 0.39}\n",
      "{'loss': 1.2483, 'learning_rate': 0.00018546603475513428, 'epoch': 0.39}\n",
      "{'loss': 1.2877, 'learning_rate': 0.0001853607161664034, 'epoch': 0.39}\n",
      "{'loss': 1.1466, 'learning_rate': 0.00018525539757767247, 'epoch': 0.39}\n",
      "{'loss': 1.1762, 'learning_rate': 0.00018515007898894156, 'epoch': 0.4}\n",
      "{'loss': 1.1525, 'learning_rate': 0.00018504476040021064, 'epoch': 0.4}\n",
      "{'loss': 1.1694, 'learning_rate': 0.00018493944181147972, 'epoch': 0.4}\n",
      "{'loss': 1.2535, 'learning_rate': 0.00018483412322274883, 'epoch': 0.4}\n",
      "{'loss': 1.4245, 'learning_rate': 0.0001847288046340179, 'epoch': 0.41}\n",
      "{'loss': 1.2862, 'learning_rate': 0.000184623486045287, 'epoch': 0.41}\n",
      "{'loss': 1.3968, 'learning_rate': 0.0001845181674565561, 'epoch': 0.41}\n",
      "{'loss': 1.0916, 'learning_rate': 0.00018441284886782516, 'epoch': 0.41}\n",
      "{'loss': 1.1483, 'learning_rate': 0.00018430753027909427, 'epoch': 0.42}\n",
      "{'loss': 1.2388, 'learning_rate': 0.00018420221169036335, 'epoch': 0.42}\n",
      "{'loss': 1.1647, 'learning_rate': 0.00018409689310163244, 'epoch': 0.42}\n",
      "{'loss': 1.2687, 'learning_rate': 0.00018399157451290155, 'epoch': 0.42}\n",
      "{'loss': 1.1895, 'learning_rate': 0.0001838862559241706, 'epoch': 0.43}\n",
      "{'loss': 1.044, 'learning_rate': 0.0001837809373354397, 'epoch': 0.43}\n",
      "{'loss': 1.3262, 'learning_rate': 0.0001836756187467088, 'epoch': 0.43}\n",
      "{'loss': 1.1458, 'learning_rate': 0.0001835703001579779, 'epoch': 0.43}\n",
      "{'loss': 1.0255, 'learning_rate': 0.000183464981569247, 'epoch': 0.44}\n",
      "{'loss': 1.2283, 'learning_rate': 0.00018335966298051607, 'epoch': 0.44}\n",
      "{'loss': 1.0822, 'learning_rate': 0.00018325434439178515, 'epoch': 0.44}\n",
      "{'loss': 1.2168, 'learning_rate': 0.00018314902580305424, 'epoch': 0.45}\n",
      "{'loss': 0.9307, 'learning_rate': 0.00018304370721432335, 'epoch': 0.45}\n",
      "{'loss': 1.0827, 'learning_rate': 0.00018293838862559243, 'epoch': 0.45}\n",
      "{'loss': 1.151, 'learning_rate': 0.0001828330700368615, 'epoch': 0.45}\n",
      "{'loss': 0.9498, 'learning_rate': 0.00018272775144813062, 'epoch': 0.46}\n",
      "{'loss': 1.0791, 'learning_rate': 0.00018262243285939968, 'epoch': 0.46}\n",
      "{'loss': 1.0699, 'learning_rate': 0.0001825171142706688, 'epoch': 0.46}\n",
      "{'loss': 1.2144, 'learning_rate': 0.00018241179568193787, 'epoch': 0.46}\n",
      "{'loss': 1.1517, 'learning_rate': 0.00018230647709320695, 'epoch': 0.47}\n",
      "{'loss': 1.064, 'learning_rate': 0.00018220115850447606, 'epoch': 0.47}\n",
      "{'loss': 1.1093, 'learning_rate': 0.00018209583991574515, 'epoch': 0.47}\n",
      "{'loss': 1.101, 'learning_rate': 0.00018199052132701423, 'epoch': 0.47}\n",
      "{'loss': 1.1031, 'learning_rate': 0.0001818852027382833, 'epoch': 0.48}\n",
      "{'loss': 0.9827, 'learning_rate': 0.0001817798841495524, 'epoch': 0.48}\n",
      "{'loss': 1.0376, 'learning_rate': 0.0001816745655608215, 'epoch': 0.48}\n",
      "{'loss': 1.1155, 'learning_rate': 0.0001815692469720906, 'epoch': 0.48}\n",
      "{'loss': 0.9689, 'learning_rate': 0.00018146392838335967, 'epoch': 0.49}\n",
      "{'loss': 0.958, 'learning_rate': 0.00018135860979462875, 'epoch': 0.49}\n",
      "{'loss': 0.9736, 'learning_rate': 0.00018125329120589784, 'epoch': 0.49}\n",
      "{'loss': 1.0062, 'learning_rate': 0.00018114797261716695, 'epoch': 0.5}\n",
      "{'loss': 1.1252, 'learning_rate': 0.00018104265402843603, 'epoch': 0.5}\n",
      "{'loss': 0.9832, 'learning_rate': 0.0001809373354397051, 'epoch': 0.5}\n",
      "{'loss': 1.041, 'learning_rate': 0.0001808320168509742, 'epoch': 0.5}\n",
      "{'loss': 0.9958, 'learning_rate': 0.00018072669826224328, 'epoch': 0.51}\n",
      "{'loss': 0.8976, 'learning_rate': 0.0001806213796735124, 'epoch': 0.51}\n",
      "{'loss': 1.0265, 'learning_rate': 0.00018051606108478147, 'epoch': 0.51}\n",
      "{'loss': 1.0354, 'learning_rate': 0.00018041074249605055, 'epoch': 0.51}\n",
      "{'loss': 0.92, 'learning_rate': 0.00018030542390731966, 'epoch': 0.52}\n",
      "{'loss': 1.1346, 'learning_rate': 0.00018020010531858872, 'epoch': 0.52}\n",
      "{'loss': 0.9589, 'learning_rate': 0.00018009478672985783, 'epoch': 0.52}\n",
      "{'loss': 1.0403, 'learning_rate': 0.0001799894681411269, 'epoch': 0.52}\n",
      "{'loss': 1.0558, 'learning_rate': 0.00017988414955239602, 'epoch': 0.53}\n",
      "{'loss': 0.9125, 'learning_rate': 0.0001797788309636651, 'epoch': 0.53}\n",
      "{'loss': 1.0359, 'learning_rate': 0.0001796735123749342, 'epoch': 0.53}\n",
      "{'loss': 0.8996, 'learning_rate': 0.00017956819378620327, 'epoch': 0.53}\n",
      "{'loss': 1.079, 'learning_rate': 0.00017946287519747235, 'epoch': 0.54}\n",
      "{'loss': 0.825, 'learning_rate': 0.00017935755660874146, 'epoch': 0.54}\n",
      "{'loss': 0.8611, 'learning_rate': 0.00017925223802001055, 'epoch': 0.54}\n",
      "{'loss': 0.8945, 'learning_rate': 0.00017914691943127963, 'epoch': 0.54}\n",
      "{'loss': 0.9611, 'learning_rate': 0.00017904160084254874, 'epoch': 0.55}\n",
      "{'loss': 0.8573, 'learning_rate': 0.0001789362822538178, 'epoch': 0.55}\n",
      "{'loss': 1.0539, 'learning_rate': 0.0001788309636650869, 'epoch': 0.55}\n",
      "{'loss': 0.8129, 'learning_rate': 0.000178725645076356, 'epoch': 0.56}\n",
      "{'loss': 0.8093, 'learning_rate': 0.00017862032648762507, 'epoch': 0.56}\n",
      "{'loss': 0.9364, 'learning_rate': 0.00017851500789889418, 'epoch': 0.56}\n",
      "{'loss': 0.9163, 'learning_rate': 0.00017840968931016324, 'epoch': 0.56}\n",
      "{'loss': 0.8834, 'learning_rate': 0.00017830437072143235, 'epoch': 0.57}\n",
      "{'loss': 0.8321, 'learning_rate': 0.00017819905213270143, 'epoch': 0.57}\n",
      "{'loss': 0.8598, 'learning_rate': 0.0001780937335439705, 'epoch': 0.57}\n",
      "{'loss': 0.8551, 'learning_rate': 0.00017798841495523962, 'epoch': 0.57}\n",
      "{'loss': 0.8845, 'learning_rate': 0.0001778830963665087, 'epoch': 0.58}\n",
      "{'loss': 0.884, 'learning_rate': 0.00017777777777777779, 'epoch': 0.58}\n",
      "{'loss': 1.1023, 'learning_rate': 0.00017767245918904687, 'epoch': 0.58}\n",
      "{'loss': 0.8383, 'learning_rate': 0.00017756714060031595, 'epoch': 0.58}\n",
      "{'loss': 0.8671, 'learning_rate': 0.00017746182201158506, 'epoch': 0.59}\n",
      "{'loss': 0.7822, 'learning_rate': 0.00017735650342285414, 'epoch': 0.59}\n",
      "{'loss': 0.7849, 'learning_rate': 0.00017725118483412323, 'epoch': 0.59}\n",
      "{'loss': 0.8425, 'learning_rate': 0.0001771458662453923, 'epoch': 0.59}\n",
      "{'loss': 0.7725, 'learning_rate': 0.0001770405476566614, 'epoch': 0.6}\n",
      "{'loss': 0.856, 'learning_rate': 0.0001769352290679305, 'epoch': 0.6}\n",
      "{'loss': 1.003, 'learning_rate': 0.00017682991047919959, 'epoch': 0.6}\n",
      "{'loss': 0.8738, 'learning_rate': 0.0001767245918904687, 'epoch': 0.61}\n",
      "{'loss': 0.8608, 'learning_rate': 0.00017661927330173778, 'epoch': 0.61}\n",
      "{'loss': 0.9842, 'learning_rate': 0.00017651395471300683, 'epoch': 0.61}\n",
      "{'loss': 0.8141, 'learning_rate': 0.00017640863612427594, 'epoch': 0.61}\n",
      "{'loss': 0.9491, 'learning_rate': 0.00017630331753554503, 'epoch': 0.62}\n",
      "{'loss': 0.6676, 'learning_rate': 0.00017619799894681414, 'epoch': 0.62}\n",
      "{'loss': 0.9452, 'learning_rate': 0.00017609268035808322, 'epoch': 0.62}\n",
      "{'loss': 0.7936, 'learning_rate': 0.00017598736176935228, 'epoch': 0.62}\n",
      "{'loss': 0.9098, 'learning_rate': 0.00017588204318062139, 'epoch': 0.63}\n",
      "{'loss': 0.8226, 'learning_rate': 0.00017577672459189047, 'epoch': 0.63}\n",
      "{'loss': 0.8266, 'learning_rate': 0.00017567140600315958, 'epoch': 0.63}\n",
      "{'loss': 0.7325, 'learning_rate': 0.00017556608741442866, 'epoch': 0.63}\n",
      "{'loss': 0.7798, 'learning_rate': 0.00017546076882569774, 'epoch': 0.64}\n",
      "{'loss': 0.8022, 'learning_rate': 0.00017535545023696683, 'epoch': 0.64}\n",
      "{'loss': 0.8515, 'learning_rate': 0.0001752501316482359, 'epoch': 0.64}\n",
      "{'loss': 0.8371, 'learning_rate': 0.00017514481305950502, 'epoch': 0.64}\n",
      "{'loss': 0.7639, 'learning_rate': 0.0001750394944707741, 'epoch': 0.65}\n",
      "{'loss': 0.8363, 'learning_rate': 0.00017493417588204319, 'epoch': 0.65}\n",
      "{'loss': 0.8211, 'learning_rate': 0.0001748288572933123, 'epoch': 0.65}\n",
      "{'loss': 0.7998, 'learning_rate': 0.00017472353870458135, 'epoch': 0.65}\n",
      "{'loss': 0.9762, 'learning_rate': 0.00017461822011585046, 'epoch': 0.66}\n",
      "{'loss': 0.7506, 'learning_rate': 0.00017451290152711954, 'epoch': 0.66}\n",
      "{'loss': 0.7575, 'learning_rate': 0.00017440758293838863, 'epoch': 0.66}\n",
      "{'loss': 0.7224, 'learning_rate': 0.00017430226434965774, 'epoch': 0.67}\n",
      "{'loss': 0.9079, 'learning_rate': 0.00017419694576092682, 'epoch': 0.67}\n",
      "{'loss': 0.5838, 'learning_rate': 0.0001740916271721959, 'epoch': 0.67}\n",
      "{'loss': 0.8175, 'learning_rate': 0.00017398630858346498, 'epoch': 0.67}\n",
      "{'loss': 0.8085, 'learning_rate': 0.00017388098999473407, 'epoch': 0.68}\n",
      "{'loss': 0.6593, 'learning_rate': 0.00017377567140600318, 'epoch': 0.68}\n",
      "{'loss': 0.796, 'learning_rate': 0.00017367035281727226, 'epoch': 0.68}\n",
      "{'loss': 0.8526, 'learning_rate': 0.00017356503422854134, 'epoch': 0.68}\n",
      "{'loss': 0.7667, 'learning_rate': 0.00017345971563981043, 'epoch': 0.69}\n",
      "{'loss': 0.6507, 'learning_rate': 0.0001733543970510795, 'epoch': 0.69}\n",
      "{'loss': 0.8754, 'learning_rate': 0.00017324907846234862, 'epoch': 0.69}\n",
      "{'loss': 0.6878, 'learning_rate': 0.0001731437598736177, 'epoch': 0.69}\n",
      "{'loss': 0.6634, 'learning_rate': 0.0001730384412848868, 'epoch': 0.7}\n",
      "{'loss': 0.7245, 'learning_rate': 0.00017293312269615587, 'epoch': 0.7}\n",
      "{'loss': 0.8498, 'learning_rate': 0.00017282780410742495, 'epoch': 0.7}\n",
      "{'loss': 0.6722, 'learning_rate': 0.00017272248551869406, 'epoch': 0.7}\n",
      "{'loss': 0.6511, 'learning_rate': 0.00017261716692996314, 'epoch': 0.71}\n",
      "{'loss': 0.774, 'learning_rate': 0.00017251184834123225, 'epoch': 0.71}\n",
      "{'loss': 0.6569, 'learning_rate': 0.00017240652975250134, 'epoch': 0.71}\n",
      "{'loss': 0.6971, 'learning_rate': 0.0001723012111637704, 'epoch': 0.72}\n",
      "{'loss': 0.6966, 'learning_rate': 0.0001721958925750395, 'epoch': 0.72}\n",
      "{'loss': 0.6447, 'learning_rate': 0.00017209057398630858, 'epoch': 0.72}\n",
      "{'loss': 0.577, 'learning_rate': 0.0001719852553975777, 'epoch': 0.72}\n",
      "{'loss': 0.744, 'learning_rate': 0.00017187993680884678, 'epoch': 0.73}\n",
      "{'loss': 0.627, 'learning_rate': 0.00017177461822011586, 'epoch': 0.73}\n",
      "{'loss': 0.6427, 'learning_rate': 0.00017166929963138494, 'epoch': 0.73}\n",
      "{'loss': 0.6253, 'learning_rate': 0.00017156398104265403, 'epoch': 0.73}\n",
      "{'loss': 0.8061, 'learning_rate': 0.00017145866245392314, 'epoch': 0.74}\n",
      "{'loss': 0.6509, 'learning_rate': 0.00017135334386519222, 'epoch': 0.74}\n",
      "{'loss': 0.5051, 'learning_rate': 0.0001712480252764613, 'epoch': 0.74}\n",
      "{'loss': 0.6684, 'learning_rate': 0.0001711427066877304, 'epoch': 0.74}\n",
      "{'loss': 0.6366, 'learning_rate': 0.00017103738809899947, 'epoch': 0.75}\n",
      "{'loss': 0.4785, 'learning_rate': 0.00017093206951026858, 'epoch': 0.75}\n",
      "{'loss': 0.5967, 'learning_rate': 0.00017082675092153766, 'epoch': 0.75}\n",
      "{'loss': 0.595, 'learning_rate': 0.00017072143233280674, 'epoch': 0.75}\n",
      "{'loss': 0.7449, 'learning_rate': 0.00017061611374407585, 'epoch': 0.76}\n",
      "{'loss': 0.6844, 'learning_rate': 0.0001705107951553449, 'epoch': 0.76}\n",
      "{'loss': 0.6795, 'learning_rate': 0.00017040547656661402, 'epoch': 0.76}\n",
      "{'loss': 0.519, 'learning_rate': 0.0001703001579778831, 'epoch': 0.76}\n",
      "{'loss': 0.6624, 'learning_rate': 0.00017019483938915218, 'epoch': 0.77}\n",
      "{'loss': 0.5515, 'learning_rate': 0.0001700895208004213, 'epoch': 0.77}\n",
      "{'loss': 0.6304, 'learning_rate': 0.00016998420221169038, 'epoch': 0.77}\n",
      "{'loss': 0.5603, 'learning_rate': 0.00016987888362295946, 'epoch': 0.78}\n",
      "{'loss': 0.6378, 'learning_rate': 0.00016977356503422854, 'epoch': 0.78}\n",
      "{'loss': 0.6567, 'learning_rate': 0.00016966824644549762, 'epoch': 0.78}\n",
      "{'loss': 0.6126, 'learning_rate': 0.00016956292785676673, 'epoch': 0.78}\n",
      "{'loss': 0.7631, 'learning_rate': 0.00016945760926803582, 'epoch': 0.79}\n",
      "{'loss': 0.6282, 'learning_rate': 0.00016935229067930493, 'epoch': 0.79}\n",
      "{'loss': 0.6361, 'learning_rate': 0.00016924697209057398, 'epoch': 0.79}\n",
      "{'loss': 0.7132, 'learning_rate': 0.00016914165350184307, 'epoch': 0.79}\n",
      "{'loss': 0.6237, 'learning_rate': 0.00016903633491311218, 'epoch': 0.8}\n",
      "{'loss': 0.5789, 'learning_rate': 0.00016893101632438126, 'epoch': 0.8}\n",
      "{'loss': 0.8141, 'learning_rate': 0.00016882569773565037, 'epoch': 0.8}\n",
      "{'loss': 0.7298, 'learning_rate': 0.00016872037914691945, 'epoch': 0.8}\n",
      "{'loss': 0.6573, 'learning_rate': 0.0001686150605581885, 'epoch': 0.81}\n",
      "{'loss': 0.674, 'learning_rate': 0.00016850974196945762, 'epoch': 0.81}\n",
      "{'loss': 0.634, 'learning_rate': 0.0001684044233807267, 'epoch': 0.81}\n",
      "{'loss': 0.495, 'learning_rate': 0.0001682991047919958, 'epoch': 0.81}\n",
      "{'loss': 0.6908, 'learning_rate': 0.0001681937862032649, 'epoch': 0.82}\n",
      "{'loss': 0.5495, 'learning_rate': 0.00016808846761453398, 'epoch': 0.82}\n",
      "{'loss': 0.6066, 'learning_rate': 0.00016798314902580306, 'epoch': 0.82}\n",
      "{'loss': 0.6385, 'learning_rate': 0.00016787783043707214, 'epoch': 0.83}\n",
      "{'loss': 0.6719, 'learning_rate': 0.00016777251184834125, 'epoch': 0.83}\n",
      "{'loss': 0.6452, 'learning_rate': 0.00016766719325961033, 'epoch': 0.83}\n",
      "{'loss': 0.6706, 'learning_rate': 0.00016756187467087942, 'epoch': 0.83}\n",
      "{'loss': 0.5227, 'learning_rate': 0.0001674565560821485, 'epoch': 0.84}\n",
      "{'loss': 0.6678, 'learning_rate': 0.00016735123749341758, 'epoch': 0.84}\n",
      "{'loss': 0.548, 'learning_rate': 0.0001672459189046867, 'epoch': 0.84}\n",
      "{'loss': 0.7473, 'learning_rate': 0.00016714060031595577, 'epoch': 0.84}\n",
      "{'loss': 0.6012, 'learning_rate': 0.00016703528172722486, 'epoch': 0.85}\n",
      "{'loss': 0.5729, 'learning_rate': 0.00016692996313849397, 'epoch': 0.85}\n",
      "{'loss': 0.59, 'learning_rate': 0.00016682464454976302, 'epoch': 0.85}\n",
      "{'loss': 0.5293, 'learning_rate': 0.00016671932596103213, 'epoch': 0.85}\n",
      "{'loss': 0.5075, 'learning_rate': 0.00016661400737230122, 'epoch': 0.86}\n",
      "{'loss': 0.6272, 'learning_rate': 0.0001665086887835703, 'epoch': 0.86}\n",
      "{'loss': 0.5722, 'learning_rate': 0.0001664033701948394, 'epoch': 0.86}\n",
      "{'loss': 0.5632, 'learning_rate': 0.0001662980516061085, 'epoch': 0.86}\n",
      "{'loss': 0.4219, 'learning_rate': 0.00016619273301737757, 'epoch': 0.87}\n",
      "{'loss': 0.5663, 'learning_rate': 0.00016608741442864666, 'epoch': 0.87}\n",
      "{'loss': 0.6122, 'learning_rate': 0.00016598209583991574, 'epoch': 0.87}\n",
      "{'loss': 0.5575, 'learning_rate': 0.00016587677725118485, 'epoch': 0.87}\n",
      "{'loss': 0.5009, 'learning_rate': 0.00016577145866245393, 'epoch': 0.88}\n",
      "{'loss': 0.5212, 'learning_rate': 0.00016566614007372304, 'epoch': 0.88}\n",
      "{'loss': 0.553, 'learning_rate': 0.0001655608214849921, 'epoch': 0.88}\n",
      "{'loss': 0.6231, 'learning_rate': 0.00016545550289626118, 'epoch': 0.89}\n",
      "{'loss': 0.6045, 'learning_rate': 0.0001653501843075303, 'epoch': 0.89}\n",
      "{'loss': 0.6312, 'learning_rate': 0.00016524486571879937, 'epoch': 0.89}\n",
      "{'loss': 0.566, 'learning_rate': 0.00016513954713006848, 'epoch': 0.89}\n",
      "{'loss': 0.7169, 'learning_rate': 0.00016503422854133754, 'epoch': 0.9}\n",
      "{'loss': 0.5302, 'learning_rate': 0.00016492890995260665, 'epoch': 0.9}\n",
      "{'loss': 0.5722, 'learning_rate': 0.00016482359136387573, 'epoch': 0.9}\n",
      "{'loss': 0.5597, 'learning_rate': 0.00016471827277514482, 'epoch': 0.9}\n",
      "{'loss': 0.477, 'learning_rate': 0.00016461295418641393, 'epoch': 0.91}\n",
      "{'loss': 0.5401, 'learning_rate': 0.000164507635597683, 'epoch': 0.91}\n",
      "{'loss': 0.4735, 'learning_rate': 0.0001644023170089521, 'epoch': 0.91}\n",
      "{'loss': 0.5573, 'learning_rate': 0.00016429699842022117, 'epoch': 0.91}\n",
      "{'loss': 0.5552, 'learning_rate': 0.00016419167983149026, 'epoch': 0.92}\n",
      "{'loss': 0.4953, 'learning_rate': 0.00016408636124275937, 'epoch': 0.92}\n",
      "{'loss': 0.5324, 'learning_rate': 0.00016398104265402845, 'epoch': 0.92}\n",
      "{'loss': 0.5187, 'learning_rate': 0.00016387572406529753, 'epoch': 0.92}\n",
      "{'loss': 0.5219, 'learning_rate': 0.00016377040547656661, 'epoch': 0.93}\n",
      "{'loss': 0.4734, 'learning_rate': 0.0001636650868878357, 'epoch': 0.93}\n",
      "{'loss': 0.5443, 'learning_rate': 0.0001635597682991048, 'epoch': 0.93}\n",
      "{'loss': 0.5892, 'learning_rate': 0.0001634544497103739, 'epoch': 0.94}\n",
      "{'loss': 0.6291, 'learning_rate': 0.00016334913112164297, 'epoch': 0.94}\n",
      "{'loss': 0.4297, 'learning_rate': 0.00016324381253291208, 'epoch': 0.94}\n",
      "{'loss': 0.5605, 'learning_rate': 0.00016313849394418114, 'epoch': 0.94}\n",
      "{'loss': 0.6155, 'learning_rate': 0.00016303317535545025, 'epoch': 0.95}\n",
      "{'loss': 0.5327, 'learning_rate': 0.00016292785676671933, 'epoch': 0.95}\n",
      "{'loss': 0.4324, 'learning_rate': 0.00016282253817798841, 'epoch': 0.95}\n",
      "{'loss': 0.4966, 'learning_rate': 0.00016271721958925752, 'epoch': 0.95}\n",
      "{'loss': 0.5123, 'learning_rate': 0.00016261190100052658, 'epoch': 0.96}\n",
      "{'loss': 0.5146, 'learning_rate': 0.0001625065824117957, 'epoch': 0.96}\n",
      "{'loss': 0.4172, 'learning_rate': 0.00016240126382306477, 'epoch': 0.96}\n",
      "{'loss': 0.4863, 'learning_rate': 0.00016229594523433386, 'epoch': 0.96}\n",
      "{'loss': 0.4914, 'learning_rate': 0.00016219062664560297, 'epoch': 0.97}\n",
      "{'loss': 0.451, 'learning_rate': 0.00016208530805687205, 'epoch': 0.97}\n",
      "{'loss': 0.4278, 'learning_rate': 0.00016197998946814113, 'epoch': 0.97}\n",
      "{'loss': 0.502, 'learning_rate': 0.00016187467087941021, 'epoch': 0.97}\n",
      "{'loss': 0.569, 'learning_rate': 0.0001617693522906793, 'epoch': 0.98}\n",
      "{'loss': 0.6895, 'learning_rate': 0.0001616640337019484, 'epoch': 0.98}\n",
      "{'loss': 0.5109, 'learning_rate': 0.0001615587151132175, 'epoch': 0.98}\n",
      "{'loss': 0.4923, 'learning_rate': 0.0001614533965244866, 'epoch': 0.98}\n",
      "{'loss': 0.5212, 'learning_rate': 0.00016134807793575566, 'epoch': 0.99}\n",
      "{'loss': 0.4417, 'learning_rate': 0.00016124275934702477, 'epoch': 0.99}\n",
      "{'loss': 0.4205, 'learning_rate': 0.00016113744075829385, 'epoch': 0.99}\n",
      "{'loss': 0.4831, 'learning_rate': 0.00016103212216956293, 'epoch': 1.0}\n",
      "{'loss': 0.5605, 'learning_rate': 0.00016092680358083204, 'epoch': 1.0}\n",
      "{'loss': 0.5424, 'learning_rate': 0.00016082148499210112, 'epoch': 1.0}\n",
      "{'loss': 0.4275, 'learning_rate': 0.0001607161664033702, 'epoch': 1.0}\n",
      "{'loss': 0.4472, 'learning_rate': 0.0001606108478146393, 'epoch': 1.01}\n",
      "{'loss': 0.369, 'learning_rate': 0.00016050552922590837, 'epoch': 1.01}\n",
      "{'loss': 0.3757, 'learning_rate': 0.00016040021063717748, 'epoch': 1.01}\n",
      "{'loss': 0.4238, 'learning_rate': 0.00016029489204844656, 'epoch': 1.01}\n",
      "{'loss': 0.3244, 'learning_rate': 0.00016018957345971565, 'epoch': 1.02}\n",
      "{'loss': 0.3854, 'learning_rate': 0.00016008425487098473, 'epoch': 1.02}\n",
      "{'loss': 0.3646, 'learning_rate': 0.0001599789362822538, 'epoch': 1.02}\n",
      "{'loss': 0.3914, 'learning_rate': 0.00015987361769352292, 'epoch': 1.02}\n",
      "{'loss': 0.4572, 'learning_rate': 0.000159768299104792, 'epoch': 1.03}\n",
      "{'loss': 0.3517, 'learning_rate': 0.0001596629805160611, 'epoch': 1.03}\n",
      "{'loss': 0.3408, 'learning_rate': 0.00015955766192733017, 'epoch': 1.03}\n",
      "{'loss': 0.3887, 'learning_rate': 0.00015945234333859925, 'epoch': 1.03}\n",
      "{'loss': 0.4674, 'learning_rate': 0.00015934702474986836, 'epoch': 1.04}\n",
      "{'loss': 0.4519, 'learning_rate': 0.00015924170616113745, 'epoch': 1.04}\n",
      "{'loss': 0.3504, 'learning_rate': 0.00015913638757240653, 'epoch': 1.04}\n",
      "{'loss': 0.4371, 'learning_rate': 0.00015903106898367564, 'epoch': 1.05}\n",
      "{'loss': 0.3996, 'learning_rate': 0.0001589257503949447, 'epoch': 1.05}\n",
      "{'loss': 0.4272, 'learning_rate': 0.0001588204318062138, 'epoch': 1.05}\n",
      "{'loss': 0.4127, 'learning_rate': 0.0001587151132174829, 'epoch': 1.05}\n",
      "{'loss': 0.3378, 'learning_rate': 0.00015860979462875197, 'epoch': 1.06}\n",
      "{'loss': 0.3953, 'learning_rate': 0.00015850447604002108, 'epoch': 1.06}\n",
      "{'loss': 0.4421, 'learning_rate': 0.00015839915745129016, 'epoch': 1.06}\n",
      "{'loss': 0.3288, 'learning_rate': 0.00015829383886255925, 'epoch': 1.06}\n",
      "{'loss': 0.4778, 'learning_rate': 0.00015818852027382833, 'epoch': 1.07}\n",
      "{'loss': 0.3558, 'learning_rate': 0.00015808320168509744, 'epoch': 1.07}\n",
      "{'loss': 0.4172, 'learning_rate': 0.00015797788309636652, 'epoch': 1.07}\n",
      "{'loss': 0.3666, 'learning_rate': 0.0001578725645076356, 'epoch': 1.07}\n",
      "{'loss': 0.3359, 'learning_rate': 0.00015776724591890472, 'epoch': 1.08}\n",
      "{'loss': 0.3858, 'learning_rate': 0.00015766192733017377, 'epoch': 1.08}\n",
      "{'loss': 0.4451, 'learning_rate': 0.00015755660874144288, 'epoch': 1.08}\n",
      "{'loss': 0.4127, 'learning_rate': 0.00015745129015271196, 'epoch': 1.08}\n",
      "{'loss': 0.3568, 'learning_rate': 0.00015734597156398105, 'epoch': 1.09}\n",
      "{'loss': 0.4125, 'learning_rate': 0.00015724065297525016, 'epoch': 1.09}\n",
      "{'loss': 0.3962, 'learning_rate': 0.0001571353343865192, 'epoch': 1.09}\n",
      "{'loss': 0.4811, 'learning_rate': 0.00015703001579778832, 'epoch': 1.09}\n",
      "{'loss': 0.3918, 'learning_rate': 0.0001569246972090574, 'epoch': 1.1}\n",
      "{'loss': 0.396, 'learning_rate': 0.0001568193786203265, 'epoch': 1.1}\n",
      "{'loss': 0.4547, 'learning_rate': 0.0001567140600315956, 'epoch': 1.1}\n",
      "{'loss': 0.4648, 'learning_rate': 0.00015660874144286468, 'epoch': 1.11}\n",
      "{'loss': 0.4153, 'learning_rate': 0.00015650342285413376, 'epoch': 1.11}\n",
      "{'loss': 0.5539, 'learning_rate': 0.00015639810426540285, 'epoch': 1.11}\n",
      "{'loss': 0.2878, 'learning_rate': 0.00015629278567667193, 'epoch': 1.11}\n",
      "{'loss': 0.3621, 'learning_rate': 0.00015618746708794104, 'epoch': 1.12}\n",
      "{'loss': 0.3827, 'learning_rate': 0.00015608214849921012, 'epoch': 1.12}\n",
      "{'loss': 0.3268, 'learning_rate': 0.0001559768299104792, 'epoch': 1.12}\n",
      "{'loss': 0.4168, 'learning_rate': 0.0001558715113217483, 'epoch': 1.12}\n",
      "{'loss': 0.3735, 'learning_rate': 0.00015576619273301737, 'epoch': 1.13}\n",
      "{'loss': 0.3443, 'learning_rate': 0.00015566087414428648, 'epoch': 1.13}\n",
      "{'loss': 0.3793, 'learning_rate': 0.00015555555555555556, 'epoch': 1.13}\n",
      "{'loss': 0.4453, 'learning_rate': 0.00015545023696682465, 'epoch': 1.13}\n",
      "{'loss': 0.405, 'learning_rate': 0.00015534491837809376, 'epoch': 1.14}\n",
      "{'loss': 0.3679, 'learning_rate': 0.0001552395997893628, 'epoch': 1.14}\n",
      "{'loss': 0.3485, 'learning_rate': 0.00015513428120063192, 'epoch': 1.14}\n",
      "{'loss': 0.3778, 'learning_rate': 0.000155028962611901, 'epoch': 1.14}\n",
      "{'loss': 0.4327, 'learning_rate': 0.0001549236440231701, 'epoch': 1.15}\n",
      "{'loss': 0.2829, 'learning_rate': 0.0001548183254344392, 'epoch': 1.15}\n",
      "{'loss': 0.3675, 'learning_rate': 0.00015471300684570828, 'epoch': 1.15}\n",
      "{'loss': 0.4335, 'learning_rate': 0.00015460768825697736, 'epoch': 1.16}\n",
      "{'loss': 0.4806, 'learning_rate': 0.00015450236966824645, 'epoch': 1.16}\n",
      "{'loss': 0.4068, 'learning_rate': 0.00015439705107951556, 'epoch': 1.16}\n",
      "{'loss': 0.3542, 'learning_rate': 0.00015429173249078464, 'epoch': 1.16}\n",
      "{'loss': 0.4676, 'learning_rate': 0.00015418641390205372, 'epoch': 1.17}\n",
      "{'loss': 0.2907, 'learning_rate': 0.0001540810953133228, 'epoch': 1.17}\n",
      "{'loss': 0.3778, 'learning_rate': 0.0001539757767245919, 'epoch': 1.17}\n",
      "{'loss': 0.4207, 'learning_rate': 0.000153870458135861, 'epoch': 1.17}\n",
      "{'loss': 0.3099, 'learning_rate': 0.00015376513954713008, 'epoch': 1.18}\n",
      "{'loss': 0.4879, 'learning_rate': 0.00015365982095839916, 'epoch': 1.18}\n",
      "{'loss': 0.3444, 'learning_rate': 0.00015355450236966827, 'epoch': 1.18}\n",
      "{'loss': 0.2962, 'learning_rate': 0.00015344918378093733, 'epoch': 1.18}\n",
      "{'loss': 0.3406, 'learning_rate': 0.00015334386519220644, 'epoch': 1.19}\n",
      "{'loss': 0.3338, 'learning_rate': 0.00015323854660347552, 'epoch': 1.19}\n",
      "{'loss': 0.3042, 'learning_rate': 0.0001531332280147446, 'epoch': 1.19}\n",
      "{'loss': 0.309, 'learning_rate': 0.0001530279094260137, 'epoch': 1.19}\n",
      "{'loss': 0.378, 'learning_rate': 0.0001529225908372828, 'epoch': 1.2}\n",
      "{'loss': 0.3651, 'learning_rate': 0.00015281727224855188, 'epoch': 1.2}\n",
      "{'loss': 0.2779, 'learning_rate': 0.00015271195365982096, 'epoch': 1.2}\n",
      "{'loss': 0.3178, 'learning_rate': 0.00015260663507109004, 'epoch': 1.2}\n",
      "{'loss': 0.4445, 'learning_rate': 0.00015250131648235915, 'epoch': 1.21}\n",
      "{'loss': 0.3276, 'learning_rate': 0.00015239599789362824, 'epoch': 1.21}\n",
      "{'loss': 0.3522, 'learning_rate': 0.00015229067930489732, 'epoch': 1.21}\n",
      "{'loss': 0.3256, 'learning_rate': 0.0001521853607161664, 'epoch': 1.22}\n",
      "{'loss': 0.2953, 'learning_rate': 0.00015208004212743549, 'epoch': 1.22}\n",
      "{'loss': 0.326, 'learning_rate': 0.0001519747235387046, 'epoch': 1.22}\n",
      "{'loss': 0.3108, 'learning_rate': 0.00015186940494997368, 'epoch': 1.22}\n",
      "{'loss': 0.3521, 'learning_rate': 0.00015176408636124276, 'epoch': 1.23}\n",
      "{'loss': 0.3094, 'learning_rate': 0.00015165876777251184, 'epoch': 1.23}\n",
      "{'loss': 0.4365, 'learning_rate': 0.00015155344918378093, 'epoch': 1.23}\n",
      "{'loss': 0.3458, 'learning_rate': 0.00015144813059505004, 'epoch': 1.23}\n",
      "{'loss': 0.3715, 'learning_rate': 0.00015134281200631912, 'epoch': 1.24}\n",
      "{'loss': 0.3384, 'learning_rate': 0.00015123749341758823, 'epoch': 1.24}\n",
      "{'loss': 0.4376, 'learning_rate': 0.0001511321748288573, 'epoch': 1.24}\n",
      "{'loss': 0.3575, 'learning_rate': 0.00015102685624012637, 'epoch': 1.24}\n",
      "{'loss': 0.3786, 'learning_rate': 0.00015092153765139548, 'epoch': 1.25}\n",
      "{'loss': 0.3162, 'learning_rate': 0.00015081621906266456, 'epoch': 1.25}\n",
      "{'loss': 0.2951, 'learning_rate': 0.00015071090047393367, 'epoch': 1.25}\n",
      "{'loss': 0.3027, 'learning_rate': 0.00015060558188520275, 'epoch': 1.25}\n",
      "{'loss': 0.3238, 'learning_rate': 0.00015050026329647184, 'epoch': 1.26}\n",
      "{'loss': 0.3356, 'learning_rate': 0.00015039494470774092, 'epoch': 1.26}\n",
      "{'loss': 0.2841, 'learning_rate': 0.00015028962611901, 'epoch': 1.26}\n",
      "{'loss': 0.2963, 'learning_rate': 0.0001501843075302791, 'epoch': 1.27}\n",
      "{'loss': 0.2561, 'learning_rate': 0.0001500789889415482, 'epoch': 1.27}\n",
      "{'loss': 0.4053, 'learning_rate': 0.00014997367035281728, 'epoch': 1.27}\n",
      "{'loss': 0.3653, 'learning_rate': 0.0001498683517640864, 'epoch': 1.27}\n",
      "{'loss': 0.3263, 'learning_rate': 0.00014976303317535544, 'epoch': 1.28}\n",
      "{'loss': 0.3295, 'learning_rate': 0.00014965771458662455, 'epoch': 1.28}\n",
      "{'loss': 0.2993, 'learning_rate': 0.00014955239599789364, 'epoch': 1.28}\n",
      "{'loss': 0.3013, 'learning_rate': 0.00014944707740916272, 'epoch': 1.28}\n",
      "{'loss': 0.2653, 'learning_rate': 0.00014934175882043183, 'epoch': 1.29}\n",
      "{'loss': 0.3938, 'learning_rate': 0.00014923644023170088, 'epoch': 1.29}\n",
      "{'loss': 0.2901, 'learning_rate': 0.00014913112164297, 'epoch': 1.29}\n",
      "{'loss': 0.2988, 'learning_rate': 0.00014902580305423908, 'epoch': 1.29}\n",
      "{'loss': 0.3766, 'learning_rate': 0.00014892048446550816, 'epoch': 1.3}\n",
      "{'loss': 0.3501, 'learning_rate': 0.00014881516587677727, 'epoch': 1.3}\n",
      "{'loss': 0.3544, 'learning_rate': 0.00014870984728804635, 'epoch': 1.3}\n",
      "{'loss': 0.3005, 'learning_rate': 0.00014860452869931544, 'epoch': 1.3}\n",
      "{'loss': 0.3254, 'learning_rate': 0.00014849921011058452, 'epoch': 1.31}\n",
      "{'loss': 0.2478, 'learning_rate': 0.0001483938915218536, 'epoch': 1.31}\n",
      "{'loss': 0.3424, 'learning_rate': 0.0001482885729331227, 'epoch': 1.31}\n",
      "{'loss': 0.3005, 'learning_rate': 0.0001481832543443918, 'epoch': 1.31}\n",
      "{'loss': 0.2691, 'learning_rate': 0.00014807793575566088, 'epoch': 1.32}\n",
      "{'loss': 0.2963, 'learning_rate': 0.00014797261716692996, 'epoch': 1.32}\n",
      "{'loss': 0.2726, 'learning_rate': 0.00014786729857819904, 'epoch': 1.32}\n",
      "{'loss': 0.3677, 'learning_rate': 0.00014776197998946815, 'epoch': 1.33}\n",
      "{'loss': 0.2705, 'learning_rate': 0.00014765666140073724, 'epoch': 1.33}\n",
      "{'loss': 0.2996, 'learning_rate': 0.00014755134281200635, 'epoch': 1.33}\n",
      "{'loss': 0.3903, 'learning_rate': 0.00014744602422327543, 'epoch': 1.33}\n",
      "{'loss': 0.3, 'learning_rate': 0.00014734070563454448, 'epoch': 1.34}\n",
      "{'loss': 0.3145, 'learning_rate': 0.0001472353870458136, 'epoch': 1.34}\n",
      "{'loss': 0.2455, 'learning_rate': 0.00014713006845708268, 'epoch': 1.34}\n",
      "{'loss': 0.4312, 'learning_rate': 0.0001470247498683518, 'epoch': 1.34}\n",
      "{'loss': 0.2477, 'learning_rate': 0.00014691943127962087, 'epoch': 1.35}\n",
      "{'loss': 0.3463, 'learning_rate': 0.00014681411269088995, 'epoch': 1.35}\n",
      "{'loss': 0.3345, 'learning_rate': 0.00014670879410215904, 'epoch': 1.35}\n",
      "{'loss': 0.2965, 'learning_rate': 0.00014660347551342812, 'epoch': 1.35}\n",
      "{'loss': 0.3444, 'learning_rate': 0.00014649815692469723, 'epoch': 1.36}\n",
      "{'loss': 0.3238, 'learning_rate': 0.0001463928383359663, 'epoch': 1.36}\n",
      "{'loss': 0.2885, 'learning_rate': 0.0001462875197472354, 'epoch': 1.36}\n",
      "{'loss': 0.2986, 'learning_rate': 0.00014618220115850448, 'epoch': 1.36}\n",
      "{'loss': 0.2752, 'learning_rate': 0.00014607688256977356, 'epoch': 1.37}\n",
      "{'loss': 0.3305, 'learning_rate': 0.00014597156398104267, 'epoch': 1.37}\n",
      "{'loss': 0.3052, 'learning_rate': 0.00014586624539231175, 'epoch': 1.37}\n",
      "{'loss': 0.2903, 'learning_rate': 0.00014576092680358083, 'epoch': 1.38}\n",
      "{'loss': 0.3177, 'learning_rate': 0.00014565560821484994, 'epoch': 1.38}\n",
      "{'loss': 0.3743, 'learning_rate': 0.000145550289626119, 'epoch': 1.38}\n",
      "{'loss': 0.3581, 'learning_rate': 0.0001454449710373881, 'epoch': 1.38}\n",
      "{'loss': 0.2997, 'learning_rate': 0.0001453396524486572, 'epoch': 1.39}\n",
      "{'loss': 0.3575, 'learning_rate': 0.00014523433385992628, 'epoch': 1.39}\n",
      "{'loss': 0.2672, 'learning_rate': 0.00014512901527119539, 'epoch': 1.39}\n",
      "{'loss': 0.2341, 'learning_rate': 0.00014502369668246447, 'epoch': 1.39}\n",
      "{'loss': 0.3853, 'learning_rate': 0.00014491837809373355, 'epoch': 1.4}\n",
      "{'loss': 0.2955, 'learning_rate': 0.00014481305950500263, 'epoch': 1.4}\n",
      "{'loss': 0.2222, 'learning_rate': 0.00014470774091627172, 'epoch': 1.4}\n",
      "{'loss': 0.2753, 'learning_rate': 0.00014460242232754083, 'epoch': 1.4}\n",
      "{'loss': 0.2434, 'learning_rate': 0.0001444971037388099, 'epoch': 1.41}\n",
      "{'loss': 0.2581, 'learning_rate': 0.00014439178515007902, 'epoch': 1.41}\n",
      "{'loss': 0.3478, 'learning_rate': 0.00014428646656134808, 'epoch': 1.41}\n",
      "{'loss': 0.3342, 'learning_rate': 0.00014418114797261716, 'epoch': 1.41}\n",
      "{'loss': 0.3466, 'learning_rate': 0.00014407582938388627, 'epoch': 1.42}\n",
      "{'loss': 0.2966, 'learning_rate': 0.00014397051079515535, 'epoch': 1.42}\n",
      "{'loss': 0.2973, 'learning_rate': 0.00014386519220642446, 'epoch': 1.42}\n",
      "{'loss': 0.3161, 'learning_rate': 0.00014375987361769352, 'epoch': 1.42}\n",
      "{'loss': 0.2862, 'learning_rate': 0.0001436545550289626, 'epoch': 1.43}\n",
      "{'loss': 0.3363, 'learning_rate': 0.0001435492364402317, 'epoch': 1.43}\n",
      "{'loss': 0.3588, 'learning_rate': 0.0001434439178515008, 'epoch': 1.43}\n",
      "{'loss': 0.3465, 'learning_rate': 0.0001433385992627699, 'epoch': 1.44}\n",
      "{'loss': 0.2698, 'learning_rate': 0.00014323328067403899, 'epoch': 1.44}\n",
      "{'loss': 0.2827, 'learning_rate': 0.00014312796208530804, 'epoch': 1.44}\n",
      "{'loss': 0.3238, 'learning_rate': 0.00014302264349657715, 'epoch': 1.44}\n",
      "{'loss': 0.2809, 'learning_rate': 0.00014291732490784623, 'epoch': 1.45}\n",
      "{'loss': 0.2556, 'learning_rate': 0.00014281200631911534, 'epoch': 1.45}\n",
      "{'loss': 0.2262, 'learning_rate': 0.00014270668773038443, 'epoch': 1.45}\n",
      "{'loss': 0.2254, 'learning_rate': 0.0001426013691416535, 'epoch': 1.45}\n",
      "{'loss': 0.212, 'learning_rate': 0.0001424960505529226, 'epoch': 1.46}\n",
      "{'loss': 0.2954, 'learning_rate': 0.00014239073196419167, 'epoch': 1.46}\n",
      "{'loss': 0.3567, 'learning_rate': 0.00014228541337546078, 'epoch': 1.46}\n",
      "{'loss': 0.3028, 'learning_rate': 0.00014218009478672987, 'epoch': 1.46}\n",
      "{'loss': 0.3629, 'learning_rate': 0.00014207477619799895, 'epoch': 1.47}\n",
      "{'loss': 0.2039, 'learning_rate': 0.00014196945760926806, 'epoch': 1.47}\n",
      "{'loss': 0.3249, 'learning_rate': 0.00014186413902053712, 'epoch': 1.47}\n",
      "{'loss': 0.2324, 'learning_rate': 0.00014175882043180623, 'epoch': 1.47}\n",
      "{'loss': 0.2651, 'learning_rate': 0.0001416535018430753, 'epoch': 1.48}\n",
      "{'loss': 0.3167, 'learning_rate': 0.0001415481832543444, 'epoch': 1.48}\n",
      "{'loss': 0.2274, 'learning_rate': 0.0001414428646656135, 'epoch': 1.48}\n",
      "{'loss': 0.3001, 'learning_rate': 0.00014133754607688258, 'epoch': 1.49}\n",
      "{'loss': 0.333, 'learning_rate': 0.00014123222748815167, 'epoch': 1.49}\n",
      "{'loss': 0.2451, 'learning_rate': 0.00014112690889942075, 'epoch': 1.49}\n",
      "{'loss': 0.2911, 'learning_rate': 0.00014102159031068983, 'epoch': 1.49}\n",
      "{'loss': 0.3623, 'learning_rate': 0.00014091627172195894, 'epoch': 1.5}\n",
      "{'loss': 0.2719, 'learning_rate': 0.00014081095313322803, 'epoch': 1.5}\n",
      "{'loss': 0.1965, 'learning_rate': 0.0001407056345444971, 'epoch': 1.5}\n",
      "{'loss': 0.2655, 'learning_rate': 0.0001406003159557662, 'epoch': 1.5}\n",
      "{'loss': 0.2781, 'learning_rate': 0.00014049499736703527, 'epoch': 1.51}\n",
      "{'loss': 0.2613, 'learning_rate': 0.00014038967877830438, 'epoch': 1.51}\n",
      "{'loss': 0.3028, 'learning_rate': 0.00014028436018957347, 'epoch': 1.51}\n",
      "{'loss': 0.3069, 'learning_rate': 0.00014017904160084258, 'epoch': 1.51}\n",
      "{'loss': 0.2235, 'learning_rate': 0.00014007372301211163, 'epoch': 1.52}\n",
      "{'loss': 0.2172, 'learning_rate': 0.00013996840442338072, 'epoch': 1.52}\n",
      "{'loss': 0.2803, 'learning_rate': 0.00013986308583464983, 'epoch': 1.52}\n",
      "{'loss': 0.3167, 'learning_rate': 0.0001397577672459189, 'epoch': 1.52}\n",
      "{'loss': 0.2277, 'learning_rate': 0.00013965244865718802, 'epoch': 1.53}\n",
      "{'loss': 0.2889, 'learning_rate': 0.0001395471300684571, 'epoch': 1.53}\n",
      "{'loss': 0.2159, 'learning_rate': 0.00013944181147972616, 'epoch': 1.53}\n",
      "{'loss': 0.2551, 'learning_rate': 0.00013933649289099527, 'epoch': 1.53}\n",
      "{'loss': 0.2358, 'learning_rate': 0.00013923117430226435, 'epoch': 1.54}\n",
      "{'loss': 0.2611, 'learning_rate': 0.00013912585571353346, 'epoch': 1.54}\n",
      "{'loss': 0.3307, 'learning_rate': 0.00013902053712480254, 'epoch': 1.54}\n",
      "{'loss': 0.2471, 'learning_rate': 0.00013891521853607162, 'epoch': 1.55}\n",
      "{'loss': 0.2371, 'learning_rate': 0.0001388098999473407, 'epoch': 1.55}\n",
      "{'loss': 0.2365, 'learning_rate': 0.0001387045813586098, 'epoch': 1.55}\n",
      "{'loss': 0.2729, 'learning_rate': 0.0001385992627698789, 'epoch': 1.55}\n",
      "{'loss': 0.2302, 'learning_rate': 0.00013849394418114798, 'epoch': 1.56}\n",
      "{'loss': 0.2428, 'learning_rate': 0.00013838862559241707, 'epoch': 1.56}\n",
      "{'loss': 0.2731, 'learning_rate': 0.00013828330700368615, 'epoch': 1.56}\n",
      "{'loss': 0.2254, 'learning_rate': 0.00013817798841495523, 'epoch': 1.56}\n",
      "{'loss': 0.4103, 'learning_rate': 0.00013807266982622434, 'epoch': 1.57}\n",
      "{'loss': 0.2499, 'learning_rate': 0.00013796735123749342, 'epoch': 1.57}\n",
      "{'loss': 0.2257, 'learning_rate': 0.0001378620326487625, 'epoch': 1.57}\n",
      "{'loss': 0.2075, 'learning_rate': 0.00013775671406003162, 'epoch': 1.57}\n",
      "{'loss': 0.2355, 'learning_rate': 0.00013765139547130067, 'epoch': 1.58}\n",
      "{'loss': 0.3213, 'learning_rate': 0.00013754607688256978, 'epoch': 1.58}\n",
      "{'loss': 0.255, 'learning_rate': 0.00013744075829383887, 'epoch': 1.58}\n",
      "{'loss': 0.2145, 'learning_rate': 0.00013733543970510795, 'epoch': 1.58}\n",
      "{'loss': 0.3218, 'learning_rate': 0.00013723012111637706, 'epoch': 1.59}\n",
      "{'loss': 0.2065, 'learning_rate': 0.00013712480252764614, 'epoch': 1.59}\n",
      "{'loss': 0.2303, 'learning_rate': 0.00013701948393891522, 'epoch': 1.59}\n",
      "{'loss': 0.2216, 'learning_rate': 0.0001369141653501843, 'epoch': 1.6}\n",
      "{'loss': 0.3573, 'learning_rate': 0.0001368088467614534, 'epoch': 1.6}\n",
      "{'loss': 0.3314, 'learning_rate': 0.0001367035281727225, 'epoch': 1.6}\n",
      "{'loss': 0.1613, 'learning_rate': 0.00013659820958399158, 'epoch': 1.6}\n",
      "{'loss': 0.2788, 'learning_rate': 0.0001364928909952607, 'epoch': 1.61}\n",
      "{'loss': 0.253, 'learning_rate': 0.00013638757240652975, 'epoch': 1.61}\n",
      "{'loss': 0.2464, 'learning_rate': 0.00013628225381779883, 'epoch': 1.61}\n",
      "{'loss': 0.2294, 'learning_rate': 0.00013617693522906794, 'epoch': 1.61}\n",
      "{'loss': 0.2319, 'learning_rate': 0.00013607161664033702, 'epoch': 1.62}\n",
      "{'loss': 0.295, 'learning_rate': 0.00013596629805160613, 'epoch': 1.62}\n",
      "{'loss': 0.2217, 'learning_rate': 0.0001358609794628752, 'epoch': 1.62}\n",
      "{'loss': 0.1823, 'learning_rate': 0.0001357556608741443, 'epoch': 1.62}\n",
      "{'loss': 0.2456, 'learning_rate': 0.00013565034228541338, 'epoch': 1.63}\n",
      "{'loss': 0.2038, 'learning_rate': 0.00013554502369668246, 'epoch': 1.63}\n",
      "{'loss': 0.1761, 'learning_rate': 0.00013543970510795157, 'epoch': 1.63}\n",
      "{'loss': 0.2058, 'learning_rate': 0.00013533438651922066, 'epoch': 1.63}\n",
      "{'loss': 0.3149, 'learning_rate': 0.00013522906793048974, 'epoch': 1.64}\n",
      "{'loss': 0.2666, 'learning_rate': 0.00013512374934175882, 'epoch': 1.64}\n",
      "{'loss': 0.157, 'learning_rate': 0.0001350184307530279, 'epoch': 1.64}\n",
      "{'loss': 0.2463, 'learning_rate': 0.00013491311216429702, 'epoch': 1.64}\n",
      "{'loss': 0.1787, 'learning_rate': 0.0001348077935755661, 'epoch': 1.65}\n",
      "{'loss': 0.3036, 'learning_rate': 0.00013470247498683518, 'epoch': 1.65}\n",
      "{'loss': 0.2009, 'learning_rate': 0.00013459715639810426, 'epoch': 1.65}\n",
      "{'loss': 0.2796, 'learning_rate': 0.00013449183780937335, 'epoch': 1.66}\n",
      "{'loss': 0.234, 'learning_rate': 0.00013438651922064246, 'epoch': 1.66}\n",
      "{'loss': 0.2293, 'learning_rate': 0.00013428120063191154, 'epoch': 1.66}\n",
      "{'loss': 0.2505, 'learning_rate': 0.00013417588204318062, 'epoch': 1.66}\n",
      "{'loss': 0.2734, 'learning_rate': 0.00013407056345444973, 'epoch': 1.67}\n",
      "{'loss': 0.2869, 'learning_rate': 0.0001339652448657188, 'epoch': 1.67}\n",
      "{'loss': 0.2919, 'learning_rate': 0.0001338599262769879, 'epoch': 1.67}\n",
      "{'loss': 0.2496, 'learning_rate': 0.00013375460768825698, 'epoch': 1.67}\n",
      "{'loss': 0.2118, 'learning_rate': 0.00013364928909952606, 'epoch': 1.68}\n",
      "{'loss': 0.283, 'learning_rate': 0.00013354397051079517, 'epoch': 1.68}\n",
      "{'loss': 0.246, 'learning_rate': 0.00013343865192206426, 'epoch': 1.68}\n",
      "{'loss': 0.1963, 'learning_rate': 0.00013333333333333334, 'epoch': 1.68}\n",
      "{'loss': 0.2496, 'learning_rate': 0.00013322801474460242, 'epoch': 1.69}\n",
      "{'loss': 0.2328, 'learning_rate': 0.0001331226961558715, 'epoch': 1.69}\n",
      "{'loss': 0.2225, 'learning_rate': 0.00013301737756714062, 'epoch': 1.69}\n",
      "{'loss': 0.2064, 'learning_rate': 0.0001329120589784097, 'epoch': 1.69}\n",
      "{'loss': 0.246, 'learning_rate': 0.00013280674038967878, 'epoch': 1.7}\n",
      "{'loss': 0.2103, 'learning_rate': 0.00013270142180094786, 'epoch': 1.7}\n",
      "{'loss': 0.2744, 'learning_rate': 0.00013259610321221695, 'epoch': 1.7}\n",
      "{'loss': 0.2314, 'learning_rate': 0.00013249078462348606, 'epoch': 1.71}\n",
      "{'loss': 0.2231, 'learning_rate': 0.00013238546603475514, 'epoch': 1.71}\n",
      "{'loss': 0.3033, 'learning_rate': 0.00013228014744602425, 'epoch': 1.71}\n",
      "{'loss': 0.1751, 'learning_rate': 0.0001321748288572933, 'epoch': 1.71}\n",
      "{'loss': 0.2378, 'learning_rate': 0.00013206951026856241, 'epoch': 1.72}\n",
      "{'loss': 0.231, 'learning_rate': 0.0001319641916798315, 'epoch': 1.72}\n",
      "{'loss': 0.2856, 'learning_rate': 0.00013185887309110058, 'epoch': 1.72}\n",
      "{'loss': 0.2275, 'learning_rate': 0.0001317535545023697, 'epoch': 1.72}\n",
      "{'loss': 0.2625, 'learning_rate': 0.00013164823591363877, 'epoch': 1.73}\n",
      "{'loss': 0.1764, 'learning_rate': 0.00013154291732490786, 'epoch': 1.73}\n",
      "{'loss': 0.2231, 'learning_rate': 0.00013143759873617694, 'epoch': 1.73}\n",
      "{'loss': 0.2605, 'learning_rate': 0.00013133228014744602, 'epoch': 1.73}\n",
      "{'loss': 0.1627, 'learning_rate': 0.00013122696155871513, 'epoch': 1.74}\n",
      "{'loss': 0.2871, 'learning_rate': 0.00013112164296998421, 'epoch': 1.74}\n",
      "{'loss': 0.2122, 'learning_rate': 0.0001310163243812533, 'epoch': 1.74}\n",
      "{'loss': 0.211, 'learning_rate': 0.00013091100579252238, 'epoch': 1.74}\n",
      "{'loss': 0.3109, 'learning_rate': 0.00013080568720379146, 'epoch': 1.75}\n",
      "{'loss': 0.2682, 'learning_rate': 0.00013070036861506057, 'epoch': 1.75}\n",
      "{'loss': 0.3007, 'learning_rate': 0.00013059505002632966, 'epoch': 1.75}\n",
      "{'loss': 0.1814, 'learning_rate': 0.00013048973143759874, 'epoch': 1.75}\n",
      "{'loss': 0.2934, 'learning_rate': 0.00013038441284886782, 'epoch': 1.76}\n",
      "{'loss': 0.2251, 'learning_rate': 0.0001302790942601369, 'epoch': 1.76}\n",
      "{'loss': 0.329, 'learning_rate': 0.00013017377567140601, 'epoch': 1.76}\n",
      "{'loss': 0.2153, 'learning_rate': 0.0001300684570826751, 'epoch': 1.77}\n",
      "{'loss': 0.2021, 'learning_rate': 0.00012996313849394418, 'epoch': 1.77}\n",
      "{'loss': 0.2124, 'learning_rate': 0.0001298578199052133, 'epoch': 1.77}\n",
      "{'loss': 0.2326, 'learning_rate': 0.00012975250131648235, 'epoch': 1.77}\n",
      "{'loss': 0.2441, 'learning_rate': 0.00012964718272775146, 'epoch': 1.78}\n",
      "{'loss': 0.2766, 'learning_rate': 0.00012954186413902054, 'epoch': 1.78}\n",
      "{'loss': 0.2119, 'learning_rate': 0.00012943654555028962, 'epoch': 1.78}\n",
      "{'loss': 0.3319, 'learning_rate': 0.00012933122696155873, 'epoch': 1.78}\n",
      "{'loss': 0.2088, 'learning_rate': 0.00012922590837282781, 'epoch': 1.79}\n",
      "{'loss': 0.168, 'learning_rate': 0.0001291205897840969, 'epoch': 1.79}\n",
      "{'loss': 0.2159, 'learning_rate': 0.00012901527119536598, 'epoch': 1.79}\n",
      "{'loss': 0.2468, 'learning_rate': 0.0001289099526066351, 'epoch': 1.79}\n",
      "{'loss': 0.2261, 'learning_rate': 0.00012880463401790417, 'epoch': 1.8}\n",
      "{'loss': 0.253, 'learning_rate': 0.00012869931542917325, 'epoch': 1.8}\n",
      "{'loss': 0.2116, 'learning_rate': 0.00012859399684044236, 'epoch': 1.8}\n",
      "{'loss': 0.2235, 'learning_rate': 0.00012848867825171142, 'epoch': 1.8}\n",
      "{'loss': 0.2024, 'learning_rate': 0.00012838335966298053, 'epoch': 1.81}\n",
      "{'loss': 0.2163, 'learning_rate': 0.0001282780410742496, 'epoch': 1.81}\n",
      "{'loss': 0.2701, 'learning_rate': 0.0001281727224855187, 'epoch': 1.81}\n",
      "{'loss': 0.2274, 'learning_rate': 0.0001280674038967878, 'epoch': 1.82}\n",
      "{'loss': 0.218, 'learning_rate': 0.00012796208530805686, 'epoch': 1.82}\n",
      "{'loss': 0.2283, 'learning_rate': 0.00012785676671932597, 'epoch': 1.82}\n",
      "{'loss': 0.2255, 'learning_rate': 0.00012775144813059505, 'epoch': 1.82}\n",
      "{'loss': 0.2082, 'learning_rate': 0.00012764612954186414, 'epoch': 1.83}\n",
      "{'loss': 0.2317, 'learning_rate': 0.00012754081095313325, 'epoch': 1.83}\n",
      "{'loss': 0.1541, 'learning_rate': 0.00012743549236440233, 'epoch': 1.83}\n",
      "{'loss': 0.2803, 'learning_rate': 0.0001273301737756714, 'epoch': 1.83}\n",
      "{'loss': 0.2105, 'learning_rate': 0.0001272248551869405, 'epoch': 1.84}\n",
      "{'loss': 0.2055, 'learning_rate': 0.00012711953659820958, 'epoch': 1.84}\n",
      "{'loss': 0.2154, 'learning_rate': 0.0001270142180094787, 'epoch': 1.84}\n",
      "{'loss': 0.2461, 'learning_rate': 0.00012690889942074777, 'epoch': 1.84}\n",
      "{'loss': 0.2723, 'learning_rate': 0.00012680358083201685, 'epoch': 1.85}\n",
      "{'loss': 0.2124, 'learning_rate': 0.00012669826224328594, 'epoch': 1.85}\n",
      "{'loss': 0.2048, 'learning_rate': 0.00012659294365455502, 'epoch': 1.85}\n",
      "{'loss': 0.2866, 'learning_rate': 0.00012648762506582413, 'epoch': 1.85}\n",
      "{'loss': 0.1699, 'learning_rate': 0.0001263823064770932, 'epoch': 1.86}\n",
      "{'loss': 0.2317, 'learning_rate': 0.0001262769878883623, 'epoch': 1.86}\n",
      "{'loss': 0.1808, 'learning_rate': 0.0001261716692996314, 'epoch': 1.86}\n",
      "{'loss': 0.244, 'learning_rate': 0.00012606635071090046, 'epoch': 1.86}\n",
      "{'loss': 0.2187, 'learning_rate': 0.00012596103212216957, 'epoch': 1.87}\n",
      "{'loss': 0.1416, 'learning_rate': 0.00012585571353343865, 'epoch': 1.87}\n",
      "{'loss': 0.2815, 'learning_rate': 0.00012575039494470774, 'epoch': 1.87}\n",
      "{'loss': 0.1719, 'learning_rate': 0.00012564507635597685, 'epoch': 1.88}\n",
      "{'loss': 0.2843, 'learning_rate': 0.00012553975776724593, 'epoch': 1.88}\n",
      "{'loss': 0.285, 'learning_rate': 0.000125434439178515, 'epoch': 1.88}\n",
      "{'loss': 0.2303, 'learning_rate': 0.0001253291205897841, 'epoch': 1.88}\n",
      "{'loss': 0.2735, 'learning_rate': 0.0001252238020010532, 'epoch': 1.89}\n",
      "{'loss': 0.1718, 'learning_rate': 0.0001251184834123223, 'epoch': 1.89}\n",
      "{'loss': 0.2741, 'learning_rate': 0.00012501316482359137, 'epoch': 1.89}\n",
      "{'loss': 0.1774, 'learning_rate': 0.00012490784623486045, 'epoch': 1.89}\n",
      "{'loss': 0.1875, 'learning_rate': 0.00012480252764612954, 'epoch': 1.9}\n",
      "{'loss': 0.1662, 'learning_rate': 0.00012469720905739865, 'epoch': 1.9}\n",
      "{'loss': 0.2007, 'learning_rate': 0.00012459189046866773, 'epoch': 1.9}\n",
      "{'loss': 0.2439, 'learning_rate': 0.0001244865718799368, 'epoch': 1.9}\n",
      "{'loss': 0.1426, 'learning_rate': 0.00012438125329120592, 'epoch': 1.91}\n",
      "{'loss': 0.1907, 'learning_rate': 0.00012427593470247498, 'epoch': 1.91}\n",
      "{'loss': 0.184, 'learning_rate': 0.0001241706161137441, 'epoch': 1.91}\n",
      "{'loss': 0.2409, 'learning_rate': 0.00012406529752501317, 'epoch': 1.91}\n",
      "{'loss': 0.1628, 'learning_rate': 0.00012395997893628225, 'epoch': 1.92}\n",
      "{'loss': 0.2387, 'learning_rate': 0.00012385466034755136, 'epoch': 1.92}\n",
      "{'loss': 0.1652, 'learning_rate': 0.00012374934175882045, 'epoch': 1.92}\n",
      "{'loss': 0.1725, 'learning_rate': 0.00012364402317008953, 'epoch': 1.93}\n",
      "{'loss': 0.244, 'learning_rate': 0.0001235387045813586, 'epoch': 1.93}\n",
      "{'loss': 0.1709, 'learning_rate': 0.0001234333859926277, 'epoch': 1.93}\n",
      "{'loss': 0.2075, 'learning_rate': 0.0001233280674038968, 'epoch': 1.93}\n",
      "{'loss': 0.2727, 'learning_rate': 0.0001232227488151659, 'epoch': 1.94}\n",
      "{'loss': 0.2859, 'learning_rate': 0.00012311743022643497, 'epoch': 1.94}\n",
      "{'loss': 0.1842, 'learning_rate': 0.00012301211163770405, 'epoch': 1.94}\n",
      "{'loss': 0.2178, 'learning_rate': 0.00012290679304897314, 'epoch': 1.94}\n",
      "{'loss': 0.1611, 'learning_rate': 0.00012280147446024225, 'epoch': 1.95}\n",
      "{'loss': 0.255, 'learning_rate': 0.00012269615587151133, 'epoch': 1.95}\n",
      "{'loss': 0.2268, 'learning_rate': 0.0001225908372827804, 'epoch': 1.95}\n",
      "{'loss': 0.2507, 'learning_rate': 0.0001224855186940495, 'epoch': 1.95}\n",
      "{'loss': 0.1803, 'learning_rate': 0.00012238020010531858, 'epoch': 1.96}\n",
      "{'loss': 0.1528, 'learning_rate': 0.0001222748815165877, 'epoch': 1.96}\n",
      "{'loss': 0.1896, 'learning_rate': 0.00012216956292785677, 'epoch': 1.96}\n",
      "{'loss': 0.1818, 'learning_rate': 0.00012206424433912587, 'epoch': 1.96}\n",
      "{'loss': 0.2284, 'learning_rate': 0.00012195892575039496, 'epoch': 1.97}\n",
      "{'loss': 0.3454, 'learning_rate': 0.00012185360716166403, 'epoch': 1.97}\n",
      "{'loss': 0.1989, 'learning_rate': 0.00012174828857293313, 'epoch': 1.97}\n",
      "{'loss': 0.2741, 'learning_rate': 0.00012164296998420221, 'epoch': 1.97}\n",
      "{'loss': 0.1929, 'learning_rate': 0.00012153765139547131, 'epoch': 1.98}\n",
      "{'loss': 0.2276, 'learning_rate': 0.0001214323328067404, 'epoch': 1.98}\n",
      "{'loss': 0.2101, 'learning_rate': 0.0001213270142180095, 'epoch': 1.98}\n",
      "{'loss': 0.1755, 'learning_rate': 0.00012122169562927857, 'epoch': 1.99}\n",
      "{'loss': 0.1596, 'learning_rate': 0.00012111637704054765, 'epoch': 1.99}\n",
      "{'loss': 0.2417, 'learning_rate': 0.00012101105845181675, 'epoch': 1.99}\n",
      "{'loss': 0.1564, 'learning_rate': 0.00012090573986308584, 'epoch': 1.99}\n",
      "{'loss': 0.1748, 'learning_rate': 0.00012080042127435494, 'epoch': 2.0}\n",
      "{'loss': 0.2064, 'learning_rate': 0.00012069510268562402, 'epoch': 2.0}\n",
      "{'loss': 0.17, 'learning_rate': 0.00012058978409689309, 'epoch': 2.0}\n",
      "{'loss': 0.1742, 'learning_rate': 0.00012048446550816219, 'epoch': 2.0}\n",
      "{'loss': 0.116, 'learning_rate': 0.00012037914691943129, 'epoch': 2.01}\n",
      "{'loss': 0.1596, 'learning_rate': 0.00012027382833070038, 'epoch': 2.01}\n",
      "{'loss': 0.1738, 'learning_rate': 0.00012016850974196947, 'epoch': 2.01}\n",
      "{'loss': 0.1833, 'learning_rate': 0.00012006319115323856, 'epoch': 2.01}\n",
      "{'loss': 0.1289, 'learning_rate': 0.00011995787256450763, 'epoch': 2.02}\n",
      "{'loss': 0.1429, 'learning_rate': 0.00011985255397577673, 'epoch': 2.02}\n",
      "{'loss': 0.1407, 'learning_rate': 0.00011974723538704582, 'epoch': 2.02}\n",
      "{'loss': 0.1272, 'learning_rate': 0.0001196419167983149, 'epoch': 2.02}\n",
      "{'loss': 0.1468, 'learning_rate': 0.000119536598209584, 'epoch': 2.03}\n",
      "{'loss': 0.1539, 'learning_rate': 0.00011943127962085307, 'epoch': 2.03}\n",
      "{'loss': 0.1662, 'learning_rate': 0.00011932596103212217, 'epoch': 2.03}\n",
      "{'loss': 0.1253, 'learning_rate': 0.00011922064244339126, 'epoch': 2.04}\n",
      "{'loss': 0.1689, 'learning_rate': 0.00011911532385466036, 'epoch': 2.04}\n",
      "{'loss': 0.1563, 'learning_rate': 0.00011901000526592944, 'epoch': 2.04}\n",
      "{'loss': 0.1771, 'learning_rate': 0.00011890468667719854, 'epoch': 2.04}\n",
      "{'loss': 0.1361, 'learning_rate': 0.00011879936808846761, 'epoch': 2.05}\n",
      "{'loss': 0.1532, 'learning_rate': 0.0001186940494997367, 'epoch': 2.05}\n",
      "{'loss': 0.1818, 'learning_rate': 0.0001185887309110058, 'epoch': 2.05}\n",
      "{'loss': 0.1781, 'learning_rate': 0.00011848341232227489, 'epoch': 2.05}\n",
      "{'loss': 0.2397, 'learning_rate': 0.00011837809373354398, 'epoch': 2.06}\n",
      "{'loss': 0.1442, 'learning_rate': 0.00011827277514481308, 'epoch': 2.06}\n",
      "{'loss': 0.1544, 'learning_rate': 0.00011816745655608215, 'epoch': 2.06}\n",
      "{'loss': 0.1603, 'learning_rate': 0.00011806213796735124, 'epoch': 2.06}\n",
      "{'loss': 0.2231, 'learning_rate': 0.00011795681937862033, 'epoch': 2.07}\n",
      "{'loss': 0.1618, 'learning_rate': 0.00011785150078988942, 'epoch': 2.07}\n",
      "{'loss': 0.1117, 'learning_rate': 0.00011774618220115852, 'epoch': 2.07}\n",
      "{'loss': 0.1719, 'learning_rate': 0.00011764086361242762, 'epoch': 2.07}\n",
      "{'loss': 0.2096, 'learning_rate': 0.00011753554502369668, 'epoch': 2.08}\n",
      "{'loss': 0.1972, 'learning_rate': 0.00011743022643496577, 'epoch': 2.08}\n",
      "{'loss': 0.1707, 'learning_rate': 0.00011732490784623486, 'epoch': 2.08}\n",
      "{'loss': 0.1397, 'learning_rate': 0.00011721958925750396, 'epoch': 2.08}\n",
      "{'loss': 0.1938, 'learning_rate': 0.00011711427066877306, 'epoch': 2.09}\n",
      "{'loss': 0.1274, 'learning_rate': 0.00011700895208004213, 'epoch': 2.09}\n",
      "{'loss': 0.1667, 'learning_rate': 0.00011690363349131121, 'epoch': 2.09}\n",
      "{'loss': 0.1576, 'learning_rate': 0.0001167983149025803, 'epoch': 2.1}\n",
      "{'loss': 0.1496, 'learning_rate': 0.0001166929963138494, 'epoch': 2.1}\n",
      "{'loss': 0.1707, 'learning_rate': 0.0001165876777251185, 'epoch': 2.1}\n",
      "{'loss': 0.1406, 'learning_rate': 0.00011648235913638758, 'epoch': 2.1}\n",
      "{'loss': 0.1306, 'learning_rate': 0.00011637704054765666, 'epoch': 2.11}\n",
      "{'loss': 0.1762, 'learning_rate': 0.00011627172195892575, 'epoch': 2.11}\n",
      "{'loss': 0.1297, 'learning_rate': 0.00011616640337019484, 'epoch': 2.11}\n",
      "{'loss': 0.1588, 'learning_rate': 0.00011606108478146394, 'epoch': 2.11}\n",
      "{'loss': 0.2237, 'learning_rate': 0.00011595576619273302, 'epoch': 2.12}\n",
      "{'loss': 0.1418, 'learning_rate': 0.00011585044760400212, 'epoch': 2.12}\n",
      "{'loss': 0.131, 'learning_rate': 0.00011574512901527119, 'epoch': 2.12}\n",
      "{'loss': 0.1604, 'learning_rate': 0.00011563981042654028, 'epoch': 2.12}\n",
      "{'loss': 0.1472, 'learning_rate': 0.00011553449183780938, 'epoch': 2.13}\n",
      "{'loss': 0.1804, 'learning_rate': 0.00011542917324907848, 'epoch': 2.13}\n",
      "{'loss': 0.1952, 'learning_rate': 0.00011532385466034756, 'epoch': 2.13}\n",
      "{'loss': 0.138, 'learning_rate': 0.00011521853607161666, 'epoch': 2.13}\n",
      "{'loss': 0.1226, 'learning_rate': 0.00011511321748288573, 'epoch': 2.14}\n",
      "{'loss': 0.1357, 'learning_rate': 0.00011500789889415482, 'epoch': 2.14}\n",
      "{'loss': 0.1444, 'learning_rate': 0.00011490258030542392, 'epoch': 2.14}\n",
      "{'loss': 0.2157, 'learning_rate': 0.000114797261716693, 'epoch': 2.15}\n",
      "{'loss': 0.1623, 'learning_rate': 0.0001146919431279621, 'epoch': 2.15}\n",
      "{'loss': 0.1489, 'learning_rate': 0.00011458662453923117, 'epoch': 2.15}\n",
      "{'loss': 0.1882, 'learning_rate': 0.00011448130595050026, 'epoch': 2.15}\n",
      "{'loss': 0.1814, 'learning_rate': 0.00011437598736176936, 'epoch': 2.16}\n",
      "{'loss': 0.1436, 'learning_rate': 0.00011427066877303844, 'epoch': 2.16}\n",
      "{'loss': 0.2086, 'learning_rate': 0.00011416535018430754, 'epoch': 2.16}\n",
      "{'loss': 0.1261, 'learning_rate': 0.00011406003159557663, 'epoch': 2.16}\n",
      "{'loss': 0.1453, 'learning_rate': 0.0001139547130068457, 'epoch': 2.17}\n",
      "{'loss': 0.1886, 'learning_rate': 0.0001138493944181148, 'epoch': 2.17}\n",
      "{'loss': 0.1394, 'learning_rate': 0.00011374407582938388, 'epoch': 2.17}\n",
      "{'loss': 0.1573, 'learning_rate': 0.00011363875724065298, 'epoch': 2.17}\n",
      "{'loss': 0.1488, 'learning_rate': 0.00011353343865192208, 'epoch': 2.18}\n",
      "{'loss': 0.1404, 'learning_rate': 0.00011342812006319117, 'epoch': 2.18}\n",
      "{'loss': 0.1377, 'learning_rate': 0.00011332280147446024, 'epoch': 2.18}\n",
      "{'loss': 0.176, 'learning_rate': 0.00011321748288572934, 'epoch': 2.18}\n",
      "{'loss': 0.1784, 'learning_rate': 0.00011311216429699842, 'epoch': 2.19}\n",
      "{'loss': 0.2138, 'learning_rate': 0.00011300684570826752, 'epoch': 2.19}\n",
      "{'loss': 0.1664, 'learning_rate': 0.00011290152711953661, 'epoch': 2.19}\n",
      "{'loss': 0.1762, 'learning_rate': 0.0001127962085308057, 'epoch': 2.19}\n",
      "{'loss': 0.2248, 'learning_rate': 0.00011269088994207478, 'epoch': 2.2}\n",
      "{'loss': 0.1472, 'learning_rate': 0.00011258557135334386, 'epoch': 2.2}\n",
      "{'loss': 0.168, 'learning_rate': 0.00011248025276461296, 'epoch': 2.2}\n",
      "{'loss': 0.1296, 'learning_rate': 0.00011237493417588205, 'epoch': 2.21}\n",
      "{'loss': 0.2036, 'learning_rate': 0.00011226961558715115, 'epoch': 2.21}\n",
      "{'loss': 0.1604, 'learning_rate': 0.00011216429699842023, 'epoch': 2.21}\n",
      "{'loss': 0.1414, 'learning_rate': 0.0001120589784096893, 'epoch': 2.21}\n",
      "{'loss': 0.1766, 'learning_rate': 0.0001119536598209584, 'epoch': 2.22}\n",
      "{'loss': 0.1211, 'learning_rate': 0.0001118483412322275, 'epoch': 2.22}\n",
      "{'loss': 0.145, 'learning_rate': 0.00011174302264349659, 'epoch': 2.22}\n",
      "{'loss': 0.161, 'learning_rate': 0.00011163770405476568, 'epoch': 2.22}\n",
      "{'loss': 0.1246, 'learning_rate': 0.00011153238546603474, 'epoch': 2.23}\n",
      "{'loss': 0.1534, 'learning_rate': 0.00011142706687730384, 'epoch': 2.23}\n",
      "{'loss': 0.1963, 'learning_rate': 0.00011132174828857294, 'epoch': 2.23}\n",
      "{'loss': 0.1251, 'learning_rate': 0.00011121642969984203, 'epoch': 2.23}\n",
      "{'loss': 0.1613, 'learning_rate': 0.00011111111111111112, 'epoch': 2.24}\n",
      "{'loss': 0.1315, 'learning_rate': 0.00011100579252238021, 'epoch': 2.24}\n",
      "{'loss': 0.1092, 'learning_rate': 0.00011090047393364928, 'epoch': 2.24}\n",
      "{'loss': 0.1946, 'learning_rate': 0.00011079515534491838, 'epoch': 2.24}\n",
      "{'loss': 0.1396, 'learning_rate': 0.00011068983675618747, 'epoch': 2.25}\n",
      "{'loss': 0.1905, 'learning_rate': 0.00011058451816745656, 'epoch': 2.25}\n",
      "{'loss': 0.1552, 'learning_rate': 0.00011047919957872565, 'epoch': 2.25}\n",
      "{'loss': 0.1942, 'learning_rate': 0.00011037388098999475, 'epoch': 2.26}\n",
      "{'loss': 0.143, 'learning_rate': 0.00011026856240126382, 'epoch': 2.26}\n",
      "{'loss': 0.2088, 'learning_rate': 0.00011016324381253292, 'epoch': 2.26}\n",
      "{'loss': 0.146, 'learning_rate': 0.000110057925223802, 'epoch': 2.26}\n",
      "{'loss': 0.1723, 'learning_rate': 0.0001099526066350711, 'epoch': 2.27}\n",
      "{'loss': 0.1318, 'learning_rate': 0.00010984728804634019, 'epoch': 2.27}\n",
      "{'loss': 0.1366, 'learning_rate': 0.00010974196945760929, 'epoch': 2.27}\n",
      "{'loss': 0.1439, 'learning_rate': 0.00010963665086887836, 'epoch': 2.27}\n",
      "{'loss': 0.207, 'learning_rate': 0.00010953133228014745, 'epoch': 2.28}\n",
      "{'loss': 0.1603, 'learning_rate': 0.00010942601369141654, 'epoch': 2.28}\n",
      "{'loss': 0.134, 'learning_rate': 0.00010932069510268563, 'epoch': 2.28}\n",
      "{'loss': 0.1316, 'learning_rate': 0.00010921537651395473, 'epoch': 2.28}\n",
      "{'loss': 0.1273, 'learning_rate': 0.0001091100579252238, 'epoch': 2.29}\n",
      "{'loss': 0.2105, 'learning_rate': 0.0001090047393364929, 'epoch': 2.29}\n",
      "{'loss': 0.1822, 'learning_rate': 0.00010889942074776198, 'epoch': 2.29}\n",
      "{'loss': 0.1195, 'learning_rate': 0.00010879410215903107, 'epoch': 2.29}\n",
      "{'loss': 0.15, 'learning_rate': 0.00010868878357030017, 'epoch': 2.3}\n",
      "{'loss': 0.1939, 'learning_rate': 0.00010858346498156927, 'epoch': 2.3}\n",
      "{'loss': 0.1238, 'learning_rate': 0.00010847814639283834, 'epoch': 2.3}\n",
      "{'loss': 0.1104, 'learning_rate': 0.00010837282780410742, 'epoch': 2.3}\n",
      "{'loss': 0.1553, 'learning_rate': 0.00010826750921537652, 'epoch': 2.31}\n",
      "{'loss': 0.1151, 'learning_rate': 0.00010816219062664561, 'epoch': 2.31}\n",
      "{'loss': 0.1847, 'learning_rate': 0.00010805687203791471, 'epoch': 2.31}\n",
      "{'loss': 0.1606, 'learning_rate': 0.00010795155344918379, 'epoch': 2.32}\n",
      "{'loss': 0.0988, 'learning_rate': 0.00010784623486045286, 'epoch': 2.32}\n",
      "{'loss': 0.2381, 'learning_rate': 0.00010774091627172196, 'epoch': 2.32}\n",
      "{'loss': 0.1711, 'learning_rate': 0.00010763559768299105, 'epoch': 2.32}\n",
      "{'loss': 0.1688, 'learning_rate': 0.00010753027909426015, 'epoch': 2.33}\n",
      "{'loss': 0.1109, 'learning_rate': 0.00010742496050552923, 'epoch': 2.33}\n",
      "{'loss': 0.1586, 'learning_rate': 0.00010731964191679833, 'epoch': 2.33}\n",
      "{'loss': 0.1704, 'learning_rate': 0.0001072143233280674, 'epoch': 2.33}\n",
      "{'loss': 0.1255, 'learning_rate': 0.0001071090047393365, 'epoch': 2.34}\n",
      "{'loss': 0.1889, 'learning_rate': 0.00010700368615060559, 'epoch': 2.34}\n",
      "{'loss': 0.1754, 'learning_rate': 0.00010689836756187467, 'epoch': 2.34}\n",
      "{'loss': 0.1751, 'learning_rate': 0.00010679304897314377, 'epoch': 2.34}\n",
      "{'loss': 0.185, 'learning_rate': 0.00010668773038441287, 'epoch': 2.35}\n",
      "{'loss': 0.144, 'learning_rate': 0.00010658241179568194, 'epoch': 2.35}\n",
      "{'loss': 0.1302, 'learning_rate': 0.00010647709320695103, 'epoch': 2.35}\n",
      "{'loss': 0.1568, 'learning_rate': 0.00010637177461822013, 'epoch': 2.35}\n",
      "{'loss': 0.1205, 'learning_rate': 0.00010626645602948921, 'epoch': 2.36}\n",
      "{'loss': 0.136, 'learning_rate': 0.00010616113744075831, 'epoch': 2.36}\n",
      "{'loss': 0.1415, 'learning_rate': 0.00010605581885202738, 'epoch': 2.36}\n",
      "{'loss': 0.2059, 'learning_rate': 0.00010595050026329647, 'epoch': 2.37}\n",
      "{'loss': 0.1624, 'learning_rate': 0.00010584518167456557, 'epoch': 2.37}\n",
      "{'loss': 0.1283, 'learning_rate': 0.00010573986308583465, 'epoch': 2.37}\n",
      "{'loss': 0.1191, 'learning_rate': 0.00010563454449710375, 'epoch': 2.37}\n",
      "{'loss': 0.1572, 'learning_rate': 0.00010552922590837284, 'epoch': 2.38}\n",
      "{'loss': 0.1374, 'learning_rate': 0.00010542390731964191, 'epoch': 2.38}\n",
      "{'loss': 0.1585, 'learning_rate': 0.00010531858873091101, 'epoch': 2.38}\n",
      "{'loss': 0.152, 'learning_rate': 0.0001052132701421801, 'epoch': 2.38}\n",
      "{'loss': 0.1106, 'learning_rate': 0.00010510795155344919, 'epoch': 2.39}\n",
      "{'loss': 0.1313, 'learning_rate': 0.00010500263296471829, 'epoch': 2.39}\n",
      "{'loss': 0.165, 'learning_rate': 0.00010489731437598738, 'epoch': 2.39}\n",
      "{'loss': 0.1222, 'learning_rate': 0.00010479199578725645, 'epoch': 2.39}\n",
      "{'loss': 0.1472, 'learning_rate': 0.00010468667719852553, 'epoch': 2.4}\n",
      "{'loss': 0.1414, 'learning_rate': 0.00010458135860979463, 'epoch': 2.4}\n",
      "{'loss': 0.1203, 'learning_rate': 0.00010447604002106373, 'epoch': 2.4}\n",
      "{'loss': 0.1137, 'learning_rate': 0.00010437072143233282, 'epoch': 2.4}\n",
      "{'loss': 0.1093, 'learning_rate': 0.0001042654028436019, 'epoch': 2.41}\n",
      "{'loss': 0.1816, 'learning_rate': 0.00010416008425487098, 'epoch': 2.41}\n",
      "{'loss': 0.1677, 'learning_rate': 0.00010405476566614007, 'epoch': 2.41}\n",
      "{'loss': 0.1645, 'learning_rate': 0.00010394944707740917, 'epoch': 2.41}\n",
      "{'loss': 0.1657, 'learning_rate': 0.00010384412848867826, 'epoch': 2.42}\n",
      "{'loss': 0.096, 'learning_rate': 0.00010373880989994735, 'epoch': 2.42}\n",
      "{'loss': 0.1718, 'learning_rate': 0.00010363349131121643, 'epoch': 2.42}\n",
      "{'loss': 0.1795, 'learning_rate': 0.00010352817272248551, 'epoch': 2.43}\n",
      "{'loss': 0.1628, 'learning_rate': 0.00010342285413375461, 'epoch': 2.43}\n",
      "{'loss': 0.1446, 'learning_rate': 0.0001033175355450237, 'epoch': 2.43}\n",
      "{'loss': 0.1535, 'learning_rate': 0.00010321221695629279, 'epoch': 2.43}\n",
      "{'loss': 0.2071, 'learning_rate': 0.00010310689836756189, 'epoch': 2.44}\n",
      "{'loss': 0.1296, 'learning_rate': 0.00010300157977883095, 'epoch': 2.44}\n",
      "{'loss': 0.1167, 'learning_rate': 0.00010289626119010005, 'epoch': 2.44}\n",
      "{'loss': 0.1526, 'learning_rate': 0.00010279094260136915, 'epoch': 2.44}\n",
      "{'loss': 0.1176, 'learning_rate': 0.00010268562401263824, 'epoch': 2.45}\n",
      "{'loss': 0.1472, 'learning_rate': 0.00010258030542390733, 'epoch': 2.45}\n",
      "{'loss': 0.1028, 'learning_rate': 0.00010247498683517642, 'epoch': 2.45}\n",
      "{'loss': 0.1422, 'learning_rate': 0.00010236966824644549, 'epoch': 2.45}\n",
      "{'loss': 0.1079, 'learning_rate': 0.00010226434965771459, 'epoch': 2.46}\n",
      "{'loss': 0.1393, 'learning_rate': 0.00010215903106898368, 'epoch': 2.46}\n",
      "{'loss': 0.1279, 'learning_rate': 0.00010205371248025277, 'epoch': 2.46}\n",
      "{'loss': 0.1638, 'learning_rate': 0.00010194839389152186, 'epoch': 2.46}\n",
      "{'loss': 0.1149, 'learning_rate': 0.00010184307530279096, 'epoch': 2.47}\n",
      "{'loss': 0.1226, 'learning_rate': 0.00010173775671406003, 'epoch': 2.47}\n",
      "{'loss': 0.1683, 'learning_rate': 0.00010163243812532913, 'epoch': 2.47}\n",
      "{'loss': 0.1289, 'learning_rate': 0.00010152711953659821, 'epoch': 2.48}\n",
      "{'loss': 0.1823, 'learning_rate': 0.0001014218009478673, 'epoch': 2.48}\n",
      "{'loss': 0.1053, 'learning_rate': 0.0001013164823591364, 'epoch': 2.48}\n",
      "{'loss': 0.1612, 'learning_rate': 0.00010121116377040547, 'epoch': 2.48}\n",
      "{'loss': 0.1397, 'learning_rate': 0.00010110584518167457, 'epoch': 2.49}\n",
      "{'loss': 0.1285, 'learning_rate': 0.00010100052659294365, 'epoch': 2.49}\n",
      "{'loss': 0.1677, 'learning_rate': 0.00010089520800421275, 'epoch': 2.49}\n",
      "{'loss': 0.1663, 'learning_rate': 0.00010078988941548184, 'epoch': 2.49}\n",
      "{'loss': 0.1268, 'learning_rate': 0.00010068457082675094, 'epoch': 2.5}\n",
      "{'loss': 0.1121, 'learning_rate': 0.00010057925223802001, 'epoch': 2.5}\n",
      "{'loss': 0.1578, 'learning_rate': 0.00010047393364928909, 'epoch': 2.5}\n",
      "{'loss': 0.118, 'learning_rate': 0.00010036861506055819, 'epoch': 2.5}\n",
      "{'loss': 0.1574, 'learning_rate': 0.00010026329647182728, 'epoch': 2.51}\n",
      "{'loss': 0.1431, 'learning_rate': 0.00010015797788309638, 'epoch': 2.51}\n",
      "{'loss': 0.1327, 'learning_rate': 0.00010005265929436546, 'epoch': 2.51}\n",
      "{'loss': 0.1208, 'learning_rate': 9.994734070563455e-05, 'epoch': 2.51}\n",
      "{'loss': 0.1, 'learning_rate': 9.984202211690363e-05, 'epoch': 2.52}\n",
      "{'loss': 0.1143, 'learning_rate': 9.973670352817273e-05, 'epoch': 2.52}\n",
      "{'loss': 0.1222, 'learning_rate': 9.963138493944182e-05, 'epoch': 2.52}\n",
      "{'loss': 0.1379, 'learning_rate': 9.95260663507109e-05, 'epoch': 2.52}\n",
      "{'loss': 0.1399, 'learning_rate': 9.942074776197999e-05, 'epoch': 2.53}\n",
      "{'loss': 0.1194, 'learning_rate': 9.931542917324908e-05, 'epoch': 2.53}\n",
      "{'loss': 0.1228, 'learning_rate': 9.921011058451817e-05, 'epoch': 2.53}\n",
      "{'loss': 0.1397, 'learning_rate': 9.910479199578726e-05, 'epoch': 2.54}\n",
      "{'loss': 0.1136, 'learning_rate': 9.899947340705636e-05, 'epoch': 2.54}\n",
      "{'loss': 0.1406, 'learning_rate': 9.889415481832543e-05, 'epoch': 2.54}\n",
      "{'loss': 0.1521, 'learning_rate': 9.878883622959453e-05, 'epoch': 2.54}\n",
      "{'loss': 0.1306, 'learning_rate': 9.868351764086362e-05, 'epoch': 2.55}\n",
      "{'loss': 0.1586, 'learning_rate': 9.85781990521327e-05, 'epoch': 2.55}\n",
      "{'loss': 0.0936, 'learning_rate': 9.84728804634018e-05, 'epoch': 2.55}\n",
      "{'loss': 0.1264, 'learning_rate': 9.836756187467088e-05, 'epoch': 2.55}\n",
      "{'loss': 0.1457, 'learning_rate': 9.826224328593997e-05, 'epoch': 2.56}\n",
      "{'loss': 0.1346, 'learning_rate': 9.815692469720906e-05, 'epoch': 2.56}\n",
      "{'loss': 0.156, 'learning_rate': 9.805160610847816e-05, 'epoch': 2.56}\n",
      "{'loss': 0.132, 'learning_rate': 9.794628751974724e-05, 'epoch': 2.56}\n",
      "{'loss': 0.1264, 'learning_rate': 9.784096893101632e-05, 'epoch': 2.57}\n",
      "{'loss': 0.123, 'learning_rate': 9.773565034228542e-05, 'epoch': 2.57}\n",
      "{'loss': 0.1132, 'learning_rate': 9.76303317535545e-05, 'epoch': 2.57}\n",
      "{'loss': 0.1521, 'learning_rate': 9.75250131648236e-05, 'epoch': 2.57}\n",
      "{'loss': 0.0931, 'learning_rate': 9.74196945760927e-05, 'epoch': 2.58}\n",
      "{'loss': 0.1318, 'learning_rate': 9.731437598736177e-05, 'epoch': 2.58}\n",
      "{'loss': 0.1916, 'learning_rate': 9.720905739863086e-05, 'epoch': 2.58}\n",
      "{'loss': 0.0997, 'learning_rate': 9.710373880989995e-05, 'epoch': 2.59}\n",
      "{'loss': 0.1469, 'learning_rate': 9.699842022116904e-05, 'epoch': 2.59}\n",
      "{'loss': 0.1426, 'learning_rate': 9.689310163243814e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0873, 'learning_rate': 9.678778304370722e-05, 'epoch': 2.59}\n",
      "{'loss': 0.1147, 'learning_rate': 9.66824644549763e-05, 'epoch': 2.6}\n",
      "{'loss': 0.1115, 'learning_rate': 9.65771458662454e-05, 'epoch': 2.6}\n",
      "{'loss': 0.1066, 'learning_rate': 9.647182727751448e-05, 'epoch': 2.6}\n",
      "{'loss': 0.159, 'learning_rate': 9.636650868878358e-05, 'epoch': 2.6}\n",
      "{'loss': 0.1661, 'learning_rate': 9.626119010005266e-05, 'epoch': 2.61}\n",
      "{'loss': 0.1526, 'learning_rate': 9.615587151132174e-05, 'epoch': 2.61}\n",
      "{'loss': 0.1214, 'learning_rate': 9.605055292259084e-05, 'epoch': 2.61}\n",
      "{'loss': 0.1718, 'learning_rate': 9.594523433385994e-05, 'epoch': 2.61}\n",
      "{'loss': 0.0873, 'learning_rate': 9.583991574512902e-05, 'epoch': 2.62}\n",
      "{'loss': 0.1255, 'learning_rate': 9.57345971563981e-05, 'epoch': 2.62}\n",
      "{'loss': 0.1073, 'learning_rate': 9.56292785676672e-05, 'epoch': 2.62}\n",
      "{'loss': 0.1284, 'learning_rate': 9.552395997893628e-05, 'epoch': 2.62}\n",
      "{'loss': 0.1506, 'learning_rate': 9.541864139020538e-05, 'epoch': 2.63}\n",
      "{'loss': 0.1198, 'learning_rate': 9.531332280147448e-05, 'epoch': 2.63}\n",
      "{'loss': 0.1013, 'learning_rate': 9.520800421274356e-05, 'epoch': 2.63}\n",
      "{'loss': 0.1343, 'learning_rate': 9.510268562401264e-05, 'epoch': 2.63}\n",
      "{'loss': 0.108, 'learning_rate': 9.499736703528174e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0996, 'learning_rate': 9.489204844655082e-05, 'epoch': 2.64}\n",
      "{'loss': 0.1151, 'learning_rate': 9.478672985781992e-05, 'epoch': 2.64}\n",
      "{'loss': 0.1851, 'learning_rate': 9.4681411269089e-05, 'epoch': 2.65}\n",
      "{'loss': 0.1685, 'learning_rate': 9.457609268035808e-05, 'epoch': 2.65}\n",
      "{'loss': 0.1156, 'learning_rate': 9.447077409162718e-05, 'epoch': 2.65}\n",
      "{'loss': 0.0995, 'learning_rate': 9.436545550289626e-05, 'epoch': 2.65}\n",
      "{'loss': 0.1274, 'learning_rate': 9.426013691416536e-05, 'epoch': 2.66}\n",
      "{'loss': 0.1527, 'learning_rate': 9.415481832543444e-05, 'epoch': 2.66}\n",
      "{'loss': 0.1266, 'learning_rate': 9.404949973670352e-05, 'epoch': 2.66}\n",
      "{'loss': 0.1313, 'learning_rate': 9.394418114797262e-05, 'epoch': 2.66}\n",
      "{'loss': 0.1406, 'learning_rate': 9.383886255924172e-05, 'epoch': 2.67}\n",
      "{'loss': 0.1401, 'learning_rate': 9.37335439705108e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0956, 'learning_rate': 9.362822538177988e-05, 'epoch': 2.67}\n",
      "{'loss': 0.1119, 'learning_rate': 9.352290679304898e-05, 'epoch': 2.67}\n",
      "{'loss': 0.1244, 'learning_rate': 9.341758820431806e-05, 'epoch': 2.68}\n",
      "{'loss': 0.1138, 'learning_rate': 9.331226961558716e-05, 'epoch': 2.68}\n",
      "{'loss': 0.1134, 'learning_rate': 9.320695102685625e-05, 'epoch': 2.68}\n",
      "{'loss': 0.1124, 'learning_rate': 9.310163243812534e-05, 'epoch': 2.68}\n",
      "{'loss': 0.1216, 'learning_rate': 9.299631384939442e-05, 'epoch': 2.69}\n",
      "{'loss': 0.1341, 'learning_rate': 9.289099526066352e-05, 'epoch': 2.69}\n",
      "{'loss': 0.1091, 'learning_rate': 9.27856766719326e-05, 'epoch': 2.69}\n",
      "{'loss': 0.1018, 'learning_rate': 9.26803580832017e-05, 'epoch': 2.7}\n",
      "{'loss': 0.1931, 'learning_rate': 9.257503949447078e-05, 'epoch': 2.7}\n",
      "{'loss': 0.1051, 'learning_rate': 9.246972090573986e-05, 'epoch': 2.7}\n",
      "{'loss': 0.1228, 'learning_rate': 9.236440231700896e-05, 'epoch': 2.7}\n",
      "{'loss': 0.0906, 'learning_rate': 9.225908372827805e-05, 'epoch': 2.71}\n",
      "{'loss': 0.1137, 'learning_rate': 9.215376513954714e-05, 'epoch': 2.71}\n",
      "{'loss': 0.1511, 'learning_rate': 9.204844655081622e-05, 'epoch': 2.71}\n",
      "{'loss': 0.096, 'learning_rate': 9.19431279620853e-05, 'epoch': 2.71}\n",
      "{'loss': 0.1074, 'learning_rate': 9.18378093733544e-05, 'epoch': 2.72}\n",
      "{'loss': 0.1203, 'learning_rate': 9.17324907846235e-05, 'epoch': 2.72}\n",
      "{'loss': 0.133, 'learning_rate': 9.162717219589258e-05, 'epoch': 2.72}\n",
      "{'loss': 0.1247, 'learning_rate': 9.152185360716167e-05, 'epoch': 2.72}\n",
      "{'loss': 0.1189, 'learning_rate': 9.141653501843076e-05, 'epoch': 2.73}\n",
      "{'loss': 0.125, 'learning_rate': 9.131121642969984e-05, 'epoch': 2.73}\n",
      "{'loss': 0.1223, 'learning_rate': 9.120589784096894e-05, 'epoch': 2.73}\n",
      "{'loss': 0.1485, 'learning_rate': 9.110057925223803e-05, 'epoch': 2.73}\n",
      "{'loss': 0.0955, 'learning_rate': 9.099526066350711e-05, 'epoch': 2.74}\n",
      "{'loss': 0.1375, 'learning_rate': 9.08899420747762e-05, 'epoch': 2.74}\n",
      "{'loss': 0.1166, 'learning_rate': 9.07846234860453e-05, 'epoch': 2.74}\n",
      "{'loss': 0.1164, 'learning_rate': 9.067930489731438e-05, 'epoch': 2.74}\n",
      "{'loss': 0.0879, 'learning_rate': 9.057398630858347e-05, 'epoch': 2.75}\n",
      "{'loss': 0.1224, 'learning_rate': 9.046866771985256e-05, 'epoch': 2.75}\n",
      "{'loss': 0.1331, 'learning_rate': 9.036334913112164e-05, 'epoch': 2.75}\n",
      "{'loss': 0.1637, 'learning_rate': 9.025803054239074e-05, 'epoch': 2.76}\n",
      "{'loss': 0.0817, 'learning_rate': 9.015271195365983e-05, 'epoch': 2.76}\n",
      "{'loss': 0.1242, 'learning_rate': 9.004739336492891e-05, 'epoch': 2.76}\n",
      "{'loss': 0.1207, 'learning_rate': 8.994207477619801e-05, 'epoch': 2.76}\n",
      "{'loss': 0.109, 'learning_rate': 8.98367561874671e-05, 'epoch': 2.77}\n",
      "{'loss': 0.1094, 'learning_rate': 8.973143759873618e-05, 'epoch': 2.77}\n",
      "{'loss': 0.1124, 'learning_rate': 8.962611901000527e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0992, 'learning_rate': 8.952080042127437e-05, 'epoch': 2.77}\n",
      "{'loss': 0.158, 'learning_rate': 8.941548183254345e-05, 'epoch': 2.78}\n",
      "{'loss': 0.1751, 'learning_rate': 8.931016324381253e-05, 'epoch': 2.78}\n",
      "{'loss': 0.0898, 'learning_rate': 8.920484465508162e-05, 'epoch': 2.78}\n",
      "{'loss': 0.1107, 'learning_rate': 8.909952606635071e-05, 'epoch': 2.78}\n",
      "{'loss': 0.1098, 'learning_rate': 8.899420747761981e-05, 'epoch': 2.79}\n",
      "{'loss': 0.1008, 'learning_rate': 8.888888888888889e-05, 'epoch': 2.79}\n",
      "{'loss': 0.1028, 'learning_rate': 8.878357030015798e-05, 'epoch': 2.79}\n",
      "{'loss': 0.092, 'learning_rate': 8.867825171142707e-05, 'epoch': 2.79}\n",
      "{'loss': 0.1178, 'learning_rate': 8.857293312269616e-05, 'epoch': 2.8}\n",
      "{'loss': 0.137, 'learning_rate': 8.846761453396525e-05, 'epoch': 2.8}\n",
      "{'loss': 0.1376, 'learning_rate': 8.836229594523435e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0988, 'learning_rate': 8.825697735650342e-05, 'epoch': 2.81}\n",
      "{'loss': 0.1272, 'learning_rate': 8.815165876777251e-05, 'epoch': 2.81}\n",
      "{'loss': 0.1141, 'learning_rate': 8.804634017904161e-05, 'epoch': 2.81}\n",
      "{'loss': 0.1043, 'learning_rate': 8.794102159031069e-05, 'epoch': 2.81}\n",
      "{'loss': 0.1198, 'learning_rate': 8.783570300157979e-05, 'epoch': 2.82}\n",
      "{'loss': 0.0908, 'learning_rate': 8.773038441284887e-05, 'epoch': 2.82}\n",
      "{'loss': 0.1213, 'learning_rate': 8.762506582411795e-05, 'epoch': 2.82}\n",
      "{'loss': 0.2025, 'learning_rate': 8.751974723538705e-05, 'epoch': 2.82}\n",
      "{'loss': 0.093, 'learning_rate': 8.741442864665615e-05, 'epoch': 2.83}\n",
      "{'loss': 0.1529, 'learning_rate': 8.730911005792523e-05, 'epoch': 2.83}\n",
      "{'loss': 0.1247, 'learning_rate': 8.720379146919431e-05, 'epoch': 2.83}\n",
      "{'loss': 0.0933, 'learning_rate': 8.709847288046341e-05, 'epoch': 2.83}\n",
      "{'loss': 0.1125, 'learning_rate': 8.699315429173249e-05, 'epoch': 2.84}\n",
      "{'loss': 0.0945, 'learning_rate': 8.688783570300159e-05, 'epoch': 2.84}\n",
      "{'loss': 0.135, 'learning_rate': 8.678251711427067e-05, 'epoch': 2.84}\n",
      "{'loss': 0.1141, 'learning_rate': 8.667719852553975e-05, 'epoch': 2.84}\n",
      "{'loss': 0.0846, 'learning_rate': 8.657187993680885e-05, 'epoch': 2.85}\n",
      "{'loss': 0.1018, 'learning_rate': 8.646656134807793e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0889, 'learning_rate': 8.636124275934703e-05, 'epoch': 2.85}\n",
      "{'loss': 0.1108, 'learning_rate': 8.625592417061613e-05, 'epoch': 2.85}\n",
      "{'loss': 0.1095, 'learning_rate': 8.61506055818852e-05, 'epoch': 2.86}\n",
      "{'loss': 0.095, 'learning_rate': 8.604528699315429e-05, 'epoch': 2.86}\n",
      "{'loss': 0.0739, 'learning_rate': 8.593996840442339e-05, 'epoch': 2.86}\n",
      "{'loss': 0.1319, 'learning_rate': 8.583464981569247e-05, 'epoch': 2.87}\n",
      "{'loss': 0.0887, 'learning_rate': 8.572933122696157e-05, 'epoch': 2.87}\n",
      "{'loss': 0.1661, 'learning_rate': 8.562401263823065e-05, 'epoch': 2.87}\n",
      "{'loss': 0.0766, 'learning_rate': 8.551869404949973e-05, 'epoch': 2.87}\n",
      "{'loss': 0.1121, 'learning_rate': 8.541337546076883e-05, 'epoch': 2.88}\n",
      "{'loss': 0.1151, 'learning_rate': 8.530805687203793e-05, 'epoch': 2.88}\n",
      "{'loss': 0.1039, 'learning_rate': 8.520273828330701e-05, 'epoch': 2.88}\n",
      "{'loss': 0.1082, 'learning_rate': 8.509741969457609e-05, 'epoch': 2.88}\n",
      "{'loss': 0.1369, 'learning_rate': 8.499210110584519e-05, 'epoch': 2.89}\n",
      "{'loss': 0.1516, 'learning_rate': 8.488678251711427e-05, 'epoch': 2.89}\n",
      "{'loss': 0.1315, 'learning_rate': 8.478146392838337e-05, 'epoch': 2.89}\n",
      "{'loss': 0.141, 'learning_rate': 8.467614533965246e-05, 'epoch': 2.89}\n",
      "{'loss': 0.0786, 'learning_rate': 8.457082675092153e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0894, 'learning_rate': 8.446550816219063e-05, 'epoch': 2.9}\n",
      "{'loss': 0.086, 'learning_rate': 8.436018957345973e-05, 'epoch': 2.9}\n",
      "{'loss': 0.1048, 'learning_rate': 8.425487098472881e-05, 'epoch': 2.9}\n",
      "{'loss': 0.086, 'learning_rate': 8.41495523959979e-05, 'epoch': 2.91}\n",
      "{'loss': 0.0808, 'learning_rate': 8.404423380726699e-05, 'epoch': 2.91}\n",
      "{'loss': 0.117, 'learning_rate': 8.393891521853607e-05, 'epoch': 2.91}\n",
      "{'loss': 0.131, 'learning_rate': 8.383359662980517e-05, 'epoch': 2.92}\n",
      "{'loss': 0.1001, 'learning_rate': 8.372827804107425e-05, 'epoch': 2.92}\n",
      "{'loss': 0.1122, 'learning_rate': 8.362295945234335e-05, 'epoch': 2.92}\n",
      "{'loss': 0.1338, 'learning_rate': 8.351764086361243e-05, 'epoch': 2.92}\n",
      "{'loss': 0.1127, 'learning_rate': 8.341232227488151e-05, 'epoch': 2.93}\n",
      "{'loss': 0.1285, 'learning_rate': 8.330700368615061e-05, 'epoch': 2.93}\n",
      "{'loss': 0.0947, 'learning_rate': 8.32016850974197e-05, 'epoch': 2.93}\n",
      "{'loss': 0.1092, 'learning_rate': 8.309636650868879e-05, 'epoch': 2.93}\n",
      "{'loss': 0.1, 'learning_rate': 8.299104791995787e-05, 'epoch': 2.94}\n",
      "{'loss': 0.1246, 'learning_rate': 8.288572933122697e-05, 'epoch': 2.94}\n",
      "{'loss': 0.1265, 'learning_rate': 8.278041074249605e-05, 'epoch': 2.94}\n",
      "{'loss': 0.0756, 'learning_rate': 8.267509215376515e-05, 'epoch': 2.94}\n",
      "{'loss': 0.0786, 'learning_rate': 8.256977356503424e-05, 'epoch': 2.95}\n",
      "{'loss': 0.1166, 'learning_rate': 8.246445497630332e-05, 'epoch': 2.95}\n",
      "{'loss': 0.0965, 'learning_rate': 8.235913638757241e-05, 'epoch': 2.95}\n",
      "{'loss': 0.1212, 'learning_rate': 8.22538177988415e-05, 'epoch': 2.95}\n",
      "{'loss': 0.1518, 'learning_rate': 8.214849921011059e-05, 'epoch': 2.96}\n",
      "{'loss': 0.1493, 'learning_rate': 8.204318062137968e-05, 'epoch': 2.96}\n",
      "{'loss': 0.1148, 'learning_rate': 8.193786203264877e-05, 'epoch': 2.96}\n",
      "{'loss': 0.1101, 'learning_rate': 8.183254344391785e-05, 'epoch': 2.96}\n",
      "{'loss': 0.1119, 'learning_rate': 8.172722485518695e-05, 'epoch': 2.97}\n",
      "{'loss': 0.1368, 'learning_rate': 8.162190626645604e-05, 'epoch': 2.97}\n",
      "{'loss': 0.1442, 'learning_rate': 8.151658767772512e-05, 'epoch': 2.97}\n",
      "{'loss': 0.1202, 'learning_rate': 8.141126908899421e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0776, 'learning_rate': 8.130595050026329e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0896, 'learning_rate': 8.120063191153239e-05, 'epoch': 2.98}\n",
      "{'loss': 0.1136, 'learning_rate': 8.109531332280148e-05, 'epoch': 2.98}\n",
      "{'loss': 0.1654, 'learning_rate': 8.098999473407057e-05, 'epoch': 2.99}\n",
      "{'loss': 0.0857, 'learning_rate': 8.088467614533965e-05, 'epoch': 2.99}\n",
      "{'loss': 0.0919, 'learning_rate': 8.077935755660874e-05, 'epoch': 2.99}\n",
      "{'loss': 0.0985, 'learning_rate': 8.067403896787783e-05, 'epoch': 2.99}\n",
      "{'loss': 0.0924, 'learning_rate': 8.056872037914692e-05, 'epoch': 3.0}\n",
      "{'loss': 0.0912, 'learning_rate': 8.046340179041602e-05, 'epoch': 3.0}\n",
      "{'loss': 0.1027, 'learning_rate': 8.03580832016851e-05, 'epoch': 3.0}\n",
      "{'loss': 0.1084, 'learning_rate': 8.025276461295419e-05, 'epoch': 3.0}\n",
      "{'loss': 0.0716, 'learning_rate': 8.014744602422328e-05, 'epoch': 3.01}\n",
      "{'loss': 0.0904, 'learning_rate': 8.004212743549237e-05, 'epoch': 3.01}\n",
      "{'loss': 0.0889, 'learning_rate': 7.993680884676146e-05, 'epoch': 3.01}\n",
      "{'loss': 0.0806, 'learning_rate': 7.983149025803054e-05, 'epoch': 3.01}\n",
      "{'loss': 0.1022, 'learning_rate': 7.972617166929963e-05, 'epoch': 3.02}\n",
      "{'loss': 0.1058, 'learning_rate': 7.962085308056872e-05, 'epoch': 3.02}\n",
      "{'loss': 0.1088, 'learning_rate': 7.951553449183782e-05, 'epoch': 3.02}\n",
      "{'loss': 0.0812, 'learning_rate': 7.94102159031069e-05, 'epoch': 3.03}\n",
      "{'loss': 0.1098, 'learning_rate': 7.930489731437599e-05, 'epoch': 3.03}\n",
      "{'loss': 0.1456, 'learning_rate': 7.919957872564508e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0705, 'learning_rate': 7.909426013691416e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0819, 'learning_rate': 7.898894154818326e-05, 'epoch': 3.04}\n",
      "{'loss': 0.085, 'learning_rate': 7.888362295945236e-05, 'epoch': 3.04}\n",
      "{'loss': 0.0749, 'learning_rate': 7.877830437072144e-05, 'epoch': 3.04}\n",
      "{'loss': 0.0708, 'learning_rate': 7.867298578199052e-05, 'epoch': 3.04}\n",
      "{'loss': 0.0859, 'learning_rate': 7.85676671932596e-05, 'epoch': 3.05}\n",
      "{'loss': 0.1027, 'learning_rate': 7.84623486045287e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0972, 'learning_rate': 7.83570300157978e-05, 'epoch': 3.05}\n",
      "{'loss': 0.1169, 'learning_rate': 7.825171142706688e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0951, 'learning_rate': 7.814639283833596e-05, 'epoch': 3.06}\n",
      "{'loss': 0.0805, 'learning_rate': 7.804107424960506e-05, 'epoch': 3.06}\n",
      "{'loss': 0.0983, 'learning_rate': 7.793575566087414e-05, 'epoch': 3.06}\n",
      "{'loss': 0.0766, 'learning_rate': 7.783043707214324e-05, 'epoch': 3.06}\n",
      "{'loss': 0.0732, 'learning_rate': 7.772511848341232e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0924, 'learning_rate': 7.76197998946814e-05, 'epoch': 3.07}\n",
      "{'loss': 0.075, 'learning_rate': 7.75144813059505e-05, 'epoch': 3.07}\n",
      "{'loss': 0.074, 'learning_rate': 7.74091627172196e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0876, 'learning_rate': 7.730384412848868e-05, 'epoch': 3.08}\n",
      "{'loss': 0.082, 'learning_rate': 7.719852553975778e-05, 'epoch': 3.08}\n",
      "{'loss': 0.0669, 'learning_rate': 7.709320695102686e-05, 'epoch': 3.08}\n",
      "{'loss': 0.1505, 'learning_rate': 7.698788836229594e-05, 'epoch': 3.09}\n",
      "{'loss': 0.0802, 'learning_rate': 7.688256977356504e-05, 'epoch': 3.09}\n",
      "{'loss': 0.0916, 'learning_rate': 7.677725118483414e-05, 'epoch': 3.09}\n",
      "{'loss': 0.0734, 'learning_rate': 7.667193259610322e-05, 'epoch': 3.09}\n",
      "{'loss': 0.0957, 'learning_rate': 7.65666140073723e-05, 'epoch': 3.1}\n",
      "{'loss': 0.0787, 'learning_rate': 7.64612954186414e-05, 'epoch': 3.1}\n",
      "{'loss': 0.0936, 'learning_rate': 7.635597682991048e-05, 'epoch': 3.1}\n",
      "{'loss': 0.0886, 'learning_rate': 7.625065824117958e-05, 'epoch': 3.1}\n",
      "{'loss': 0.0839, 'learning_rate': 7.614533965244866e-05, 'epoch': 3.11}\n",
      "{'loss': 0.1073, 'learning_rate': 7.604002106371774e-05, 'epoch': 3.11}\n",
      "{'loss': 0.109, 'learning_rate': 7.593470247498684e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0923, 'learning_rate': 7.582938388625592e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0864, 'learning_rate': 7.572406529752502e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0857, 'learning_rate': 7.561874670879411e-05, 'epoch': 3.12}\n",
      "{'loss': 0.099, 'learning_rate': 7.551342812006318e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0797, 'learning_rate': 7.540810953133228e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0807, 'learning_rate': 7.530279094260138e-05, 'epoch': 3.13}\n",
      "{'loss': 0.1031, 'learning_rate': 7.519747235387046e-05, 'epoch': 3.13}\n",
      "{'loss': 0.0814, 'learning_rate': 7.509215376513956e-05, 'epoch': 3.13}\n",
      "{'loss': 0.0782, 'learning_rate': 7.498683517640864e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0753, 'learning_rate': 7.488151658767772e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0852, 'learning_rate': 7.477619799894682e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0813, 'learning_rate': 7.467087941021591e-05, 'epoch': 3.14}\n",
      "{'loss': 0.1248, 'learning_rate': 7.4565560821485e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0842, 'learning_rate': 7.446024223275408e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0816, 'learning_rate': 7.435492364402318e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0724, 'learning_rate': 7.424960505529226e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0772, 'learning_rate': 7.414428646656136e-05, 'epoch': 3.16}\n",
      "{'loss': 0.088, 'learning_rate': 7.403896787783044e-05, 'epoch': 3.16}\n",
      "{'loss': 0.0735, 'learning_rate': 7.393364928909952e-05, 'epoch': 3.16}\n",
      "{'loss': 0.0687, 'learning_rate': 7.382833070036862e-05, 'epoch': 3.16}\n",
      "{'loss': 0.103, 'learning_rate': 7.372301211163771e-05, 'epoch': 3.17}\n",
      "{'loss': 0.0744, 'learning_rate': 7.36176935229068e-05, 'epoch': 3.17}\n",
      "{'loss': 0.0917, 'learning_rate': 7.35123749341759e-05, 'epoch': 3.17}\n",
      "{'loss': 0.1139, 'learning_rate': 7.340705634544498e-05, 'epoch': 3.17}\n",
      "{'loss': 0.104, 'learning_rate': 7.330173775671406e-05, 'epoch': 3.18}\n",
      "{'loss': 0.0998, 'learning_rate': 7.319641916798316e-05, 'epoch': 3.18}\n",
      "{'loss': 0.0852, 'learning_rate': 7.309110057925224e-05, 'epoch': 3.18}\n",
      "{'loss': 0.0909, 'learning_rate': 7.298578199052133e-05, 'epoch': 3.18}\n",
      "{'loss': 0.0732, 'learning_rate': 7.288046340179042e-05, 'epoch': 3.19}\n",
      "{'loss': 0.1103, 'learning_rate': 7.27751448130595e-05, 'epoch': 3.19}\n",
      "{'loss': 0.1015, 'learning_rate': 7.26698262243286e-05, 'epoch': 3.19}\n",
      "{'loss': 0.1115, 'learning_rate': 7.256450763559769e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0701, 'learning_rate': 7.245918904686678e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0925, 'learning_rate': 7.235387045813586e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0702, 'learning_rate': 7.224855186940495e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0857, 'learning_rate': 7.214323328067404e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0862, 'learning_rate': 7.203791469194313e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0716, 'learning_rate': 7.193259610321223e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0832, 'learning_rate': 7.18272775144813e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0776, 'learning_rate': 7.17219589257504e-05, 'epoch': 3.22}\n",
      "{'loss': 0.1444, 'learning_rate': 7.161664033701949e-05, 'epoch': 3.22}\n",
      "{'loss': 0.0661, 'learning_rate': 7.151132174828858e-05, 'epoch': 3.22}\n",
      "{'loss': 0.0759, 'learning_rate': 7.140600315955767e-05, 'epoch': 3.22}\n",
      "{'loss': 0.0863, 'learning_rate': 7.130068457082675e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0959, 'learning_rate': 7.119536598209584e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0937, 'learning_rate': 7.109004739336493e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0732, 'learning_rate': 7.098472880463403e-05, 'epoch': 3.23}\n",
      "{'loss': 0.1091, 'learning_rate': 7.087941021590311e-05, 'epoch': 3.24}\n",
      "{'loss': 0.074, 'learning_rate': 7.07740916271722e-05, 'epoch': 3.24}\n",
      "{'loss': 0.0969, 'learning_rate': 7.066877303844129e-05, 'epoch': 3.24}\n",
      "{'loss': 0.0936, 'learning_rate': 7.056345444971038e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0724, 'learning_rate': 7.045813586097947e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0946, 'learning_rate': 7.035281727224855e-05, 'epoch': 3.25}\n",
      "{'loss': 0.1536, 'learning_rate': 7.024749868351764e-05, 'epoch': 3.25}\n",
      "{'loss': 0.1027, 'learning_rate': 7.014218009478673e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0671, 'learning_rate': 7.003686150605582e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0833, 'learning_rate': 6.993154291732491e-05, 'epoch': 3.26}\n",
      "{'loss': 0.08, 'learning_rate': 6.982622432859401e-05, 'epoch': 3.26}\n",
      "{'loss': 0.096, 'learning_rate': 6.972090573986308e-05, 'epoch': 3.27}\n",
      "{'loss': 0.0718, 'learning_rate': 6.961558715113217e-05, 'epoch': 3.27}\n",
      "{'loss': 0.083, 'learning_rate': 6.951026856240127e-05, 'epoch': 3.27}\n",
      "{'loss': 0.0942, 'learning_rate': 6.940494997367035e-05, 'epoch': 3.27}\n",
      "{'loss': 0.0991, 'learning_rate': 6.929963138493945e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0905, 'learning_rate': 6.919431279620853e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0914, 'learning_rate': 6.908899420747762e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0801, 'learning_rate': 6.898367561874671e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0875, 'learning_rate': 6.887835703001581e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0622, 'learning_rate': 6.877303844128489e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0637, 'learning_rate': 6.866771985255397e-05, 'epoch': 3.29}\n",
      "{'loss': 0.089, 'learning_rate': 6.856240126382307e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0718, 'learning_rate': 6.845708267509215e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0683, 'learning_rate': 6.835176408636125e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0738, 'learning_rate': 6.824644549763035e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0819, 'learning_rate': 6.814112690889942e-05, 'epoch': 3.31}\n",
      "{'loss': 0.0616, 'learning_rate': 6.803580832016851e-05, 'epoch': 3.31}\n",
      "{'loss': 0.0683, 'learning_rate': 6.79304897314376e-05, 'epoch': 3.31}\n",
      "{'loss': 0.0633, 'learning_rate': 6.782517114270669e-05, 'epoch': 3.31}\n",
      "{'loss': 0.0828, 'learning_rate': 6.771985255397579e-05, 'epoch': 3.32}\n",
      "{'loss': 0.1203, 'learning_rate': 6.761453396524487e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0848, 'learning_rate': 6.750921537651395e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0745, 'learning_rate': 6.740389678778305e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0745, 'learning_rate': 6.729857819905213e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0765, 'learning_rate': 6.719325961032123e-05, 'epoch': 3.33}\n",
      "{'loss': 0.1009, 'learning_rate': 6.708794102159031e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0764, 'learning_rate': 6.69826224328594e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0691, 'learning_rate': 6.687730384412849e-05, 'epoch': 3.34}\n",
      "{'loss': 0.062, 'learning_rate': 6.677198525539759e-05, 'epoch': 3.34}\n",
      "{'loss': 0.109, 'learning_rate': 6.666666666666667e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0852, 'learning_rate': 6.656134807793575e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0722, 'learning_rate': 6.645602948920485e-05, 'epoch': 3.35}\n",
      "{'loss': 0.1163, 'learning_rate': 6.635071090047393e-05, 'epoch': 3.35}\n",
      "{'loss': 0.0679, 'learning_rate': 6.624539231174303e-05, 'epoch': 3.35}\n",
      "{'loss': 0.0837, 'learning_rate': 6.614007372301212e-05, 'epoch': 3.36}\n",
      "{'loss': 0.0975, 'learning_rate': 6.603475513428121e-05, 'epoch': 3.36}\n",
      "{'loss': 0.0636, 'learning_rate': 6.592943654555029e-05, 'epoch': 3.36}\n",
      "{'loss': 0.0672, 'learning_rate': 6.582411795681939e-05, 'epoch': 3.36}\n",
      "{'loss': 0.096, 'learning_rate': 6.571879936808847e-05, 'epoch': 3.37}\n",
      "{'loss': 0.063, 'learning_rate': 6.561348077935757e-05, 'epoch': 3.37}\n",
      "{'loss': 0.0832, 'learning_rate': 6.550816219062665e-05, 'epoch': 3.37}\n",
      "{'loss': 0.1012, 'learning_rate': 6.540284360189573e-05, 'epoch': 3.37}\n",
      "{'loss': 0.0778, 'learning_rate': 6.529752501316483e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0912, 'learning_rate': 6.519220642443391e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0956, 'learning_rate': 6.508688783570301e-05, 'epoch': 3.38}\n",
      "{'loss': 0.1093, 'learning_rate': 6.498156924697209e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0898, 'learning_rate': 6.487625065824117e-05, 'epoch': 3.39}\n",
      "{'loss': 0.1028, 'learning_rate': 6.477093206951027e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0592, 'learning_rate': 6.466561348077937e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0773, 'learning_rate': 6.456029489204845e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0958, 'learning_rate': 6.445497630331754e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0901, 'learning_rate': 6.434965771458663e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0709, 'learning_rate': 6.424433912585571e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0706, 'learning_rate': 6.41390205371248e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0858, 'learning_rate': 6.40337019483939e-05, 'epoch': 3.41}\n",
      "{'loss': 0.0828, 'learning_rate': 6.392838335966299e-05, 'epoch': 3.41}\n",
      "{'loss': 0.0647, 'learning_rate': 6.382306477093207e-05, 'epoch': 3.41}\n",
      "{'loss': 0.1079, 'learning_rate': 6.371774618220117e-05, 'epoch': 3.42}\n",
      "{'loss': 0.0752, 'learning_rate': 6.361242759347025e-05, 'epoch': 3.42}\n",
      "{'loss': 0.0781, 'learning_rate': 6.350710900473934e-05, 'epoch': 3.42}\n",
      "{'loss': 0.0824, 'learning_rate': 6.340179041600843e-05, 'epoch': 3.42}\n",
      "{'loss': 0.0702, 'learning_rate': 6.329647182727751e-05, 'epoch': 3.43}\n",
      "{'loss': 0.1153, 'learning_rate': 6.31911532385466e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0584, 'learning_rate': 6.30858346498157e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0769, 'learning_rate': 6.298051606108479e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0631, 'learning_rate': 6.287519747235387e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0802, 'learning_rate': 6.276987888362296e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0658, 'learning_rate': 6.266456029489205e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0673, 'learning_rate': 6.255924170616114e-05, 'epoch': 3.44}\n",
      "{'loss': 0.1268, 'learning_rate': 6.245392311743023e-05, 'epoch': 3.45}\n",
      "{'loss': 0.0907, 'learning_rate': 6.234860452869932e-05, 'epoch': 3.45}\n",
      "{'loss': 0.0603, 'learning_rate': 6.22432859399684e-05, 'epoch': 3.45}\n",
      "{'loss': 0.0748, 'learning_rate': 6.213796735123749e-05, 'epoch': 3.45}\n",
      "{'loss': 0.0887, 'learning_rate': 6.203264876250659e-05, 'epoch': 3.46}\n",
      "{'loss': 0.1106, 'learning_rate': 6.192733017377568e-05, 'epoch': 3.46}\n",
      "{'loss': 0.0794, 'learning_rate': 6.182201158504476e-05, 'epoch': 3.46}\n",
      "{'loss': 0.0639, 'learning_rate': 6.171669299631385e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0681, 'learning_rate': 6.161137440758294e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0546, 'learning_rate': 6.150605581885203e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0764, 'learning_rate': 6.140073723012112e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0787, 'learning_rate': 6.12954186413902e-05, 'epoch': 3.48}\n",
      "{'loss': 0.1197, 'learning_rate': 6.119010005265929e-05, 'epoch': 3.48}\n",
      "{'loss': 0.1203, 'learning_rate': 6.108478146392838e-05, 'epoch': 3.48}\n",
      "{'loss': 0.0633, 'learning_rate': 6.097946287519748e-05, 'epoch': 3.48}\n",
      "{'loss': 0.1007, 'learning_rate': 6.0874144286466564e-05, 'epoch': 3.49}\n",
      "{'loss': 0.0691, 'learning_rate': 6.0768825697735654e-05, 'epoch': 3.49}\n",
      "{'loss': 0.093, 'learning_rate': 6.066350710900475e-05, 'epoch': 3.49}\n",
      "{'loss': 0.0609, 'learning_rate': 6.0558188520273826e-05, 'epoch': 3.49}\n",
      "{'loss': 0.0672, 'learning_rate': 6.045286993154292e-05, 'epoch': 3.5}\n",
      "{'loss': 0.068, 'learning_rate': 6.034755134281201e-05, 'epoch': 3.5}\n",
      "{'loss': 0.0639, 'learning_rate': 6.0242232754081095e-05, 'epoch': 3.5}\n",
      "{'loss': 0.0883, 'learning_rate': 6.013691416535019e-05, 'epoch': 3.5}\n",
      "{'loss': 0.1024, 'learning_rate': 6.003159557661928e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0875, 'learning_rate': 5.9926276987888364e-05, 'epoch': 3.51}\n",
      "{'loss': 0.061, 'learning_rate': 5.982095839915745e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0654, 'learning_rate': 5.9715639810426536e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0563, 'learning_rate': 5.961032122169563e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0636, 'learning_rate': 5.950500263296472e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0736, 'learning_rate': 5.9399684044233805e-05, 'epoch': 3.52}\n",
      "{'loss': 0.1169, 'learning_rate': 5.92943654555029e-05, 'epoch': 3.53}\n",
      "{'loss': 0.0796, 'learning_rate': 5.918904686677199e-05, 'epoch': 3.53}\n",
      "{'loss': 0.0781, 'learning_rate': 5.9083728278041074e-05, 'epoch': 3.53}\n",
      "{'loss': 0.0652, 'learning_rate': 5.897840968931016e-05, 'epoch': 3.53}\n",
      "{'loss': 0.0615, 'learning_rate': 5.887309110057926e-05, 'epoch': 3.54}\n",
      "{'loss': 0.0571, 'learning_rate': 5.876777251184834e-05, 'epoch': 3.54}\n",
      "{'loss': 0.0852, 'learning_rate': 5.866245392311743e-05, 'epoch': 3.54}\n",
      "{'loss': 0.0865, 'learning_rate': 5.855713533438653e-05, 'epoch': 3.54}\n",
      "{'loss': 0.1036, 'learning_rate': 5.8451816745655604e-05, 'epoch': 3.55}\n",
      "{'loss': 0.1199, 'learning_rate': 5.83464981569247e-05, 'epoch': 3.55}\n",
      "{'loss': 0.0661, 'learning_rate': 5.824117956819379e-05, 'epoch': 3.55}\n",
      "{'loss': 0.0669, 'learning_rate': 5.813586097946287e-05, 'epoch': 3.55}\n",
      "{'loss': 0.0655, 'learning_rate': 5.803054239073197e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0733, 'learning_rate': 5.792522380200106e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0675, 'learning_rate': 5.781990521327014e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0628, 'learning_rate': 5.771458662453924e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0766, 'learning_rate': 5.760926803580833e-05, 'epoch': 3.57}\n",
      "{'loss': 0.0614, 'learning_rate': 5.750394944707741e-05, 'epoch': 3.57}\n",
      "{'loss': 0.0687, 'learning_rate': 5.73986308583465e-05, 'epoch': 3.57}\n",
      "{'loss': 0.0814, 'learning_rate': 5.729331226961558e-05, 'epoch': 3.58}\n",
      "{'loss': 0.071, 'learning_rate': 5.718799368088468e-05, 'epoch': 3.58}\n",
      "{'loss': 0.0599, 'learning_rate': 5.708267509215377e-05, 'epoch': 3.58}\n",
      "{'loss': 0.0653, 'learning_rate': 5.697735650342285e-05, 'epoch': 3.58}\n",
      "{'loss': 0.0796, 'learning_rate': 5.687203791469194e-05, 'epoch': 3.59}\n",
      "{'loss': 0.0506, 'learning_rate': 5.676671932596104e-05, 'epoch': 3.59}\n",
      "{'loss': 0.095, 'learning_rate': 5.666140073723012e-05, 'epoch': 3.59}\n",
      "{'loss': 0.0856, 'learning_rate': 5.655608214849921e-05, 'epoch': 3.59}\n",
      "{'loss': 0.0892, 'learning_rate': 5.645076355976831e-05, 'epoch': 3.6}\n",
      "{'loss': 0.0695, 'learning_rate': 5.634544497103739e-05, 'epoch': 3.6}\n",
      "{'loss': 0.1058, 'learning_rate': 5.624012638230648e-05, 'epoch': 3.6}\n",
      "{'loss': 0.0968, 'learning_rate': 5.6134807793575576e-05, 'epoch': 3.6}\n",
      "{'loss': 0.0765, 'learning_rate': 5.602948920484465e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0676, 'learning_rate': 5.592417061611375e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0572, 'learning_rate': 5.581885202738284e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0664, 'learning_rate': 5.571353343865192e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0741, 'learning_rate': 5.560821484992102e-05, 'epoch': 3.62}\n",
      "{'loss': 0.0721, 'learning_rate': 5.5502896261190106e-05, 'epoch': 3.62}\n",
      "{'loss': 0.0674, 'learning_rate': 5.539757767245919e-05, 'epoch': 3.62}\n",
      "{'loss': 0.0665, 'learning_rate': 5.529225908372828e-05, 'epoch': 3.62}\n",
      "{'loss': 0.0594, 'learning_rate': 5.5186940494997375e-05, 'epoch': 3.63}\n",
      "{'loss': 0.0552, 'learning_rate': 5.508162190626646e-05, 'epoch': 3.63}\n",
      "{'loss': 0.0804, 'learning_rate': 5.497630331753555e-05, 'epoch': 3.63}\n",
      "{'loss': 0.077, 'learning_rate': 5.4870984728804644e-05, 'epoch': 3.64}\n",
      "{'loss': 0.0715, 'learning_rate': 5.476566614007373e-05, 'epoch': 3.64}\n",
      "{'loss': 0.0639, 'learning_rate': 5.4660347551342816e-05, 'epoch': 3.64}\n",
      "{'loss': 0.0559, 'learning_rate': 5.45550289626119e-05, 'epoch': 3.64}\n",
      "{'loss': 0.0681, 'learning_rate': 5.444971037388099e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0713, 'learning_rate': 5.4344391785150085e-05, 'epoch': 3.65}\n",
      "{'loss': 0.068, 'learning_rate': 5.423907319641917e-05, 'epoch': 3.65}\n",
      "{'loss': 0.1188, 'learning_rate': 5.413375460768826e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0911, 'learning_rate': 5.4028436018957354e-05, 'epoch': 3.66}\n",
      "{'loss': 0.0881, 'learning_rate': 5.392311743022643e-05, 'epoch': 3.66}\n",
      "{'loss': 0.0708, 'learning_rate': 5.3817798841495526e-05, 'epoch': 3.66}\n",
      "{'loss': 0.0528, 'learning_rate': 5.3712480252764616e-05, 'epoch': 3.66}\n",
      "{'loss': 0.0658, 'learning_rate': 5.36071616640337e-05, 'epoch': 3.67}\n",
      "{'loss': 0.0732, 'learning_rate': 5.3501843075302795e-05, 'epoch': 3.67}\n",
      "{'loss': 0.061, 'learning_rate': 5.3396524486571885e-05, 'epoch': 3.67}\n",
      "{'loss': 0.0517, 'learning_rate': 5.329120589784097e-05, 'epoch': 3.67}\n",
      "{'loss': 0.1005, 'learning_rate': 5.3185887309110064e-05, 'epoch': 3.68}\n",
      "{'loss': 0.0587, 'learning_rate': 5.3080568720379154e-05, 'epoch': 3.68}\n",
      "{'loss': 0.0591, 'learning_rate': 5.2975250131648236e-05, 'epoch': 3.68}\n",
      "{'loss': 0.058, 'learning_rate': 5.2869931542917326e-05, 'epoch': 3.69}\n",
      "{'loss': 0.0804, 'learning_rate': 5.276461295418642e-05, 'epoch': 3.69}\n",
      "{'loss': 0.069, 'learning_rate': 5.2659294365455505e-05, 'epoch': 3.69}\n",
      "{'loss': 0.0766, 'learning_rate': 5.2553975776724595e-05, 'epoch': 3.69}\n",
      "{'loss': 0.0591, 'learning_rate': 5.244865718799369e-05, 'epoch': 3.7}\n",
      "{'loss': 0.077, 'learning_rate': 5.234333859926277e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0551, 'learning_rate': 5.2238020010531864e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0542, 'learning_rate': 5.213270142180095e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0664, 'learning_rate': 5.2027382833070036e-05, 'epoch': 3.71}\n",
      "{'loss': 0.0585, 'learning_rate': 5.192206424433913e-05, 'epoch': 3.71}\n",
      "{'loss': 0.0936, 'learning_rate': 5.1816745655608215e-05, 'epoch': 3.71}\n",
      "{'loss': 0.1062, 'learning_rate': 5.1711427066877305e-05, 'epoch': 3.71}\n",
      "{'loss': 0.0642, 'learning_rate': 5.1606108478146394e-05, 'epoch': 3.72}\n",
      "{'loss': 0.0626, 'learning_rate': 5.150078988941548e-05, 'epoch': 3.72}\n",
      "{'loss': 0.0697, 'learning_rate': 5.1395471300684574e-05, 'epoch': 3.72}\n",
      "{'loss': 0.0753, 'learning_rate': 5.129015271195366e-05, 'epoch': 3.72}\n",
      "{'loss': 0.0582, 'learning_rate': 5.1184834123222746e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0605, 'learning_rate': 5.107951553449184e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0682, 'learning_rate': 5.097419694576093e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0658, 'learning_rate': 5.0868878357030015e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0597, 'learning_rate': 5.0763559768299104e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0847, 'learning_rate': 5.06582411795682e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0622, 'learning_rate': 5.0552922590837284e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0747, 'learning_rate': 5.044760400210637e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0876, 'learning_rate': 5.034228541337547e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0569, 'learning_rate': 5.0236966824644546e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0741, 'learning_rate': 5.013164823591364e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0749, 'learning_rate': 5.002632964718273e-05, 'epoch': 3.76}\n",
      "{'loss': 0.0893, 'learning_rate': 4.9921011058451815e-05, 'epoch': 3.76}\n",
      "{'loss': 0.07, 'learning_rate': 4.981569246972091e-05, 'epoch': 3.76}\n",
      "{'loss': 0.1372, 'learning_rate': 4.9710373880989994e-05, 'epoch': 3.76}\n",
      "{'loss': 0.0724, 'learning_rate': 4.960505529225908e-05, 'epoch': 3.77}\n",
      "{'loss': 0.0565, 'learning_rate': 4.949973670352818e-05, 'epoch': 3.77}\n",
      "{'loss': 0.0829, 'learning_rate': 4.939441811479726e-05, 'epoch': 3.77}\n",
      "{'loss': 0.0865, 'learning_rate': 4.928909952606635e-05, 'epoch': 3.77}\n",
      "{'loss': 0.1094, 'learning_rate': 4.918378093733544e-05, 'epoch': 3.78}\n",
      "{'loss': 0.0531, 'learning_rate': 4.907846234860453e-05, 'epoch': 3.78}\n",
      "{'loss': 0.0522, 'learning_rate': 4.897314375987362e-05, 'epoch': 3.78}\n",
      "{'loss': 0.0614, 'learning_rate': 4.886782517114271e-05, 'epoch': 3.78}\n",
      "{'loss': 0.0914, 'learning_rate': 4.87625065824118e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0622, 'learning_rate': 4.865718799368088e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0507, 'learning_rate': 4.855186940494997e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0973, 'learning_rate': 4.844655081621907e-05, 'epoch': 3.8}\n",
      "{'loss': 0.0649, 'learning_rate': 4.834123222748815e-05, 'epoch': 3.8}\n",
      "{'loss': 0.0614, 'learning_rate': 4.823591363875724e-05, 'epoch': 3.8}\n",
      "{'loss': 0.0502, 'learning_rate': 4.813059505002633e-05, 'epoch': 3.8}\n",
      "{'loss': 0.121, 'learning_rate': 4.802527646129542e-05, 'epoch': 3.81}\n",
      "{'loss': 0.0591, 'learning_rate': 4.791995787256451e-05, 'epoch': 3.81}\n",
      "{'loss': 0.1099, 'learning_rate': 4.78146392838336e-05, 'epoch': 3.81}\n",
      "{'loss': 0.09, 'learning_rate': 4.770932069510269e-05, 'epoch': 3.81}\n",
      "{'loss': 0.1036, 'learning_rate': 4.760400210637178e-05, 'epoch': 3.82}\n",
      "{'loss': 0.0582, 'learning_rate': 4.749868351764087e-05, 'epoch': 3.82}\n",
      "{'loss': 0.0524, 'learning_rate': 4.739336492890996e-05, 'epoch': 3.82}\n",
      "{'loss': 0.0545, 'learning_rate': 4.728804634017904e-05, 'epoch': 3.82}\n",
      "{'loss': 0.0676, 'learning_rate': 4.718272775144813e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0661, 'learning_rate': 4.707740916271722e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0645, 'learning_rate': 4.697209057398631e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0526, 'learning_rate': 4.68667719852554e-05, 'epoch': 3.83}\n",
      "{'loss': 0.1171, 'learning_rate': 4.676145339652449e-05, 'epoch': 3.84}\n",
      "{'loss': 0.0564, 'learning_rate': 4.665613480779358e-05, 'epoch': 3.84}\n",
      "{'loss': 0.074, 'learning_rate': 4.655081621906267e-05, 'epoch': 3.84}\n",
      "{'loss': 0.0517, 'learning_rate': 4.644549763033176e-05, 'epoch': 3.84}\n",
      "{'loss': 0.0855, 'learning_rate': 4.634017904160085e-05, 'epoch': 3.85}\n",
      "{'loss': 0.0742, 'learning_rate': 4.623486045286993e-05, 'epoch': 3.85}\n",
      "{'loss': 0.0514, 'learning_rate': 4.6129541864139027e-05, 'epoch': 3.85}\n",
      "{'loss': 0.0625, 'learning_rate': 4.602422327540811e-05, 'epoch': 3.86}\n",
      "{'loss': 0.0563, 'learning_rate': 4.59189046866772e-05, 'epoch': 3.86}\n",
      "{'loss': 0.0518, 'learning_rate': 4.581358609794629e-05, 'epoch': 3.86}\n",
      "{'loss': 0.0691, 'learning_rate': 4.570826750921538e-05, 'epoch': 3.86}\n",
      "{'loss': 0.0647, 'learning_rate': 4.560294892048447e-05, 'epoch': 3.87}\n",
      "{'loss': 0.1281, 'learning_rate': 4.549763033175356e-05, 'epoch': 3.87}\n",
      "{'loss': 0.0632, 'learning_rate': 4.539231174302265e-05, 'epoch': 3.87}\n",
      "{'loss': 0.0931, 'learning_rate': 4.5286993154291737e-05, 'epoch': 3.87}\n",
      "{'loss': 0.0582, 'learning_rate': 4.518167456556082e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0992, 'learning_rate': 4.5076355976829916e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0538, 'learning_rate': 4.4971037388099005e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0555, 'learning_rate': 4.486571879936809e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0615, 'learning_rate': 4.4760400210637185e-05, 'epoch': 3.89}\n",
      "{'loss': 0.0621, 'learning_rate': 4.465508162190627e-05, 'epoch': 3.89}\n",
      "{'loss': 0.056, 'learning_rate': 4.454976303317536e-05, 'epoch': 3.89}\n",
      "{'loss': 0.0555, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.89}\n",
      "{'loss': 0.0863, 'learning_rate': 4.4339125855713536e-05, 'epoch': 3.9}\n",
      "{'loss': 0.0537, 'learning_rate': 4.4233807266982626e-05, 'epoch': 3.9}\n",
      "{'loss': 0.0851, 'learning_rate': 4.412848867825171e-05, 'epoch': 3.9}\n",
      "{'loss': 0.0576, 'learning_rate': 4.4023170089520805e-05, 'epoch': 3.91}\n",
      "{'loss': 0.0573, 'learning_rate': 4.3917851500789895e-05, 'epoch': 3.91}\n",
      "{'loss': 0.08, 'learning_rate': 4.381253291205898e-05, 'epoch': 3.91}\n",
      "{'loss': 0.0516, 'learning_rate': 4.3707214323328074e-05, 'epoch': 3.91}\n",
      "{'loss': 0.0555, 'learning_rate': 4.3601895734597157e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0868, 'learning_rate': 4.3496577145866246e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0552, 'learning_rate': 4.3391258557135336e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0758, 'learning_rate': 4.3285939968404425e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0506, 'learning_rate': 4.3180621379673515e-05, 'epoch': 3.93}\n",
      "{'loss': 0.0511, 'learning_rate': 4.30753027909426e-05, 'epoch': 3.93}\n",
      "{'loss': 0.0624, 'learning_rate': 4.2969984202211694e-05, 'epoch': 3.93}\n",
      "{'loss': 0.0597, 'learning_rate': 4.2864665613480784e-05, 'epoch': 3.93}\n",
      "{'loss': 0.0551, 'learning_rate': 4.2759347024749867e-05, 'epoch': 3.94}\n",
      "{'loss': 0.0552, 'learning_rate': 4.265402843601896e-05, 'epoch': 3.94}\n",
      "{'loss': 0.0787, 'learning_rate': 4.2548709847288046e-05, 'epoch': 3.94}\n",
      "{'loss': 0.0493, 'learning_rate': 4.2443391258557135e-05, 'epoch': 3.94}\n",
      "{'loss': 0.0552, 'learning_rate': 4.233807266982623e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0806, 'learning_rate': 4.2232754081095315e-05, 'epoch': 3.95}\n",
      "{'loss': 0.069, 'learning_rate': 4.2127435492364404e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0636, 'learning_rate': 4.2022116903633494e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0465, 'learning_rate': 4.1916798314902583e-05, 'epoch': 3.96}\n",
      "{'loss': 0.0801, 'learning_rate': 4.181147972617167e-05, 'epoch': 3.96}\n",
      "{'loss': 0.0517, 'learning_rate': 4.1706161137440756e-05, 'epoch': 3.96}\n",
      "{'loss': 0.0706, 'learning_rate': 4.160084254870985e-05, 'epoch': 3.97}\n",
      "{'loss': 0.0593, 'learning_rate': 4.1495523959978935e-05, 'epoch': 3.97}\n",
      "{'loss': 0.0638, 'learning_rate': 4.1390205371248025e-05, 'epoch': 3.97}\n",
      "{'loss': 0.0765, 'learning_rate': 4.128488678251712e-05, 'epoch': 3.97}\n",
      "{'loss': 0.065, 'learning_rate': 4.1179568193786204e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0607, 'learning_rate': 4.1074249605055293e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0597, 'learning_rate': 4.096893101632438e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0679, 'learning_rate': 4.086361242759347e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0533, 'learning_rate': 4.075829383886256e-05, 'epoch': 3.99}\n",
      "{'loss': 0.0573, 'learning_rate': 4.0652975250131645e-05, 'epoch': 3.99}\n",
      "{'loss': 0.0623, 'learning_rate': 4.054765666140074e-05, 'epoch': 3.99}\n",
      "{'loss': 0.0731, 'learning_rate': 4.0442338072669824e-05, 'epoch': 3.99}\n",
      "{'loss': 0.0487, 'learning_rate': 4.0337019483938914e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0473, 'learning_rate': 4.023170089520801e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0508, 'learning_rate': 4.012638230647709e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0502, 'learning_rate': 4.002106371774618e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0518, 'learning_rate': 3.991574512901527e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0485, 'learning_rate': 3.981042654028436e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0487, 'learning_rate': 3.970510795155345e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0502, 'learning_rate': 3.959978936282254e-05, 'epoch': 4.02}\n",
      "{'loss': 0.0416, 'learning_rate': 3.949447077409163e-05, 'epoch': 4.02}\n",
      "{'loss': 0.0535, 'learning_rate': 3.938915218536072e-05, 'epoch': 4.02}\n",
      "{'loss': 0.0497, 'learning_rate': 3.92838335966298e-05, 'epoch': 4.02}\n",
      "{'loss': 0.0526, 'learning_rate': 3.91785150078989e-05, 'epoch': 4.03}\n",
      "{'loss': 0.045, 'learning_rate': 3.907319641916798e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0555, 'learning_rate': 3.896787783043707e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0543, 'learning_rate': 3.886255924170616e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0479, 'learning_rate': 3.875724065297525e-05, 'epoch': 4.04}\n",
      "{'loss': 0.0525, 'learning_rate': 3.865192206424434e-05, 'epoch': 4.04}\n",
      "{'loss': 0.0455, 'learning_rate': 3.854660347551343e-05, 'epoch': 4.04}\n",
      "{'loss': 0.0468, 'learning_rate': 3.844128488678252e-05, 'epoch': 4.04}\n",
      "{'loss': 0.0952, 'learning_rate': 3.833596629805161e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0492, 'learning_rate': 3.82306477093207e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0462, 'learning_rate': 3.812532912058979e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0753, 'learning_rate': 3.802001053185887e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0584, 'learning_rate': 3.791469194312796e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0526, 'learning_rate': 3.780937335439706e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0531, 'learning_rate': 3.770405476566614e-05, 'epoch': 4.06}\n",
      "{'loss': 0.063, 'learning_rate': 3.759873617693523e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0536, 'learning_rate': 3.749341758820432e-05, 'epoch': 4.07}\n",
      "{'loss': 0.0465, 'learning_rate': 3.738809899947341e-05, 'epoch': 4.07}\n",
      "{'loss': 0.0542, 'learning_rate': 3.72827804107425e-05, 'epoch': 4.07}\n",
      "{'loss': 0.0508, 'learning_rate': 3.717746182201159e-05, 'epoch': 4.08}\n",
      "{'loss': 0.0411, 'learning_rate': 3.707214323328068e-05, 'epoch': 4.08}\n",
      "{'loss': 0.0679, 'learning_rate': 3.696682464454976e-05, 'epoch': 4.08}\n",
      "{'loss': 0.0512, 'learning_rate': 3.686150605581886e-05, 'epoch': 4.08}\n",
      "{'loss': 0.1193, 'learning_rate': 3.675618746708795e-05, 'epoch': 4.09}\n",
      "{'loss': 0.0587, 'learning_rate': 3.665086887835703e-05, 'epoch': 4.09}\n",
      "{'loss': 0.0555, 'learning_rate': 3.654555028962612e-05, 'epoch': 4.09}\n",
      "{'loss': 0.0616, 'learning_rate': 3.644023170089521e-05, 'epoch': 4.09}\n",
      "{'loss': 0.0517, 'learning_rate': 3.63349131121643e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0424, 'learning_rate': 3.622959452343339e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0573, 'learning_rate': 3.612427593470248e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0482, 'learning_rate': 3.601895734597157e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0654, 'learning_rate': 3.591363875724065e-05, 'epoch': 4.11}\n",
      "{'loss': 0.0511, 'learning_rate': 3.5808320168509746e-05, 'epoch': 4.11}\n",
      "{'loss': 0.0436, 'learning_rate': 3.5703001579778836e-05, 'epoch': 4.11}\n",
      "{'loss': 0.0938, 'learning_rate': 3.559768299104792e-05, 'epoch': 4.11}\n",
      "{'loss': 0.0476, 'learning_rate': 3.5492364402317015e-05, 'epoch': 4.12}\n",
      "{'loss': 0.0473, 'learning_rate': 3.53870458135861e-05, 'epoch': 4.12}\n",
      "{'loss': 0.0546, 'learning_rate': 3.528172722485519e-05, 'epoch': 4.12}\n",
      "{'loss': 0.0482, 'learning_rate': 3.517640863612428e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0622, 'learning_rate': 3.507109004739337e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0439, 'learning_rate': 3.4965771458662456e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0456, 'learning_rate': 3.486045286993154e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0594, 'learning_rate': 3.4755134281200636e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0654, 'learning_rate': 3.4649815692469725e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0489, 'learning_rate': 3.454449710373881e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0555, 'learning_rate': 3.4439178515007904e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0909, 'learning_rate': 3.433385992627699e-05, 'epoch': 4.15}\n",
      "{'loss': 0.0518, 'learning_rate': 3.422854133754608e-05, 'epoch': 4.15}\n",
      "{'loss': 0.0473, 'learning_rate': 3.412322274881517e-05, 'epoch': 4.15}\n",
      "{'loss': 0.0463, 'learning_rate': 3.4017904160084256e-05, 'epoch': 4.15}\n",
      "{'loss': 0.0479, 'learning_rate': 3.3912585571353346e-05, 'epoch': 4.16}\n",
      "{'loss': 0.0892, 'learning_rate': 3.3807266982622435e-05, 'epoch': 4.16}\n",
      "{'loss': 0.0537, 'learning_rate': 3.3701948393891525e-05, 'epoch': 4.16}\n",
      "{'loss': 0.1001, 'learning_rate': 3.3596629805160614e-05, 'epoch': 4.16}\n",
      "{'loss': 0.0493, 'learning_rate': 3.34913112164297e-05, 'epoch': 4.17}\n",
      "{'loss': 0.0858, 'learning_rate': 3.3385992627698794e-05, 'epoch': 4.17}\n",
      "{'loss': 0.043, 'learning_rate': 3.3280674038967876e-05, 'epoch': 4.17}\n",
      "{'loss': 0.051, 'learning_rate': 3.3175355450236966e-05, 'epoch': 4.17}\n",
      "{'loss': 0.0593, 'learning_rate': 3.307003686150606e-05, 'epoch': 4.18}\n",
      "{'loss': 0.053, 'learning_rate': 3.2964718272775145e-05, 'epoch': 4.18}\n",
      "{'loss': 0.051, 'learning_rate': 3.2859399684044235e-05, 'epoch': 4.18}\n",
      "{'loss': 0.0586, 'learning_rate': 3.2754081095313324e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0452, 'learning_rate': 3.2648762506582414e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0447, 'learning_rate': 3.2543443917851504e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0554, 'learning_rate': 3.2438125329120586e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0463, 'learning_rate': 3.233280674038968e-05, 'epoch': 4.2}\n",
      "{'loss': 0.0872, 'learning_rate': 3.222748815165877e-05, 'epoch': 4.2}\n",
      "{'loss': 0.0699, 'learning_rate': 3.2122169562927855e-05, 'epoch': 4.2}\n",
      "{'loss': 0.044, 'learning_rate': 3.201685097419695e-05, 'epoch': 4.2}\n",
      "{'loss': 0.0532, 'learning_rate': 3.1911532385466034e-05, 'epoch': 4.21}\n",
      "{'loss': 0.0427, 'learning_rate': 3.1806213796735124e-05, 'epoch': 4.21}\n",
      "{'loss': 0.0695, 'learning_rate': 3.1700895208004214e-05, 'epoch': 4.21}\n",
      "{'loss': 0.0458, 'learning_rate': 3.15955766192733e-05, 'epoch': 4.21}\n",
      "{'loss': 0.0544, 'learning_rate': 3.149025803054239e-05, 'epoch': 4.22}\n",
      "{'loss': 0.0526, 'learning_rate': 3.138493944181148e-05, 'epoch': 4.22}\n",
      "{'loss': 0.06, 'learning_rate': 3.127962085308057e-05, 'epoch': 4.22}\n",
      "{'loss': 0.0556, 'learning_rate': 3.117430226434966e-05, 'epoch': 4.22}\n",
      "{'loss': 0.0449, 'learning_rate': 3.1068983675618744e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0455, 'learning_rate': 3.096366508688784e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0455, 'learning_rate': 3.0858346498156924e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0498, 'learning_rate': 3.075302790942601e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0526, 'learning_rate': 3.06477093206951e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0421, 'learning_rate': 3.054239073196419e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0579, 'learning_rate': 3.0437072143233282e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0719, 'learning_rate': 3.0331753554502375e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0381, 'learning_rate': 3.022643496577146e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0437, 'learning_rate': 3.0121116377040547e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0463, 'learning_rate': 3.001579778830964e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0595, 'learning_rate': 2.9910479199578727e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0517, 'learning_rate': 2.9805160610847816e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0452, 'learning_rate': 2.9699842022116902e-05, 'epoch': 4.26}\n",
      "{'loss': 0.061, 'learning_rate': 2.9594523433385995e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0493, 'learning_rate': 2.948920484465508e-05, 'epoch': 4.27}\n",
      "{'loss': 0.055, 'learning_rate': 2.938388625592417e-05, 'epoch': 4.27}\n",
      "{'loss': 0.0456, 'learning_rate': 2.9278567667193264e-05, 'epoch': 4.27}\n",
      "{'loss': 0.0423, 'learning_rate': 2.917324907846235e-05, 'epoch': 4.27}\n",
      "{'loss': 0.0451, 'learning_rate': 2.9067930489731437e-05, 'epoch': 4.28}\n",
      "{'loss': 0.045, 'learning_rate': 2.896261190100053e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0467, 'learning_rate': 2.885729331226962e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0475, 'learning_rate': 2.8751974723538705e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0569, 'learning_rate': 2.864665613480779e-05, 'epoch': 4.29}\n",
      "{'loss': 0.0549, 'learning_rate': 2.8541337546076885e-05, 'epoch': 4.29}\n",
      "{'loss': 0.0506, 'learning_rate': 2.843601895734597e-05, 'epoch': 4.29}\n",
      "{'loss': 0.0466, 'learning_rate': 2.833070036861506e-05, 'epoch': 4.3}\n",
      "{'loss': 0.0501, 'learning_rate': 2.8225381779884153e-05, 'epoch': 4.3}\n",
      "{'loss': 0.0708, 'learning_rate': 2.812006319115324e-05, 'epoch': 4.3}\n",
      "{'loss': 0.0432, 'learning_rate': 2.8014744602422326e-05, 'epoch': 4.3}\n",
      "{'loss': 0.0447, 'learning_rate': 2.790942601369142e-05, 'epoch': 4.31}\n",
      "{'loss': 0.0475, 'learning_rate': 2.780410742496051e-05, 'epoch': 4.31}\n",
      "{'loss': 0.0612, 'learning_rate': 2.7698788836229595e-05, 'epoch': 4.31}\n",
      "{'loss': 0.0408, 'learning_rate': 2.7593470247498688e-05, 'epoch': 4.31}\n",
      "{'loss': 0.0513, 'learning_rate': 2.7488151658767774e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0558, 'learning_rate': 2.7382833070036863e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0438, 'learning_rate': 2.727751448130595e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0462, 'learning_rate': 2.7172195892575043e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0635, 'learning_rate': 2.706687730384413e-05, 'epoch': 4.33}\n",
      "{'loss': 0.046, 'learning_rate': 2.6961558715113215e-05, 'epoch': 4.33}\n",
      "{'loss': 0.0509, 'learning_rate': 2.6856240126382308e-05, 'epoch': 4.33}\n",
      "{'loss': 0.0469, 'learning_rate': 2.6750921537651398e-05, 'epoch': 4.33}\n",
      "{'loss': 0.048, 'learning_rate': 2.6645602948920484e-05, 'epoch': 4.34}\n",
      "{'loss': 0.053, 'learning_rate': 2.6540284360189577e-05, 'epoch': 4.34}\n",
      "{'loss': 0.0912, 'learning_rate': 2.6434965771458663e-05, 'epoch': 4.34}\n",
      "{'loss': 0.0441, 'learning_rate': 2.6329647182727753e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0417, 'learning_rate': 2.6224328593996846e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0416, 'learning_rate': 2.6119010005265932e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0487, 'learning_rate': 2.6013691416535018e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0418, 'learning_rate': 2.5908372827804108e-05, 'epoch': 4.36}\n",
      "{'loss': 0.0403, 'learning_rate': 2.5803054239073197e-05, 'epoch': 4.36}\n",
      "{'loss': 0.0435, 'learning_rate': 2.5697735650342287e-05, 'epoch': 4.36}\n",
      "{'loss': 0.0491, 'learning_rate': 2.5592417061611373e-05, 'epoch': 4.36}\n",
      "{'loss': 0.06, 'learning_rate': 2.5487098472880466e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0456, 'learning_rate': 2.5381779884149552e-05, 'epoch': 4.37}\n",
      "{'loss': 0.052, 'learning_rate': 2.5276461295418642e-05, 'epoch': 4.37}\n",
      "{'loss': 0.039, 'learning_rate': 2.5171142706687735e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0462, 'learning_rate': 2.506582411795682e-05, 'epoch': 4.38}\n",
      "{'loss': 0.0423, 'learning_rate': 2.4960505529225907e-05, 'epoch': 4.38}\n",
      "{'loss': 0.0504, 'learning_rate': 2.4855186940494997e-05, 'epoch': 4.38}\n",
      "{'loss': 0.0424, 'learning_rate': 2.474986835176409e-05, 'epoch': 4.38}\n",
      "{'loss': 0.0417, 'learning_rate': 2.4644549763033176e-05, 'epoch': 4.39}\n",
      "{'loss': 0.0484, 'learning_rate': 2.4539231174302266e-05, 'epoch': 4.39}\n",
      "{'loss': 0.0422, 'learning_rate': 2.4433912585571355e-05, 'epoch': 4.39}\n",
      "{'loss': 0.0476, 'learning_rate': 2.432859399684044e-05, 'epoch': 4.39}\n",
      "{'loss': 0.0916, 'learning_rate': 2.4223275408109534e-05, 'epoch': 4.4}\n",
      "{'loss': 0.0488, 'learning_rate': 2.411795681937862e-05, 'epoch': 4.4}\n",
      "{'loss': 0.0437, 'learning_rate': 2.401263823064771e-05, 'epoch': 4.4}\n",
      "{'loss': 0.0732, 'learning_rate': 2.39073196419168e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0453, 'learning_rate': 2.380200105318589e-05, 'epoch': 4.41}\n",
      "{'loss': 0.054, 'learning_rate': 2.369668246445498e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0481, 'learning_rate': 2.3591363875724065e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0432, 'learning_rate': 2.3486045286993155e-05, 'epoch': 4.42}\n",
      "{'loss': 0.0717, 'learning_rate': 2.3380726698262244e-05, 'epoch': 4.42}\n",
      "{'loss': 0.059, 'learning_rate': 2.3275408109531334e-05, 'epoch': 4.42}\n",
      "{'loss': 0.0638, 'learning_rate': 2.3170089520800424e-05, 'epoch': 4.42}\n",
      "{'loss': 0.0483, 'learning_rate': 2.3064770932069513e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0692, 'learning_rate': 2.29594523433386e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0409, 'learning_rate': 2.285413375460769e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0402, 'learning_rate': 2.274881516587678e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0476, 'learning_rate': 2.2643496577145868e-05, 'epoch': 4.44}\n",
      "{'loss': 0.0433, 'learning_rate': 2.2538177988414958e-05, 'epoch': 4.44}\n",
      "{'loss': 0.0641, 'learning_rate': 2.2432859399684044e-05, 'epoch': 4.44}\n",
      "{'loss': 0.0612, 'learning_rate': 2.2327540810953134e-05, 'epoch': 4.44}\n",
      "{'loss': 0.064, 'learning_rate': 2.2222222222222223e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0402, 'learning_rate': 2.2116903633491313e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0437, 'learning_rate': 2.2011585044760402e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0491, 'learning_rate': 2.190626645602949e-05, 'epoch': 4.46}\n",
      "{'loss': 0.0515, 'learning_rate': 2.1800947867298578e-05, 'epoch': 4.46}\n",
      "{'loss': 0.0411, 'learning_rate': 2.1695629278567668e-05, 'epoch': 4.46}\n",
      "{'loss': 0.0475, 'learning_rate': 2.1590310689836757e-05, 'epoch': 4.46}\n",
      "{'loss': 0.0495, 'learning_rate': 2.1484992101105847e-05, 'epoch': 4.47}\n",
      "{'loss': 0.0452, 'learning_rate': 2.1379673512374933e-05, 'epoch': 4.47}\n",
      "{'loss': 0.0496, 'learning_rate': 2.1274354923644023e-05, 'epoch': 4.47}\n",
      "{'loss': 0.0836, 'learning_rate': 2.1169036334913116e-05, 'epoch': 4.47}\n",
      "{'loss': 0.0445, 'learning_rate': 2.1063717746182202e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0404, 'learning_rate': 2.0958399157451292e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0406, 'learning_rate': 2.0853080568720378e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0535, 'learning_rate': 2.0747761979989468e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0417, 'learning_rate': 2.064244339125856e-05, 'epoch': 4.49}\n",
      "{'loss': 0.0662, 'learning_rate': 2.0537124802527647e-05, 'epoch': 4.49}\n",
      "{'loss': 0.0403, 'learning_rate': 2.0431806213796736e-05, 'epoch': 4.49}\n",
      "{'loss': 0.0452, 'learning_rate': 2.0326487625065823e-05, 'epoch': 4.49}\n",
      "{'loss': 0.0403, 'learning_rate': 2.0221169036334912e-05, 'epoch': 4.5}\n",
      "{'loss': 0.044, 'learning_rate': 2.0115850447604005e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0445, 'learning_rate': 2.001053185887309e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0407, 'learning_rate': 1.990521327014218e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0706, 'learning_rate': 1.979989468141127e-05, 'epoch': 4.51}\n",
      "{'loss': 0.0562, 'learning_rate': 1.969457609268036e-05, 'epoch': 4.51}\n",
      "{'loss': 0.0419, 'learning_rate': 1.958925750394945e-05, 'epoch': 4.51}\n",
      "{'loss': 0.0395, 'learning_rate': 1.9483938915218536e-05, 'epoch': 4.52}\n",
      "{'loss': 0.0442, 'learning_rate': 1.9378620326487626e-05, 'epoch': 4.52}\n",
      "{'loss': 0.0615, 'learning_rate': 1.9273301737756715e-05, 'epoch': 4.52}\n",
      "{'loss': 0.0478, 'learning_rate': 1.9167983149025805e-05, 'epoch': 4.52}\n",
      "{'loss': 0.0376, 'learning_rate': 1.9062664560294894e-05, 'epoch': 4.53}\n",
      "{'loss': 0.1104, 'learning_rate': 1.895734597156398e-05, 'epoch': 4.53}\n",
      "{'loss': 0.0658, 'learning_rate': 1.885202738283307e-05, 'epoch': 4.53}\n",
      "{'loss': 0.0389, 'learning_rate': 1.874670879410216e-05, 'epoch': 4.53}\n",
      "{'loss': 0.0475, 'learning_rate': 1.864139020537125e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0505, 'learning_rate': 1.853607161664034e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0923, 'learning_rate': 1.843075302790943e-05, 'epoch': 4.54}\n",
      "{'loss': 0.047, 'learning_rate': 1.8325434439178515e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0377, 'learning_rate': 1.8220115850447604e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0491, 'learning_rate': 1.8114797261716694e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0417, 'learning_rate': 1.8009478672985784e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0439, 'learning_rate': 1.7904160084254873e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0587, 'learning_rate': 1.779884149552396e-05, 'epoch': 4.56}\n",
      "{'loss': 0.0403, 'learning_rate': 1.769352290679305e-05, 'epoch': 4.56}\n",
      "{'loss': 0.0487, 'learning_rate': 1.758820431806214e-05, 'epoch': 4.56}\n",
      "{'loss': 0.053, 'learning_rate': 1.7482885729331228e-05, 'epoch': 4.57}\n",
      "{'loss': 0.043, 'learning_rate': 1.7377567140600318e-05, 'epoch': 4.57}\n",
      "{'loss': 0.0477, 'learning_rate': 1.7272248551869404e-05, 'epoch': 4.57}\n",
      "{'loss': 0.0558, 'learning_rate': 1.7166929963138494e-05, 'epoch': 4.57}\n",
      "{'loss': 0.0452, 'learning_rate': 1.7061611374407587e-05, 'epoch': 4.58}\n",
      "{'loss': 0.0415, 'learning_rate': 1.6956292785676673e-05, 'epoch': 4.58}\n",
      "{'loss': 0.0401, 'learning_rate': 1.6850974196945762e-05, 'epoch': 4.58}\n",
      "{'loss': 0.0435, 'learning_rate': 1.674565560821485e-05, 'epoch': 4.58}\n",
      "{'loss': 0.0515, 'learning_rate': 1.6640337019483938e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0552, 'learning_rate': 1.653501843075303e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0373, 'learning_rate': 1.6429699842022117e-05, 'epoch': 4.59}\n",
      "{'loss': 0.066, 'learning_rate': 1.6324381253291207e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0484, 'learning_rate': 1.6219062664560293e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0512, 'learning_rate': 1.6113744075829386e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0387, 'learning_rate': 1.6008425487098476e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0405, 'learning_rate': 1.5903106898367562e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0456, 'learning_rate': 1.579778830963665e-05, 'epoch': 4.61}\n",
      "{'loss': 0.0466, 'learning_rate': 1.569246972090574e-05, 'epoch': 4.61}\n",
      "{'loss': 0.0439, 'learning_rate': 1.558715113217483e-05, 'epoch': 4.61}\n",
      "{'loss': 0.0462, 'learning_rate': 1.548183254344392e-05, 'epoch': 4.61}\n",
      "{'loss': 0.0579, 'learning_rate': 1.5376513954713007e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0391, 'learning_rate': 1.5271195365982096e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0578, 'learning_rate': 1.5165876777251187e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0401, 'learning_rate': 1.5060558188520274e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0416, 'learning_rate': 1.4955239599789363e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0405, 'learning_rate': 1.4849921011058451e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0421, 'learning_rate': 1.474460242232754e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0424, 'learning_rate': 1.4639283833596632e-05, 'epoch': 4.64}\n",
      "{'loss': 0.0362, 'learning_rate': 1.4533965244865718e-05, 'epoch': 4.64}\n",
      "{'loss': 0.0494, 'learning_rate': 1.442864665613481e-05, 'epoch': 4.64}\n",
      "{'loss': 0.099, 'learning_rate': 1.4323328067403896e-05, 'epoch': 4.64}\n",
      "{'loss': 0.0469, 'learning_rate': 1.4218009478672985e-05, 'epoch': 4.65}\n",
      "{'loss': 0.0416, 'learning_rate': 1.4112690889942077e-05, 'epoch': 4.65}\n",
      "{'loss': 0.0365, 'learning_rate': 1.4007372301211163e-05, 'epoch': 4.65}\n",
      "{'loss': 0.0534, 'learning_rate': 1.3902053712480254e-05, 'epoch': 4.65}\n",
      "{'loss': 0.0436, 'learning_rate': 1.3796735123749344e-05, 'epoch': 4.66}\n",
      "{'loss': 0.0424, 'learning_rate': 1.3691416535018432e-05, 'epoch': 4.66}\n",
      "{'loss': 0.035, 'learning_rate': 1.3586097946287521e-05, 'epoch': 4.66}\n",
      "{'loss': 0.0504, 'learning_rate': 1.3480779357556608e-05, 'epoch': 4.66}\n",
      "{'loss': 0.0458, 'learning_rate': 1.3375460768825699e-05, 'epoch': 4.67}\n",
      "{'loss': 0.0368, 'learning_rate': 1.3270142180094788e-05, 'epoch': 4.67}\n",
      "{'loss': 0.0461, 'learning_rate': 1.3164823591363876e-05, 'epoch': 4.67}\n",
      "{'loss': 0.0374, 'learning_rate': 1.3059505002632966e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0405, 'learning_rate': 1.2954186413902054e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0407, 'learning_rate': 1.2848867825171143e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0462, 'learning_rate': 1.2743549236440233e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0391, 'learning_rate': 1.2638230647709321e-05, 'epoch': 4.69}\n",
      "{'loss': 0.044, 'learning_rate': 1.253291205897841e-05, 'epoch': 4.69}\n",
      "{'loss': 0.0424, 'learning_rate': 1.2427593470247498e-05, 'epoch': 4.69}\n",
      "{'loss': 0.0408, 'learning_rate': 1.2322274881516588e-05, 'epoch': 4.69}\n",
      "{'loss': 0.0476, 'learning_rate': 1.2216956292785678e-05, 'epoch': 4.7}\n",
      "{'loss': 0.0364, 'learning_rate': 1.2111637704054767e-05, 'epoch': 4.7}\n",
      "{'loss': 0.042, 'learning_rate': 1.2006319115323855e-05, 'epoch': 4.7}\n",
      "{'loss': 0.0655, 'learning_rate': 1.1901000526592945e-05, 'epoch': 4.7}\n",
      "{'loss': 0.0407, 'learning_rate': 1.1795681937862033e-05, 'epoch': 4.71}\n",
      "{'loss': 0.0464, 'learning_rate': 1.1690363349131122e-05, 'epoch': 4.71}\n",
      "{'loss': 0.0426, 'learning_rate': 1.1585044760400212e-05, 'epoch': 4.71}\n",
      "{'loss': 0.0426, 'learning_rate': 1.14797261716693e-05, 'epoch': 4.71}\n",
      "{'loss': 0.039, 'learning_rate': 1.137440758293839e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0576, 'learning_rate': 1.1269088994207479e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0439, 'learning_rate': 1.1163770405476567e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0503, 'learning_rate': 1.1058451816745656e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0364, 'learning_rate': 1.0953133228014744e-05, 'epoch': 4.73}\n",
      "{'loss': 0.0378, 'learning_rate': 1.0847814639283834e-05, 'epoch': 4.73}\n",
      "{'loss': 0.0519, 'learning_rate': 1.0742496050552924e-05, 'epoch': 4.73}\n",
      "{'loss': 0.053, 'learning_rate': 1.0637177461822011e-05, 'epoch': 4.74}\n",
      "{'loss': 0.0459, 'learning_rate': 1.0531858873091101e-05, 'epoch': 4.74}\n",
      "{'loss': 0.0366, 'learning_rate': 1.0426540284360189e-05, 'epoch': 4.74}\n",
      "{'loss': 0.0628, 'learning_rate': 1.032122169562928e-05, 'epoch': 4.74}\n",
      "{'loss': 0.0412, 'learning_rate': 1.0215903106898368e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0379, 'learning_rate': 1.0110584518167456e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0446, 'learning_rate': 1.0005265929436546e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0414, 'learning_rate': 9.899947340705635e-06, 'epoch': 4.75}\n",
      "{'loss': 0.046, 'learning_rate': 9.794628751974725e-06, 'epoch': 4.76}\n",
      "{'loss': 0.0462, 'learning_rate': 9.689310163243813e-06, 'epoch': 4.76}\n",
      "{'loss': 0.0389, 'learning_rate': 9.583991574512902e-06, 'epoch': 4.76}\n",
      "{'loss': 0.0368, 'learning_rate': 9.47867298578199e-06, 'epoch': 4.76}\n",
      "{'loss': 0.0379, 'learning_rate': 9.37335439705108e-06, 'epoch': 4.77}\n",
      "{'loss': 0.063, 'learning_rate': 9.26803580832017e-06, 'epoch': 4.77}\n",
      "{'loss': 0.0503, 'learning_rate': 9.162717219589257e-06, 'epoch': 4.77}\n",
      "{'loss': 0.0456, 'learning_rate': 9.057398630858347e-06, 'epoch': 4.77}\n",
      "{'loss': 0.0525, 'learning_rate': 8.952080042127437e-06, 'epoch': 4.78}\n",
      "{'loss': 0.0429, 'learning_rate': 8.846761453396524e-06, 'epoch': 4.78}\n",
      "{'loss': 0.0379, 'learning_rate': 8.741442864665614e-06, 'epoch': 4.78}\n",
      "{'loss': 0.0717, 'learning_rate': 8.636124275934702e-06, 'epoch': 4.79}\n",
      "{'loss': 0.0382, 'learning_rate': 8.530805687203793e-06, 'epoch': 4.79}\n",
      "{'loss': 0.0456, 'learning_rate': 8.425487098472881e-06, 'epoch': 4.79}\n",
      "{'loss': 0.0868, 'learning_rate': 8.320168509741969e-06, 'epoch': 4.79}\n",
      "{'loss': 0.0376, 'learning_rate': 8.214849921011059e-06, 'epoch': 4.8}\n",
      "{'loss': 0.0428, 'learning_rate': 8.109531332280147e-06, 'epoch': 4.8}\n",
      "{'loss': 0.0404, 'learning_rate': 8.004212743549238e-06, 'epoch': 4.8}\n",
      "{'loss': 0.0438, 'learning_rate': 7.898894154818326e-06, 'epoch': 4.8}\n",
      "{'loss': 0.0561, 'learning_rate': 7.793575566087415e-06, 'epoch': 4.81}\n",
      "{'loss': 0.08, 'learning_rate': 7.688256977356503e-06, 'epoch': 4.81}\n",
      "{'loss': 0.0714, 'learning_rate': 7.582938388625594e-06, 'epoch': 4.81}\n",
      "{'loss': 0.0467, 'learning_rate': 7.477619799894682e-06, 'epoch': 4.81}\n",
      "{'loss': 0.0429, 'learning_rate': 7.37230121116377e-06, 'epoch': 4.82}\n",
      "{'loss': 0.0391, 'learning_rate': 7.266982622432859e-06, 'epoch': 4.82}\n",
      "{'loss': 0.0379, 'learning_rate': 7.161664033701948e-06, 'epoch': 4.82}\n",
      "{'loss': 0.0437, 'learning_rate': 7.056345444971038e-06, 'epoch': 4.82}\n",
      "{'loss': 0.043, 'learning_rate': 6.951026856240127e-06, 'epoch': 4.83}\n",
      "{'loss': 0.0392, 'learning_rate': 6.845708267509216e-06, 'epoch': 4.83}\n",
      "{'loss': 0.0487, 'learning_rate': 6.740389678778304e-06, 'epoch': 4.83}\n",
      "{'loss': 0.04, 'learning_rate': 6.635071090047394e-06, 'epoch': 4.83}\n",
      "{'loss': 0.0387, 'learning_rate': 6.529752501316483e-06, 'epoch': 4.84}\n",
      "{'loss': 0.0581, 'learning_rate': 6.424433912585572e-06, 'epoch': 4.84}\n",
      "{'loss': 0.0645, 'learning_rate': 6.3191153238546605e-06, 'epoch': 4.84}\n",
      "{'loss': 0.04, 'learning_rate': 6.213796735123749e-06, 'epoch': 4.85}\n",
      "{'loss': 0.0421, 'learning_rate': 6.108478146392839e-06, 'epoch': 4.85}\n",
      "{'loss': 0.0383, 'learning_rate': 6.0031595576619276e-06, 'epoch': 4.85}\n",
      "{'loss': 0.0447, 'learning_rate': 5.897840968931016e-06, 'epoch': 4.85}\n",
      "{'loss': 0.0386, 'learning_rate': 5.792522380200106e-06, 'epoch': 4.86}\n",
      "{'loss': 0.0845, 'learning_rate': 5.687203791469195e-06, 'epoch': 4.86}\n",
      "{'loss': 0.0413, 'learning_rate': 5.581885202738283e-06, 'epoch': 4.86}\n",
      "{'loss': 0.075, 'learning_rate': 5.476566614007372e-06, 'epoch': 4.86}\n",
      "{'loss': 0.0555, 'learning_rate': 5.371248025276462e-06, 'epoch': 4.87}\n",
      "{'loss': 0.0388, 'learning_rate': 5.2659294365455505e-06, 'epoch': 4.87}\n",
      "{'loss': 0.049, 'learning_rate': 5.16061084781464e-06, 'epoch': 4.87}\n",
      "{'loss': 0.0433, 'learning_rate': 5.055292259083728e-06, 'epoch': 4.87}\n",
      "{'loss': 0.0374, 'learning_rate': 4.949973670352818e-06, 'epoch': 4.88}\n",
      "{'loss': 0.0679, 'learning_rate': 4.844655081621906e-06, 'epoch': 4.88}\n",
      "{'loss': 0.0848, 'learning_rate': 4.739336492890995e-06, 'epoch': 4.88}\n",
      "{'loss': 0.0419, 'learning_rate': 4.634017904160085e-06, 'epoch': 4.88}\n",
      "{'loss': 0.0408, 'learning_rate': 4.5286993154291735e-06, 'epoch': 4.89}\n",
      "{'loss': 0.0357, 'learning_rate': 4.423380726698262e-06, 'epoch': 4.89}\n",
      "{'loss': 0.0551, 'learning_rate': 4.318062137967351e-06, 'epoch': 4.89}\n",
      "{'loss': 0.0448, 'learning_rate': 4.212743549236441e-06, 'epoch': 4.9}\n",
      "{'loss': 0.0361, 'learning_rate': 4.107424960505529e-06, 'epoch': 4.9}\n",
      "{'loss': 0.0695, 'learning_rate': 4.002106371774619e-06, 'epoch': 4.9}\n",
      "{'loss': 0.0373, 'learning_rate': 3.896787783043708e-06, 'epoch': 4.9}\n",
      "{'loss': 0.0397, 'learning_rate': 3.791469194312797e-06, 'epoch': 4.91}\n",
      "{'loss': 0.045, 'learning_rate': 3.686150605581885e-06, 'epoch': 4.91}\n",
      "{'loss': 0.0853, 'learning_rate': 3.580832016850974e-06, 'epoch': 4.91}\n",
      "{'loss': 0.0413, 'learning_rate': 3.4755134281200636e-06, 'epoch': 4.91}\n",
      "{'loss': 0.0377, 'learning_rate': 3.370194839389152e-06, 'epoch': 4.92}\n",
      "{'loss': 0.0449, 'learning_rate': 3.2648762506582415e-06, 'epoch': 4.92}\n",
      "{'loss': 0.0374, 'learning_rate': 3.1595576619273302e-06, 'epoch': 4.92}\n",
      "{'loss': 0.0567, 'learning_rate': 3.0542390731964194e-06, 'epoch': 4.92}\n",
      "{'loss': 0.0436, 'learning_rate': 2.948920484465508e-06, 'epoch': 4.93}\n",
      "{'loss': 0.0385, 'learning_rate': 2.8436018957345973e-06, 'epoch': 4.93}\n",
      "{'loss': 0.0498, 'learning_rate': 2.738283307003686e-06, 'epoch': 4.93}\n",
      "{'loss': 0.0372, 'learning_rate': 2.6329647182727753e-06, 'epoch': 4.93}\n",
      "{'loss': 0.0388, 'learning_rate': 2.527646129541864e-06, 'epoch': 4.94}\n",
      "{'loss': 0.0397, 'learning_rate': 2.422327540810953e-06, 'epoch': 4.94}\n",
      "{'loss': 0.0805, 'learning_rate': 2.3170089520800424e-06, 'epoch': 4.94}\n",
      "{'loss': 0.0393, 'learning_rate': 2.211690363349131e-06, 'epoch': 4.94}\n",
      "{'loss': 0.046, 'learning_rate': 2.1063717746182203e-06, 'epoch': 4.95}\n",
      "{'loss': 0.042, 'learning_rate': 2.0010531858873095e-06, 'epoch': 4.95}\n",
      "{'loss': 0.0628, 'learning_rate': 1.8957345971563984e-06, 'epoch': 4.95}\n",
      "{'loss': 0.0472, 'learning_rate': 1.790416008425487e-06, 'epoch': 4.96}\n",
      "{'loss': 0.0381, 'learning_rate': 1.685097419694576e-06, 'epoch': 4.96}\n",
      "{'loss': 0.038, 'learning_rate': 1.5797788309636651e-06, 'epoch': 4.96}\n",
      "{'loss': 0.0408, 'learning_rate': 1.474460242232754e-06, 'epoch': 4.96}\n",
      "{'loss': 0.0341, 'learning_rate': 1.369141653501843e-06, 'epoch': 4.97}\n",
      "{'loss': 0.0815, 'learning_rate': 1.263823064770932e-06, 'epoch': 4.97}\n",
      "{'loss': 0.0356, 'learning_rate': 1.1585044760400212e-06, 'epoch': 4.97}\n",
      "{'loss': 0.0463, 'learning_rate': 1.0531858873091101e-06, 'epoch': 4.97}\n",
      "{'loss': 0.0487, 'learning_rate': 9.478672985781992e-07, 'epoch': 4.98}\n",
      "{'loss': 0.0507, 'learning_rate': 8.42548709847288e-07, 'epoch': 4.98}\n",
      "{'loss': 0.037, 'learning_rate': 7.37230121116377e-07, 'epoch': 4.98}\n",
      "{'loss': 0.0521, 'learning_rate': 6.31911532385466e-07, 'epoch': 4.98}\n",
      "{'loss': 0.0357, 'learning_rate': 5.265929436545551e-07, 'epoch': 4.99}\n",
      "{'loss': 0.0383, 'learning_rate': 4.21274354923644e-07, 'epoch': 4.99}\n",
      "{'loss': 0.0629, 'learning_rate': 3.15955766192733e-07, 'epoch': 4.99}\n",
      "{'loss': 0.0447, 'learning_rate': 2.10637177461822e-07, 'epoch': 4.99}\n",
      "{'loss': 0.0475, 'learning_rate': 1.05318588730911e-07, 'epoch': 5.0}\n",
      "{'loss': 0.0436, 'learning_rate': 0.0, 'epoch': 5.0}\n",
      "{'train_runtime': 46070.7, 'train_samples_per_second': 4.144, 'train_steps_per_second': 4.144, 'train_loss': 0.3814519633492479, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=190900, training_loss=0.3814519633492479, metrics={'train_runtime': 46070.7, 'train_samples_per_second': 4.144, 'train_steps_per_second': 4.144, 'train_loss': 0.3814519633492479, 'epoch': 5.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/train_steps_per_second</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>190900</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0436</td></tr><tr><td>train/total_flos</td><td>9.97612978176e+16</td></tr><tr><td>train/train_loss</td><td>0.38145</td></tr><tr><td>train/train_runtime</td><td>46070.7</td></tr><tr><td>train/train_samples_per_second</td><td>4.144</td></tr><tr><td>train/train_steps_per_second</td><td>4.144</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GPT2-DocRED-w-ner-[]-5epochs</strong> at: <a href='https://wandb.ai/tian1995/GPT2-normal/runs/7ao24mdl' target=\"_blank\">https://wandb.ai/tian1995/GPT2-normal/runs/7ao24mdl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230709_222050-7ao24mdl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "trainer.save_model(\"DocRED/GPT_w_ner[]/model\")\n",
    "\n",
    "# save the tokenizer\n",
    "# tokenizer.save_pretrained(\"DocRED/GPT_w_ner/tokenizer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "checkpoint = \"DocRED/GPT_w_ner[]/model\"\n",
    "# checkpoint = \"DocRED/GPT_without_ner/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"DocRED/GPT_w_ner[]/gpt2_tokenizer\")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/mambaforge/envs/BioRED/lib/python3.10/site-packages/transformers/generation/utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet text : @HondaCustSvc Your customer service has been horrible during the recall process. I will never purchase a Honda again. Label : or get rid of a bottle from a public transport\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "inputs = tokenizer(\"Tweet text : @HondaCustSvc Your customer service has been horrible during the recall process. I will never purchase a Honda again. Label :\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10, pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file from DocRED/data/test.json and DocRED/data/rel_info.json\n",
    "\n",
    "import json\n",
    "\n",
    "with open('DocRED/data/dev.json') as f:\n",
    "    test_set = json.load(f)\n",
    "\n",
    "\n",
    "with open('DocRED/data/rel_info.json') as f:\n",
    "    rel_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b41da423a6d4577aa7a8f1a843f87b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with ner\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "relation_dict = {\n",
    "    'id': [],\n",
    "    'text': [],\n",
    "    'head': [],\n",
    "    'tail': [],\n",
    "    'head_first': [],\n",
    "    'relation': [],\n",
    "    'head_start_pos' : [],\n",
    "    'tail_start_pos' : []\n",
    "}\n",
    "\n",
    "for i in tqdm(range(len(test_set))):\n",
    "    sents = \"\"\n",
    "    for sent in test_set[i]['sents']:\n",
    "        # flatten the sent list\n",
    "        a = \" \".join(sent)\n",
    "        sents += a.lower() + \" \"\n",
    "    # relation_dict['text'].append(sents)\n",
    "\n",
    "    for relation_pair in test_set[i]['labels']:\n",
    "        relation_dict['id'].append(i)\n",
    "        relation_dict['text'].append(sents)\n",
    "        head = []\n",
    "        head_ = []\n",
    "        head_start_pos = []\n",
    "        head.append([[item['name'].lower()] for item in test_set[i]['vertexSet'][relation_pair['h']]])\n",
    "        for j, item in enumerate(head[0]):\n",
    "            if item not in head_:\n",
    "                head_.append(item)\n",
    "                head_start_pos.append(test_set[i]['vertexSet'][relation_pair['h']][j]['pos'][0])\n",
    "\n",
    "        relation_dict['head'].append(head_)\n",
    "        relation_dict['head_start_pos'].append(head_start_pos)\n",
    "\n",
    "        tail = []\n",
    "        tail_ = []\n",
    "        tail_start_pos = []\n",
    "        tail.append([[item['name'].lower()] for item in test_set[i]['vertexSet'][relation_pair['t']]])\n",
    "        for j, item in enumerate(tail[0]):\n",
    "            if item not in tail_:\n",
    "                tail_.append(item)\n",
    "                tail_start_pos.append(test_set[i]['vertexSet'][relation_pair['t']][j]['pos'][0])\n",
    "        relation_dict['tail'].append(tail_)\n",
    "        relation_dict['tail_start_pos'].append(tail_start_pos)\n",
    "\n",
    "        \n",
    "        if test_set[i]['vertexSet'][relation_pair['h']][0]['pos'][0] < test_set[i]['vertexSet'][relation_pair['t']][0]['pos'][0]:\n",
    "            relation_dict['head_first'].append(1)\n",
    "        else:\n",
    "            relation_dict['head_first'].append(0)\n",
    "        \n",
    "        relation_dict['relation'].append(relation_pair['r'])\n",
    "    # break\n",
    "\n",
    "\n",
    "# save the relation_dict to a json file\n",
    "\n",
    "with open('DocRED/data/DocRED_baseline_metadata/dev_relation_dict.json', 'w') as f:\n",
    "    json.dump(relation_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "if ner:\n",
    "    with open('DocRED/data/DocRED_baseline_metadata/dev_relation_dict.json') as f:\n",
    "        relation_dict = json.load(f)\n",
    "\n",
    "    dataset = Dataset.from_dict(\n",
    "        {\n",
    "            'text': relation_dict['text'],\n",
    "            'head': relation_dict['head'],\n",
    "            'tail': relation_dict['tail'],\n",
    "            'head_first': relation_dict['head_first'],\n",
    "            'relation': relation_dict['relation']\n",
    "        }\n",
    "    )\n",
    "\n",
    "else:\n",
    "    with open('DocRED/data/DocRED_baseline_metadata/dev_relation_dict_without_ner.json') as f:\n",
    "        relation_dict = json.load(f)\n",
    "\n",
    "    dataset = Dataset.from_dict(\n",
    "        {\n",
    "            'text': relation_dict['text'],\n",
    "            'pair': relation_dict['pair'],\n",
    "            'relation': relation_dict['relation']\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rel_info\n",
    "\n",
    "with open('DocRED/data/rel_info.json') as f:\n",
    "    rel_info = json.load(f)\n",
    "\n",
    "rel2id = {v: k for k, v in rel_info.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country of citizenship\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'conrad oberon johnson ( november 15 , 1915  february 3 , 2008 ) was an american music educator , long associated with the city of houston , who was inducted into the texas bandmasters hall of fame in 2000 . born in victoria , texas , conrad johnson was nine when his family moved to houston . following studies at yates high school , he attended houston college for negroes and graduated from wiley college . he was an active member of omega psi phi fraternity . he started his career in music education in 1941 and , following a thirty - seven - year career , retired from his position at kashmere high school in 1978 , but continued to remain active in shaping music in houston by conducting summer programs and in - home tutoring . johnson was a proficient musician in his own right and , at one point , played with count basie . erskine hawkins tried to convince him to join his orchestra , but johnson declined , citing a love of teaching and obligations to his family . later , johnson made his lasting contribution to music by forming the kashmere stage band , a renowned school orchestra that won a number of awards during its decade - long run . the conrad o. johnson school of fine arts at kashmere high school is named after him . conrad o. johnson died in houston days after his former students staged a celebration in his honor . the gala saturday night concert , which was filmed by a documentary crew , was described by the students as \" the greatest 92nd birthday gift that he could have ever requested . \" ',\n",
       " 'head': [['conrad oberon johnson'],\n",
       "  ['conrad johnson'],\n",
       "  ['conrad o. johnson'],\n",
       "  ['johnson']],\n",
       " 'tail': [['american']],\n",
       " 'head_first': 1,\n",
       " 'relation': 'P27'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 45\n",
    "print(rel_info[dataset[n]['relation']])\n",
    "dataset[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pro_processing_ner_infer(example, tokenizer):\n",
    "    texts = example['text']\n",
    "\n",
    "    # special_tokens = [50259, 50260, 50261, 50262, 50263, 50264]\n",
    "\n",
    "    output_texts = []\n",
    "\n",
    "    text_ids = tokenizer(texts, add_special_tokens=False)['input_ids']\n",
    "\n",
    "    for i in range(len(example['head'])):\n",
    "        head = \"\"\n",
    "        for item in example['head'][i]:\n",
    "            head += item[0] + \" ; \"\n",
    "        head = head[:-2]\n",
    "        head += \". \"\n",
    "\n",
    "        tail = \"\"\n",
    "        for item in example['tail'][i]:\n",
    "            tail += item[0] + \" ; \"\n",
    "        tail = tail[:-2]\n",
    "        tail += \". \"\n",
    "        \n",
    "        if example['head_first'][i] == 1:\n",
    "            output_line = \"[entity1] : \" + head + \"[entity2] : \" + tail + \"[learn1] [learn2] [learn3] [learn4] [learn5] [learn6] \"\n",
    "            # output_line = output_line + f\"the relation between source entity 1 and target entity 2 is {rel_info[example['relation'][i]]} . \" + tokenizer.eos_token\n",
    "\n",
    "        else:\n",
    "            output_line = \"[entity1] : \" + tail + \"[entity2] : \" + head + \"[learn1] [learn2] [learn3] [learn4] [learn5] [learn6] \"\n",
    "            # output_line = output_line + f\"the relation between source entity 2 and target entity 1 is {rel_info[example['relation'][i]]} . \" + tokenizer.eos_token\n",
    "        \n",
    "        output_texts.append(output_line)\n",
    "\n",
    "\n",
    "    output_ids = tokenizer(output_texts, add_special_tokens=False)['input_ids']\n",
    "\n",
    "    # input_ids = []\n",
    "    # attention_mask = []\n",
    "\n",
    "    count = 0\n",
    "    for i, ids in enumerate(output_ids):\n",
    "        if len(text_ids[i]) + len(ids) > 1024:\n",
    "            text_ids[i] = text_ids[:1024 - len(ids)]\n",
    "            count += 1\n",
    "        text_ids[i] = text_ids[i] + output_ids[i]\n",
    "        assert len(text_ids[i]) <= 1024\n",
    "        # attention_mask.append([1] * len(text_ids[i]) + [0] * (1024 - len(text_ids[i])))\n",
    "    if count != 0:\n",
    "        print(f\"truncated {count} examples\")\n",
    "\n",
    "    # if padding:\n",
    "    #     for i, ids in enumerate(output_ids):\n",
    "    #         output_ids[i] = ids + [tokenizer.pad_token_id] * (1024 - len(ids))\n",
    "    #         text_ids[i] = text_ids[i] + [tokenizer.pad_token_id] * (1024 - len(text_ids[i]))\n",
    "\n",
    "    return {\n",
    "        'input_ids': text_ids,\n",
    "        # 'attention_mask': attention_mask,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'head', 'tail', 'head_first', 'relation'],\n",
       "    num_rows: 12275\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4162969cb24dee811e64b07937ee5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12275 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenized_dataset = dataset.map(lambda example: pro_processing_without_ner_infer(example, tokenizer), batched=True, remove_columns=['text', 'pair', 'relation'])\n",
    "tokenized_dataset = dataset.map(lambda example: pro_processing_ner_infer(example, tokenizer), batched=True, remove_columns=['text', 'head', 'tail', 'head_first', 'relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b74bee517e9419995aa9701ea84abcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12275 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # save tokenizer_dataset\n",
    "\n",
    "# tokenized_dataset.save_to_disk('DocRED/data/DocRED_baseline_metadata/dev_tokenized_dataset_dev_w_ner_[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "tokenized_dataset = load_from_disk('DocRED/data/DocRED_baseline_metadata/dev_tokenized_dataset_dev_w_ner_[]')\n",
    "# tokenized_dataset = load_from_disk('DocRED/data/DocRED_baseline_metadata/dev_tokenized_dataset_without_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(type='torch', columns=['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conrad oberon johnson ( november 15, 1915  february 3, 2008 ) was an american music educator, long associated with the city of houston, who was inducted into the texas bandmasters hall of fame in 2000. born in victoria, texas, conrad johnson was nine when his family moved to houston. following studies at yates high school, he attended houston college for negroes and graduated from wiley college. he was an active member of omega psi phi fraternity. he started his career in music education in 1941 and, following a thirty - seven - year career, retired from his position at kashmere high school in 1978, but continued to remain active in shaping music in houston by conducting summer programs and in - home tutoring. johnson was a proficient musician in his own right and, at one point, played with count basie. erskine hawkins tried to convince him to join his orchestra, but johnson declined, citing a love of teaching and obligations to his family. later, johnson made his lasting contribution to music by forming the kashmere stage band, a renowned school orchestra that won a number of awards during its decade - long run. the conrad o. johnson school of fine arts at kashmere high school is named after him. conrad o. johnson died in houston days after his former students staged a celebration in his honor. the gala saturday night concert, which was filmed by a documentary crew, was described by the students as \" the greatest 92nd birthday gift that he could have ever requested. \"  [entity1] : conrad oberon johnson ; conrad johnson ; conrad o. johnson ; johnson. [entity2] : american. [learn1] [learn2] [learn3] [learn4] [learn5] [learn6]'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset[45]['input_ids'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rel_info\n",
    "\n",
    "with open('DocRED/data/rel_info.json') as f:\n",
    "    rel_info = json.load(f)\n",
    "\n",
    "rel2id = {v: k for k, v in rel_info.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4678d53bf30e4006b10bc2e0f59f8973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is contains administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country of citizenship. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is inception. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is mother. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is inception. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is date of birth. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is member of. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is award received. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is notable work. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is publication date. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is award received. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is inception. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is member of political party. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is publisher. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is religion. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is sibling. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is date of birth. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is conflict. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is director. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is instance of. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is performer. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is part of. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is continent. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is participant. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is performer. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is followed by. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is narrative location. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is place of death. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country of citizenship. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is notable work. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is author. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is performer. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is author. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country of citizenship. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is participant. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is part of. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country of origin. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is member of sports team. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is sibling. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is date of birth. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is member of. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is member of. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is spouse. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is cast member. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is follows. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is inception. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country of citizenship. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is applies to jurisdiction. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is characters. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is part of. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is performer. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is employer. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country of citizenship. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is present in work. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is record label. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is parent organization. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is composer. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is contains administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is part of. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is cast member. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country of citizenship. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is date of birth. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is screenwriter. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is performer. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is mouth of the watercourse. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is date of death. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is follows. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is date of birth. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is religion. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is member of. <|endoftext|>\n",
      "the relation between source [entity2] and target [entity1] is located in the administrative territorial entity. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is country. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is date of birth. <|endoftext|>\n",
      "the relation between source [entity1] and target [entity2] is date of birth. <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "outputs = []\n",
    "model.to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(tokenized_dataset))):\n",
    "    # for i in range(1):\n",
    "        output = model.generate(input_ids=tokenized_dataset[\"input_ids\"][i].unsqueeze(0).to(\"cuda\"), max_new_tokens=100, pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "        output_text = tokenizer.batch_decode(output.detach().cpu().numpy(), skip_special_tokens=False)[0]\n",
    "        try:\n",
    "            outputs.append(output_text.split(\"[learn1] [learn2] [learn3] [learn4] [learn5] [learn6]\")[1].strip())\n",
    "        except:\n",
    "            outputs.append(output_text.split(\"[learn1][learn2][learn3][learn4][learn5][learn6]\")[1].strip())\n",
    "        if i % 100 == 0:\n",
    "            print(outputs[-1])\n",
    "\n",
    "    # print(tokenizer.batch_decode(output.detach().cpu().numpy(), skip_special_tokens=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the relation between source [entity1] and target [entity2] is country of citizenship. <|endoftext|>'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'conrad oberon johnson ( november 15 , 1915  february 3 , 2008 ) was an american music educator , long associated with the city of houston , who was inducted into the texas bandmasters hall of fame in 2000 . born in victoria , texas , conrad johnson was nine when his family moved to houston . following studies at yates high school , he attended houston college for negroes and graduated from wiley college . he was an active member of omega psi phi fraternity . he started his career in music education in 1941 and , following a thirty - seven - year career , retired from his position at kashmere high school in 1978 , but continued to remain active in shaping music in houston by conducting summer programs and in - home tutoring . johnson was a proficient musician in his own right and , at one point , played with count basie . erskine hawkins tried to convince him to join his orchestra , but johnson declined , citing a love of teaching and obligations to his family . later , johnson made his lasting contribution to music by forming the kashmere stage band , a renowned school orchestra that won a number of awards during its decade - long run . the conrad o. johnson school of fine arts at kashmere high school is named after him . conrad o. johnson died in houston days after his former students staged a celebration in his honor . the gala saturday night concert , which was filmed by a documentary crew , was described by the students as \" the greatest 92nd birthday gift that he could have ever requested . \" ',\n",
       " 'head': [['conrad oberon johnson'],\n",
       "  ['conrad johnson'],\n",
       "  ['conrad o. johnson'],\n",
       "  ['johnson']],\n",
       " 'tail': [['american']],\n",
       " 'head_first': 1,\n",
       " 'relation': 'P27'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'country of citizenship'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_info['P27']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 12275\n"
     ]
    }
   ],
   "source": [
    "# post processing for the outputs w ner\n",
    "# (source, target, relation)\n",
    "# (2, 1, relation)\n",
    "pairs = []\n",
    "count = 0\n",
    "for output in outputs:\n",
    "    # if the output doesn't end with \"<|endoftext|>\", find the lastest \";\" of the output and only take the previous part\n",
    "    try:\n",
    "        source = output.split(\"between source [entity\")[1].strip()\n",
    "        source = source.split(\"] and target \")[0].strip()\n",
    "\n",
    "        target = output.split(\" and target [entity\")[1].strip()\n",
    "        target = target.split(\"] is \")[0].strip()\n",
    "\n",
    "        relation = output.split(\" is \")[-1].strip()\n",
    "        relation = relation.split(\". <|endoftext|>\")[0].strip()\n",
    "\n",
    "        try:\n",
    "            relation = rel2id[relation]\n",
    "        except:\n",
    "            count += 1\n",
    "            pass\n",
    "\n",
    "        pairs.append((source, target, relation))\n",
    "    except:\n",
    "        pairs.append((\"none\", \"none\", \"none\"))\n",
    "\n",
    "print(f\"{count} / {len(outputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the relation between source [entity1] and target [entity2] is country of citizenship. <|endoftext|>'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"output\": [],\n",
    "    \"label\": []\n",
    "}\n",
    "\n",
    "for i, output in enumerate(pairs):\n",
    "    result['output'].append(output)\n",
    "    if dataset[i]['head_first'] == 1:\n",
    "        result['label'].append(('1', '2', dataset[i]['relation']))\n",
    "    else:\n",
    "        result['label'].append(('2', '1', dataset[i]['relation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result dictionary\n",
    "# import pickle\n",
    "# with open(\"DocRED/GPT_w_ner[]/result/epoch_5_result.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2', '1', 'P17')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['label'][48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2', '1', 'P17')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['output'][48]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"DocRED/GPT_w_ner[]/result/epoch_5_result.pkl\", \"rb\") as f:\n",
    "    result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length: 12275, 12275\n",
      "instance:\n",
      "('1', '2', 'P17')\n",
      "('1', '2', 'P17')\n"
     ]
    }
   ],
   "source": [
    "print(f'the length: {len(result[\"output\"])}, {len(result[\"label\"])}')\n",
    "print(f'instance:\\n{result[\"output\"][0]}\\n{result[\"label\"][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source and target, relation\n",
    "st_tp = 0\n",
    "st_fp = 0\n",
    "st_fn = 0\n",
    "st_tn = 0\n",
    "\n",
    "r_tp = 0\n",
    "r_fp = 0\n",
    "r_fn = 0\n",
    "r_tn = 0\n",
    "\n",
    "tuple_tp = 0\n",
    "tuple_fp = 0  \n",
    "tuple_fn = 0\n",
    "tuple_tn = 0\n",
    "\n",
    "\n",
    "for output, label in zip(result['output'], result['label']):\n",
    "    pair = False\n",
    "    relation = False\n",
    "    if output[0] == label[0] and output[1] == label[1]:\n",
    "        st_tp += 1\n",
    "        pair = True\n",
    "    else:\n",
    "        st_fn += 1\n",
    "        st_fp += 1\n",
    "    \n",
    "    if output[2] == label[2]:\n",
    "        r_tp += 1\n",
    "        relation = True\n",
    "    else:\n",
    "        r_fn += 1\n",
    "        r_fp += 1\n",
    "\n",
    "    if pair and relation:\n",
    "        tuple_tp += 1\n",
    "    else:\n",
    "        tuple_fn += 1\n",
    "        tuple_fp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source and target precision: 0.8537678207739308, recall: 0.8537678207739308, f1: 0.8537678207739308\n",
      "relation precision: 0.7141344195519348, recall: 0.7141344195519348, f1: 0.7141344195519348\n",
      "tuple precision: 0.6980855397148676, recall: 0.6980855397148676, f1: 0.6980855397148676\n"
     ]
    }
   ],
   "source": [
    "# calculate the precision, recall and f1 score\n",
    "\n",
    "# for source and target\n",
    "st_precision = st_tp / (st_tp + st_fp)\n",
    "st_recall = st_tp / (st_tp + st_fn)\n",
    "st_f1 = 2 * st_precision * st_recall / (st_precision + st_recall)\n",
    "print(f\"source and target precision: {st_precision}, recall: {st_recall}, f1: {st_f1}\")\n",
    "\n",
    "# for relation\n",
    "r_precision = r_tp / (r_tp + r_fp)\n",
    "r_recall = r_tp / (r_tp + r_fn)\n",
    "r_f1 = 2 * r_precision * r_recall / (r_precision + r_recall)\n",
    "print(f\"relation precision: {r_precision}, recall: {r_recall}, f1: {r_f1}\")\n",
    "\n",
    "# for tuple\n",
    "tuple_precision = tuple_tp / (tuple_tp + tuple_fp)\n",
    "tuple_recall = tuple_tp / (tuple_tp + tuple_fn)\n",
    "tuple_f1 = 2 * tuple_precision * tuple_recall / (tuple_precision + tuple_recall)\n",
    "print(f\"tuple precision: {tuple_precision}, recall: {tuple_recall}, f1: {tuple_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioRED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
